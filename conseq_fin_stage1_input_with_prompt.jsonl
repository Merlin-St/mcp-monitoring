{"input": "ONLY RESPOND WITH JSON. NO EXPLANATIONS. NO MARKDOWN. NO TEXT OUTSIDE JSON.\n\nAnalyze the MCP server for financial relevance. Look for keywords: payment, banking, credit, loan, finance, money, currency, crypto, investment, trading, portfolio, market, exchange, wallet, account, budget, expense, income, tax, invoice, billing, accounting, insurance, compliance, KYC, AML.\n\nJSON FORMAT (NOTHING ELSE):\n{\n  \"server_name\": \"string\",\n  \"server_id\": \"string\", \n  \"is_finance_llm\": \"yes|no|unclear\",\n  \"confidence\": \"high|medium|low\",\n  \"threat_models\": [],\n  \"analysis_notes\": \"Brief reason\"\n}\n\nIf financial keywords found: is_finance_llm=\"yes\". If not: is_finance_llm=\"no\". If unclear: is_finance_llm=\"unclear\".\n\nRESPOND ONLY WITH JSON.\n\nMCP Server Data:\n{\"server_name\": \"pagerduty-mcp-server\", \"server_id\": \"wpfleger96/pagerduty-mcp-server\", \"description\": \"PagerDuty MCP Server for LLM Agent Integration\", \"readme\": \"# PagerDuty MCP Server\\nA server that exposes PagerDuty API functionality to LLMs. This server is designed to be used programmatically, with structured inputs and outputs.\\n\\n<a href=\\\"https://glama.ai/mcp/servers/@wpfleger96/pagerduty-mcp-server\\\">\\n  <img width=\\\"380\\\" height=\\\"200\\\" src=\\\"https://glama.ai/mcp/servers/@wpfleger96/pagerduty-mcp-server/badge\\\" alt=\\\"PagerDuty Server MCP server\\\" />\\n</a>\\n\\n[![PyPI Downloads](https://img.shields.io/pypi/dm/pagerduty-mcp-server.svg)](https://pypi.org/project/pagerduty-mcp-server/)\\n[![Python Versions](https://img.shields.io/pypi/pyversions/pagerduty-mcp-server.svg)](https://pypi.org/project/pagerduty-mcp-server/)\\n[![GitHub Contributors](https://img.shields.io/github/contributors/wpfleger96/pagerduty-mcp-server.svg)](https://github.com/wpfleger96/pagerduty-mcp-server/graphs/contributors)\\n[![PyPI version](https://img.shields.io/pypi/v/pagerduty-mcp-server.svg)](https://pypi.org/project/pagerduty-mcp-server/)\\n[![License](https://img.shields.io/github/license/wpfleger96/pagerduty-mcp-server.svg)](https://github.com/wpfleger96/pagerduty-mcp-server/blob/main/LICENSE)\\n\\n## Overview\\nThe PagerDuty MCP Server provides a set of tools for interacting with the PagerDuty API. These tools are designed to be used by LLMs to perform various operations on PagerDuty resources such as incidents, services, teams, and users.\\n\\n## Installation\\n### From PyPI\\n```bash\\npip install pagerduty-mcp-server\\n```\\n\\n### From Source\\n```sh\\n# Clone the repository\\ngit clone https://github.com/wpfleger96/pagerduty-mcp-server.git\\ncd pagerduty-mcp-server\\n\\n# Install dependencies\\nbrew install uv\\nuv sync\\n```\\n\\n## Requirements\\n- Python 3.13 or higher\\n- PagerDuty API key\\n\\n## Configuration\\nThe PagerDuty MCP Server requires a PagerDuty API key to be set in the environment:\\n```bash\\nPAGERDUTY_API_KEY=your_api_key_here\\n```\\n\\n## Usage\\n### As Goose Extension\\n```json\\n{\\n  \\\"type\\\": \\\"stdio\\\",\\n  \\\"enabled\\\": true,\\n  \\\"args\\\": [\\n    \\\"run\\\",\\n    \\\"python\\\",\\n    \\\"-m\\\",\\n    \\\"pagerduty_mcp_server\\\"\\n  ],\\n  \\\"commandInput\\\": \\\"uv run python -m pagerduty_mcp_server\\\",\\n  \\\"timeout\\\": 300,\\n  \\\"id\\\": \\\"pagerduty-mcp-server\\\",\\n  \\\"name\\\": \\\"pagerduty-mcp-server\\\",\\n  \\\"description\\\": \\\"pagerduty-mcp-server\\\",\\n  \\\"env_keys\\\": [\\n    \\\"PAGERDUTY_API_KEY\\\"\\n  ],\\n  \\\"cmd\\\": \\\"uv\\\"\\n}\\n```\\n\\n### As Standalone Server\\n```sh\\nuv run python -m pagerduty_mcp_server\\n```\\n\\n## Response Format\\nAll API responses follow a consistent format:\\n```json\\n{\\n  \\\"metadata\\\": {\\n    \\\"count\\\": <int>,  // Number of results\\n    \\\"description\\\": \\\"<str>\\\"  // A short summary of the results\\n  },\\n  <resource_type>: [ // Always pluralized for consistency, even if one result is returned\\n    {\\n      ...\\n    },\\n    ...\\n  ],\\n  \\\"error\\\": {  // Only present if there's an error\\n    \\\"message\\\": \\\"<str>\\\",  // Human-readable error description\\n    \\\"code\\\": \\\"<str>\\\"  // Machine-readable error code\\n  }\\n}\\n```\\n\\n### Error Handling\\nWhen an error occurs, the response will include an error object with the following structure:\\n```json\\n{\\n  \\\"metadata\\\": {\\n    \\\"count\\\": 0,\\n    \\\"description\\\": \\\"Error occurred while processing request\\\"\\n  },\\n  \\\"error\\\": {\\n    \\\"message\\\": \\\"Invalid user ID provided\\\",\\n    \\\"code\\\": \\\"INVALID_USER_ID\\\"\\n  }\\n}\\n```\\n\\nCommon error scenarios include:\\n- Invalid resource IDs (e.g., user_id, team_id, service_id)\\n- Missing required parameters\\n- Invalid parameter values\\n- API request failures\\n- Response processing errors\\n\\n### Parameter Validation\\n- All ID parameters must be valid PagerDuty resource IDs\\n- Date parameters must be valid ISO8601 timestamps\\n- List parameters (e.g., `statuses`, `team_ids`) must contain valid values\\n- Invalid values in list parameters will be ignored\\n- Required parameters cannot be `None` or empty strings\\n- For `statuses` in `list_incidents`, only `triggered`, `acknowledged`, and `resolved` are valid values\\n- For `urgency` in incidents, only `high` and `low` are valid values\\n- The `limit` parameter can be used to restrict the number of results returned by list operations\\n\\n### Rate Limiting and Pagination\\n- The server respects PagerDuty's rate limits\\n- The server automatically handles pagination for you\\n- The `limit` parameter can be used to control the number of results returned by list operations\\n- If no limit is specified, the server will return up to {pagerduty_mcp_server.utils.RESPONSE_LIMIT} results by default\\n\\n### Example Usage\\n```python\\nfrom pagerduty_mcp_server import incidents\\nfrom pagerduty_mcp_server.utils import RESPONSE_LIMIT\\n\\n# List all incidents (including resolved) for the current user's teams\\nincidents_list = incidents.list_incidents()\\n\\n# List only active incidents\\nactive_incidents = incidents.list_incidents(statuses=['triggered', 'acknowledged'])\\n\\n# List incidents for specific services\\nservice_incidents = incidents.list_incidents(service_ids=['SERVICE-1', 'SERVICE-2'])\\n\\n# List incidents for specific teams\\nteam_incidents = incidents.list_incidents(team_ids=['TEAM-1', 'TEAM-2'])\\n\\n# List incidents within a date range\\ndate_range_incidents = incidents.list_incidents(\\n    since='2024-03-01T00:00:00Z',\\n    until='2024-\\n[...truncated for length...]\", \"tools\": [{\"name\": \"statuses\", \"description\": \", `team_ids`) must contain valid values\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"amount\": {\"type\": \"number\", \"description\": \"Numeric amount or value\"}}, \"required\": [\"amount\"]}, \"source\": \"readme\", \"access_level\": \"read\"}, {\"name\": \"None\", \"description\": \"or empty strings\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"input\": {\"type\": \"string\", \"description\": \"Input parameter for None\"}}, \"required\": [\"input\"]}, \"source\": \"readme\", \"access_level\": \"read\"}, {\"name\": \"urgency\", \"description\": \"in incidents, only `high` and `low` are valid values\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"amount\": {\"type\": \"number\", \"description\": \"Numeric amount or value\"}}, \"required\": [\"amount\"]}, \"source\": \"readme\", \"access_level\": \"read\"}, {\"name\": \"limit\", \"description\": \"parameter can be used to restrict the number of results returned by list operations\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"input\": {\"type\": \"string\", \"description\": \"Input parameter for limit\"}}, \"required\": [\"input\"]}, \"source\": \"readme\", \"access_level\": \"read\"}, {\"name\": \"current_user_context\", \"description\": \"parameter (defaults to `True`) which automatically filters results based on this context. When `current_user_context` is `True`, you cannot use certain filter parameters as they would conflict with the automatic filtering:\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"message\": {\"type\": \"string\", \"description\": \"Text content or message\"}}, \"required\": [\"message\"]}, \"source\": \"readme\", \"access_level\": \"read\"}, {\"name\": \"user_ids\", \"description\": \"cannot be used with `current_user_context=True`\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"message\": {\"type\": \"string\", \"description\": \"Text content or message\"}}, \"required\": [\"message\"]}, \"source\": \"readme\", \"access_level\": \"read\"}, {\"name\": \"team_ids\", \"description\": \"and `service_ids` cannot be used with `current_user_context=True`\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"message\": {\"type\": \"string\", \"description\": \"Text content or message\"}}, \"required\": [\"message\"]}, \"source\": \"readme\", \"access_level\": \"read\"}, {\"name\": \"schedule_ids\", \"description\": \"can still be used to filter by specific schedules\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"input\": {\"type\": \"string\", \"description\": \"Input parameter for schedule_ids\"}}, \"required\": [\"input\"]}, \"source\": \"readme\", \"access_level\": \"read\"}, {\"name\": \"PAGERDUTY_API_KEY\", \"description\": \"in the environment before running the full test suite.\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"input\": {\"type\": \"string\", \"description\": \"Input parameter for PAGERDUTY_API_KEY\"}}, \"required\": [\"input\"]}, \"source\": \"readme\", \"access_level\": \"execute\"}], \"tools_count\": 9, \"homepage\": \"\", \"url\": \"https://github.com/wpfleger96/pagerduty-mcp-server\", \"topics\": [], \"data_sources\": [\"github\"]}", "target": "", "id": "wpfleger96/pagerduty-mcp-server", "metadata": {"stage": "finance_filter"}}
{"input": "ONLY RESPOND WITH JSON. NO EXPLANATIONS. NO MARKDOWN. NO TEXT OUTSIDE JSON.\n\nAnalyze the MCP server for financial relevance. Look for keywords: payment, banking, credit, loan, finance, money, currency, crypto, investment, trading, portfolio, market, exchange, wallet, account, budget, expense, income, tax, invoice, billing, accounting, insurance, compliance, KYC, AML.\n\nJSON FORMAT (NOTHING ELSE):\n{\n  \"server_name\": \"string\",\n  \"server_id\": \"string\", \n  \"is_finance_llm\": \"yes|no|unclear\",\n  \"confidence\": \"high|medium|low\",\n  \"threat_models\": [],\n  \"analysis_notes\": \"Brief reason\"\n}\n\nIf financial keywords found: is_finance_llm=\"yes\". If not: is_finance_llm=\"no\". If unclear: is_finance_llm=\"unclear\".\n\nRESPOND ONLY WITH JSON.\n\nMCP Server Data:\n{\"server_name\": \"awsome_kali_MCPServers\", \"server_id\": \"ccq1/awsome_kali_mcpservers\", \"description\": \"awsome kali MCPServers is a set of MCP servers tailored for Kali Linux, designed to empower AI Agents in reverse engineering and security testing. It offers flexible network analysis, target sniffing, traffic analysis, binary understanding, and automation, enhancing AI-driven workflows.\", \"readme\": \"# awsome-kali-MCPServers\\n\\n## Overview\\nWelcome to awsome-kali-MCPServers! This repository is a collection of Model Context Protocol (MCP) servers designed specifically for Kali Linux environments. The goal is to enhance reverse engineering, security testing, and automation workflows by integrating powerful tools and flexible features. Whether you're a security researcher or a developer, this project aims to streamline your tasks with Kali Linux.\\n\\n## Quick Start\\nFollow these steps to quickly get started with `kali-mcps`:\\n1. **Build the Docker Image**\\nFirst, build the Docker image, temporarily named kali-mcps. Run the following command in the project root directory:\\n```bash\\ndocker build -t kali-mcps:latest .\\n```\\n2. **Launch an MCP Client**\\nEnsure you have an MCP client installed, such as claude desktop, cline, goose, or roo code. Open your chosen MCP client.\\n3. **Configure the MCP Client**\\nIn your MCP client, create a configuration file (e.g., config.json) with the following content:\\n```json\\n{\\n  \\\"mcpServers\\\": {\\n    \\\"kali-docker\\\": {\\n      \\\"command\\\": \\\"docker\\\",\\n      \\\"args\\\": [\\\"run\\\", \\\"-i\\\", \\\"kali-mcps:latest\\\"]\\n    }\\n  }\\n}\\n```\\n- `\\\"kali-docker\\\"` is the server name, which you can customize.\\n- `\\\"command\\\": \\\"docker\\\"` specifies that Docker will be used to run the container.\\n- `\\\"args\\\"` defines the Docker run parameters: `-i` enables interactive mode, and `kali-mcps:latest` is the image you just built.\\n\\n4. **Use Kali Tools**\\nOnce configured, connect to the kali-mcps container via the MCP client and start using the built-in Kali tools (e.g., Nmap, nm, objdump, strings, tshark) for your tasks. Examples include:\\n- Run `basic_scan` for basic network scanning.\\n- Run `disassemble` to disassemble a target file.\\n- Run `capture_live` to capture real-time network traffic.\\n\\n<p align=\\\"center\\\">\\n  <img width=\\\"482\\\" alt=\\\"image\\\" src=\\\"https://github.com/user-attachments/assets/0e9fff0a-059d-424b-bb36-450a1d11adf9\\\" />\\n</p>\\n\\n## What to Expect\\nNetwork Analysis: Tools for sniffing and analyzing traffic.\\nBinary Understanding: Support for reverse engineering and function analysis.\\nAutomation: Scripts and servers to simplify repetitive tasks.\\n\\n## New Features\\nSince the last update, we have added the following features, integrating a series of tools based on the FastMCP framework:\\n\\n### 1. Network Scanning (Nmap)\\n- `basic_scan`: Basic network scanning.\\n- `intense_scan`: In-depth network scanning.\\n- `stealth_scan`: Stealth network scanning.\\n- `quick_scan`: Quick network scanning.\\n- `vulnerability_scan`: Vulnerability scanning.\\n\\n### 2. Symbol Analysis (nm)\\n- `basic_symbols`: Lists basic symbols.\\n- `dynamic_symbols`: Lists dynamic symbols.\\n- `demangle_symbols`: Decodes symbols.\\n- `numeric_sort`: Sorts symbols numerically.\\n- `size_sort`: Sorts symbols by size.\\n- `undefined_symbols`: Lists undefined symbols.\\n\\n### 3. Binary Analysis (objdump)\\n- `file_headers`: Lists file headers.\\n- `disassemble`: Disassembles the target file.\\n- `symbol_table`: Lists the symbol table.\\n- `section_headers`: Lists section headers.\\n- `full_contents`: Lists full contents.\\n\\n### 4. String Extraction (strings)\\n- `basic_strings`: Basic string extraction.\\n- `min_length_strings`: Extracts strings with a specified minimum length.\\n- `offset_strings`: Extracts strings with offsets.\\n- `encoding_strings`: Extracts strings based on encoding.\\n\\n### 5. Network Traffic Analysis (Wireshark/tshark)\\n- `capture_live`: Captures network traffic in real-time.\\n- `analyze_pcap`: Analyzes pcap files.\\n- `extract_http`: Extracts HTTP data.\\n- `protocol_hierarchy`: Lists protocol hierarchy.\\n- `conversation_statistics`: Provides conversation statistics.\\n- `expert_info`: Analyzes expert information.\\n### 6. Sandbox Support (Docker)\\nA new sandbox feature has been added, enabling secure command execution in an isolated container environment:\\n\\nRuns commands using Docker containers, with the default image being ubuntu-systemd:22.04.\\nConfigurable memory limit (default: 2GB), CPU limit (default: 1 core), network mode, and timeout duration.\\nSupports bidirectional file copying between the host and the container.\\nAutomatically cleans up container resources.\\n\\n\\n## TODO\\n- [ ] **Docker Sandbox Support**: Add containerized environments for safe testing and execution.\\n- [ ] **Network Tools Integration**: Support for tools like Nmap and Wireshark for advanced network analysis.\\n- [ ] **Reverse Engineering Tools**: Integrate Ghidra and Radare2 for enhanced binary analysis.\\n- [ ] **Agent Support**: Enable agent-based functionality for distributed tasks or remote operations.\\n \\n## Current Status\\nThis project is still in its early stages. I\\u2019m working on preparing the content, including server configurations, tool integrations, and documentation. Nothing is fully ready yet, but stay tuned\\u2014exciting things are coming soon!\\n\\n## Stay Updated\\nFeel free to star or watch this repository to get updates as I add more features and files. Contributions and suggestions are welcome once the groundwork is laid out.\\n\", \"tools\": [{\"name\": \"basic_scan\", \"description\": \"for basic network scanning.\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"input\": {\"type\": \"string\", \"description\": \"Input parameter for basic_scan\"}}, \"required\": [\"input\"]}, \"source\": \"readme\", \"access_level\": \"read\"}, {\"name\": \"disassemble\", \"description\": \"to disassemble a target file.\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"file_path\": {\"type\": \"string\", \"description\": \"File path or file to process\"}}, \"required\": [\"file_path\"]}, \"source\": \"readme\", \"access_level\": \"read\"}, {\"name\": \"capture_live\", \"description\": \"to capture real-time network traffic.\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"input\": {\"type\": \"string\", \"description\": \"Input parameter for capture_live\"}}, \"required\": [\"input\"]}, \"source\": \"readme\", \"access_level\": \"read\"}, {\"name\": \"intense_scan\", \"description\": \"In-depth network scanning.\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"input\": {\"type\": \"string\", \"description\": \"Input parameter for intense_scan\"}}, \"required\": [\"input\"]}, \"source\": \"readme\", \"access_level\": \"read\"}, {\"name\": \"stealth_scan\", \"description\": \"Stealth network scanning.\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"input\": {\"type\": \"string\", \"description\": \"Input parameter for stealth_scan\"}}, \"required\": [\"input\"]}, \"source\": \"readme\", \"access_level\": \"read\"}, {\"name\": \"quick_scan\", \"description\": \"Quick network scanning.\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"input\": {\"type\": \"string\", \"description\": \"Input parameter for quick_scan\"}}, \"required\": [\"input\"]}, \"source\": \"readme\", \"access_level\": \"read\"}, {\"name\": \"vulnerability_scan\", \"description\": \"Vulnerability scanning.\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"input\": {\"type\": \"string\", \"description\": \"Input parameter for vulnerability_scan\"}}, \"required\": [\"input\"]}, \"source\": \"readme\", \"access_level\": \"read\"}, {\"name\": \"basic_symbols\", \"description\": \"Lists basic symbols.\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"input\": {\"type\": \"string\", \"description\": \"Input parameter for basic_symbols\"}}, \"required\": [\"input\"]}, \"source\": \"readme\", \"access_level\": \"read\"}, {\"name\": \"dynamic_symbols\", \"description\": \"Lists dynamic symbols.\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"input\": {\"type\": \"string\", \"description\": \"Input parameter for dynamic_symbols\"}}, \"required\": [\"input\"]}, \"source\": \"readme\", \"access_level\": \"read\"}, {\"name\": \"demangle_symbols\", \"description\": \"Decodes symbols.\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"input\": {\"type\": \"string\", \"description\": \"Input parameter for demangle_symbols\"}}, \"required\": [\"input\"]}, \"source\": \"readme\", \"access_level\": \"read\"}, {\"name\": \"numeric_sort\", \"description\": \"Sorts symbols numerically.\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"input\": {\"type\": \"string\", \"description\": \"Input parameter for numeric_sort\"}}, \"required\": [\"input\"]}, \"source\": \"readme\", \"access_level\": \"read\"}, {\"name\": \"size_sort\", \"description\": \"Sorts symbols by size.\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"input\": {\"type\": \"string\", \"description\": \"Input parameter for size_sort\"}}, \"required\": [\"input\"]}, \"source\": \"readme\", \"access_level\": \"read\"}, {\"name\": \"undefined_symbols\", \"description\": \"Lists undefined symbols.\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"input\": {\"type\": \"string\", \"description\": \"Input parameter for undefined_symbols\"}}, \"required\": [\"input\"]}, \"source\": \"readme\", \"access_level\": \"read\"}, {\"name\": \"file_headers\", \"description\": \"Lists file headers.\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"file_path\": {\"type\": \"string\", \"description\": \"File path or file to process\"}}, \"required\": [\"file_path\"]}, \"source\": \"readme\", \"access_level\": \"read\"}, {\"name\": \"symbol_table\", \"description\": \"Lists the symbol table.\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"input\": {\"type\": \"string\", \"description\": \"Input parameter for symbol_table\"}}, \"required\": [\"input\"]}, \"source\": \"readme\", \"access_level\": \"read\"}, {\"name\": \"section_headers\", \"description\": \"Lists section headers.\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"input\": {\"type\": \"string\", \"description\": \"Input parameter for section_headers\"}}, \"required\": [\"input\"]}, \"source\": \"readme\", \"access_level\": \"read\"}, {\"name\": \"full_contents\", \"description\": \"Lists full contents.\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"message\": {\"type\": \"string\", \"description\": \"Text content or message\"}}, \"required\": [\"message\"]}, \"source\": \"readme\", \"access_level\": \"read\"}, {\"name\": \"basic_strings\", \"description\": \"Basic string extraction.\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"input\": {\"type\": \"string\", \"description\": \"Input parameter for basic_strings\"}}, \"required\": [\"input\"]}, \"source\": \"readme\", \"access_level\": \"read\"}, {\"name\": \"min_length_strings\", \"description\": \"Extracts strings with a specified minimum length.\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"input\": {\"type\": \"string\", \"description\": \"Input parameter for min_length_strings\"}}, \"required\": [\"input\"]}, \"source\": \"readme\", \"access_level\": \"read\"}, {\"name\": \"offset_strings\", \"description\": \"Extracts strings with offsets.\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"input\": {\"type\": \"string\", \"description\": \"Input parameter for offset_strings\"}}, \"required\": [\"input\"]}, \"source\": \"readme\", \"access_level\": \"write\"}, {\"name\": \"encoding_strings\", \"description\": \"Extracts strings based on encoding.\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"input\": {\"type\": \"string\", \"description\": \"Input parameter for encoding_strings\"}}, \"required\": [\"input\"]}, \"source\": \"readme\", \"access_level\": \"read\"}, {\"name\": \"analyze_pcap\", \"description\": \"Analyzes pcap files.\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"file_path\": {\"type\": \"string\", \"description\": \"File path or file to process\"}}, \"required\": [\"file_path\"]}, \"source\": \"readme\", \"access_level\": \"read\"}, {\"name\": \"extract_http\", \"description\": \"Extracts HTTP data.\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"input\": {\"type\": \"string\", \"description\": \"Input parameter for extract_http\"}}, \"required\": [\"input\"]}, \"source\": \"readme\", \"access_level\": \"read\"}, {\"name\": \"protocol_hierarchy\", \"description\": \"Lists protocol hierarchy.\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"input\": {\"type\": \"string\", \"description\": \"Input parameter for protocol_hierarchy\"}}, \"required\": [\"input\"]}, \"source\": \"readme\", \"access_level\": \"read\"}, {\"name\": \"conversation_statistics\", \"description\": \"Provides conversation statistics.\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"input\": {\"type\": \"string\", \"description\": \"Input parameter for conversation_statistics\"}}, \"required\": [\"input\"]}, \"source\": \"readme\", \"access_level\": \"read\"}, {\"name\": \"expert_info\", \"description\": \"Analyzes expert information.\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"input\": {\"type\": \"string\", \"description\": \"Input parameter for expert_info\"}}, \"required\": [\"input\"]}, \"source\": \"readme\", \"access_level\": \"read\"}], \"tools_count\": 26, \"homepage\": \"\", \"url\": \"https://github.com/ccq1/awsome_kali_MCPServers\", \"topics\": [\"agent\", \"kali-linux\", \"llm\", \"mcp-server\", \"security\", \"tools\"], \"data_sources\": [\"github\"]}", "target": "", "id": "ccq1/awsome_kali_mcpservers", "metadata": {"stage": "finance_filter"}}
{"input": "ONLY RESPOND WITH JSON. NO EXPLANATIONS. NO MARKDOWN. NO TEXT OUTSIDE JSON.\n\nAnalyze the MCP server for financial relevance. Look for keywords: payment, banking, credit, loan, finance, money, currency, crypto, investment, trading, portfolio, market, exchange, wallet, account, budget, expense, income, tax, invoice, billing, accounting, insurance, compliance, KYC, AML.\n\nJSON FORMAT (NOTHING ELSE):\n{\n  \"server_name\": \"string\",\n  \"server_id\": \"string\", \n  \"is_finance_llm\": \"yes|no|unclear\",\n  \"confidence\": \"high|medium|low\",\n  \"threat_models\": [],\n  \"analysis_notes\": \"Brief reason\"\n}\n\nIf financial keywords found: is_finance_llm=\"yes\". If not: is_finance_llm=\"no\". If unclear: is_finance_llm=\"unclear\".\n\nRESPOND ONLY WITH JSON.\n\nMCP Server Data:\n{\"server_name\": \"agent\", \"server_id\": \"1mcp-app/agent\", \"description\": \"A unified Model Context Protocol server implementation that aggregates multiple MCP servers into one.\", \"readme\": \"# 1MCP - One MCP Server for All\\n\\nA unified Model Context Protocol server implementation that aggregates multiple MCP servers into one.\\n\\n[![NPM Version](https://img.shields.io/npm/v/@1mcp/agent)](https://www.npmjs.com/package/@1mcp/agent)\\n[![NPM License](https://img.shields.io/npm/l/@1mcp/agent)](https://www.npmjs.com/package/@1mcp/agent)\\n[![smithery badge](https://smithery.ai/badge/@1mcp-app/agent)](https://smithery.ai/server/@1mcp-app/agent)\\n\\n## Overview\\n\\n1MCP (One MCP) is designed to simplify the way you work with AI assistants. Instead of configuring multiple MCP servers for different clients (Claude Desktop, Cherry Studio, Cursor, Roo Code, Claude, etc.), 1MCP provides a single, unified server that:\\n\\n- Aggregates multiple MCP servers into one unified interface\\n- Reduces system resource usage by eliminating redundant server instances\\n- Simplifies configuration management across different AI assistants\\n- Provides a standardized way for AI models to interact with external tools and resources\\n- Supports dynamic configuration reloading without server restart\\n- Handles graceful shutdown and resource cleanup\\n\\n## Quick Start\\n\\nTo enable Cursor to use existing MCP servers already configured in Claude Desktop, follow these steps:\\n\\n1. Run the 1MCP server with the Claude Desktop config file:\\n```bash\\nnpx -y @1mcp/agent --config ~/Library/Application\\\\ Support/Claude/claude_desktop_config.json\\n```\\n\\n2. Add the 1MCP server to your Cursor config file (`~/.cursor/mcp.json`):\\n```json\\n{\\n    \\\"mcpServers\\\": {\\n        \\\"1mcp\\\": {\\n            \\\"type\\\": \\\"http\\\",\\n            \\\"url\\\": \\\"http://localhost:3050/sse\\\"\\n        }\\n    }\\n}\\n```\\n\\n3. Enjoy it!\\n\\n## Usage\\n\\nYou can run the server directly using `npx`:\\n\\n```bash\\n# Basic usage (starts server with SSE transport)\\nnpx -y @1mcp/agent\\n\\n# Use existing Claude Desktop config\\nnpx -y @1mcp/agent --config ~/Library/Application\\\\ Support/Claude/claude_desktop_config.json\\n\\n# Use stdio transport instead of SSE\\nnpx -y @1mcp/agent --transport stdio\\n\\n# Show all available options\\nnpx -y @1mcp/agent --help\\n```\\n\\nAvailable options:\\n- `--transport, -t`: Choose transport type (\\\"stdio\\\" or \\\"http\\\", default: \\\"http\\\")\\n- `--config, -c`: Use a specific config file\\n- `--port, -P`: Change HTTP port (default: 3050)\\n- `--host, -H`: Change HTTP host (default: localhost)\\n- `--tags, -g`: Filter servers by tags (see Tags section below)\\n- `--help, -h`: Show help\\n\\nExample with environment variables:\\n```bash\\n# Using environment variables\\nONE_MCP_PORT=3051 ONE_MCP_TAGS=network,filesystem npx -y @1mcp/agent\\n\\n# Or in your shell configuration\\nexport ONE_MCP_PORT=3051\\nexport ONE_MCP_TAGS=network,filesystem\\nnpx -y @1mcp/agent\\n```\\n\\n## Docker\\n\\nYou can also run 1MCP using Docker:\\n\\n```bash\\n# Pull the latest image\\ndocker pull ghcr.io/1mcp-app/agent:latest\\n\\n# Run with HTTP transport (default)\\ndocker run -p 3050:3050 ghcr.io/1mcp-app/agent\\n\\n# Run with a custom config file\\ndocker run -p 3050:3050 -v /path/to/config.json:/config.json ghcr.io/1mcp-app/agent --config /config.json\\n\\n# Run with stdio transport\\ndocker run -i ghcr.io/1mcp-app/agent --transport stdio\\n```\\n\\nAvailable image tags:\\n- `latest`: Latest stable release\\n- `vX.Y.Z`: Specific version (e.g. `v1.0.0`)\\n- `sha-<commit>`: Specific commit\\n\\n### Environment Variables\\n\\nYou can configure 1MCP using environment variables prefixed with `ONE_MCP_`:\\n- `ONE_MCP_TRANSPORT`: Transport type (\\\"stdio\\\" or \\\"http\\\", default: \\\"http\\\")\\n- `ONE_MCP_PORT`: HTTP port (default: 3050)\\n- `ONE_MCP_HOST`: HTTP host (default: \\\"localhost\\\")\\n- `ONE_MCP_CONFIG`: Path to config file\\n- `ONE_MCP_TAGS`: Comma-separated list of tags to filter servers\\n\\nExample with environment variables:\\n```bash\\ndocker run -p 3051:3051 \\\\\\n  -e ONE_MCP_PORT=3051 \\\\\\n  -e ONE_MCP_TAGS=network,filesystem \\\\\\n  ghcr.io/1mcp-app/agent\\n```\\n\\n### Understanding Tags\\n\\nTags help you control which MCP servers are available to different clients. Think of tags as labels that describe what each server can do.\\n\\n#### How to Use Tags\\n\\n1. **In your server config**: Add tags to each server to describe its capabilities\\n```json\\n{\\n  \\\"mcpServers\\\": {\\n    \\\"web-server\\\": {\\n      \\\"command\\\": \\\"uvx\\\",\\n      \\\"args\\\": [\\\"mcp-server-fetch\\\"],\\n      \\\"tags\\\": [\\\"network\\\", \\\"web\\\"],\\n      \\\"disabled\\\": false\\n    },\\n    \\\"file-server\\\": {\\n      \\\"command\\\": \\\"npx\\\",\\n      \\\"args\\\": [\\\"-y\\\", \\\"@modelcontextprotocol/server-filesystem\\\", \\\"~/Downloads\\\"],\\n      \\\"tags\\\": [\\\"filesystem\\\"],\\n      \\\"disabled\\\": false\\n    }\\n  }\\n}\\n```\\n\\n2. **When starting 1MCP in stdio mode**: You can filter servers by tags\\n```bash\\n# Only start servers with the \\\"network\\\" tag\\nnpx -y @1mcp/agent --transport stdio --tags \\\"network\\\"\\n\\n# Start servers with either \\\"network\\\" or \\\"filesystem\\\" tags\\nnpx -y @1mcp/agent --transport stdio --tags \\\"network,filesystem\\\"\\n```\\n\\n3. **When using SSE transport**: Clients can request servers with specific tags\\n```json\\n{\\n    \\\"mcpServers\\\": {\\n        \\\"1mcp\\\": {\\n            \\\"type\\\": \\\"http\\\",\\n            \\\"url\\\": \\\"http://localhost:3050/sse?tags=network\\\"  // Only connect to network-capable servers\\n        }\\n    }\\n}\\n```\\n\\nExample tags\\n[...truncated for length...]\", \"tools\": [{\"name\": \"npx\", \"description\": \"```bash\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"input\": {\"type\": \"string\", \"description\": \"Input parameter for npx\"}}, \"required\": [\"input\"]}, \"source\": \"readme\", \"access_level\": \"read\"}, {\"name\": \"latest\", \"description\": \"Latest stable release\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"input\": {\"type\": \"string\", \"description\": \"Input parameter for latest\"}}, \"required\": [\"input\"]}, \"source\": \"readme\", \"access_level\": \"read\"}, {\"name\": \"ONE_MCP_\", \"description\": \"- `ONE_MCP_TRANSPORT`: Transport type (\\\"stdio\\\" or \\\"http\\\", default: \\\"http\\\")\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"input\": {\"type\": \"string\", \"description\": \"Input parameter for ONE_MCP_\"}}, \"required\": [\"input\"]}, \"source\": \"readme\", \"access_level\": \"read\"}, {\"name\": \"ONE_MCP_PORT\", \"description\": \"HTTP port (default: 3050)\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"input\": {\"type\": \"string\", \"description\": \"Input parameter for ONE_MCP_PORT\"}}, \"required\": [\"input\"]}, \"source\": \"readme\", \"access_level\": \"read\"}, {\"name\": \"ONE_MCP_HOST\", \"description\": \"HTTP host (default: \\\"localhost\\\")\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"input\": {\"type\": \"string\", \"description\": \"Input parameter for ONE_MCP_HOST\"}}, \"required\": [\"input\"]}, \"source\": \"readme\", \"access_level\": \"read\"}, {\"name\": \"ONE_MCP_CONFIG\", \"description\": \"Path to config file\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"file_path\": {\"type\": \"string\", \"description\": \"File path or file to process\"}}, \"required\": [\"file_path\"]}, \"source\": \"readme\", \"access_level\": \"read\"}, {\"name\": \"ONE_MCP_TAGS\", \"description\": \"Comma-separated list of tags to filter servers\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"input\": {\"type\": \"string\", \"description\": \"Input parameter for ONE_MCP_TAGS\"}}, \"required\": [\"input\"]}, \"source\": \"readme\", \"access_level\": \"read\"}, {\"name\": \"network\", \"description\": \"For servers that make web requests\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"input\": {\"type\": \"string\", \"description\": \"Input parameter for network\"}}, \"required\": [\"input\"]}, \"source\": \"readme\", \"access_level\": \"write\"}, {\"name\": \"filesystem\", \"description\": \"For servers that handle file operations\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"file_path\": {\"type\": \"string\", \"description\": \"File path or file to process\"}}, \"required\": [\"file_path\"]}, \"source\": \"readme\", \"access_level\": \"read\"}, {\"name\": \"memory\", \"description\": \"For servers that provide memory/storage\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"input\": {\"type\": \"string\", \"description\": \"Input parameter for memory\"}}, \"required\": [\"input\"]}, \"source\": \"readme\", \"access_level\": \"read\"}, {\"name\": \"shell\", \"description\": \"For servers that run shell commands\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"input\": {\"type\": \"string\", \"description\": \"Input parameter for shell\"}}, \"required\": [\"input\"]}, \"source\": \"readme\", \"access_level\": \"execute\"}, {\"name\": \"db\", \"description\": \"For servers that handle database operations\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"input\": {\"type\": \"string\", \"description\": \"Input parameter for db\"}}, \"required\": [\"input\"]}, \"source\": \"readme\", \"access_level\": \"read\"}, {\"name\": \"ONE_MCP_TRANSPORT\", \"description\": \"Transport type (\\\"stdio\\\" or \\\"http\\\", default: \\\"http\\\")\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"input\": {\"type\": \"string\", \"description\": \"Input parameter for ONE_MCP_TRANSPORT\"}}, \"required\": [\"input\"]}, \"source\": \"readme\", \"access_level\": \"read\"}], \"tools_count\": 13, \"homepage\": \"\", \"url\": \"https://github.com/1mcp-app/agent\", \"topics\": [\"mcp\", \"mcp-client\", \"mcp-gateway\", \"mcp-server\", \"unified-mcp-server\"], \"data_sources\": [\"github\"]}", "target": "", "id": "1mcp-app/agent", "metadata": {"stage": "finance_filter"}}
{"input": "ONLY RESPOND WITH JSON. NO EXPLANATIONS. NO MARKDOWN. NO TEXT OUTSIDE JSON.\n\nAnalyze the MCP server for financial relevance. Look for keywords: payment, banking, credit, loan, finance, money, currency, crypto, investment, trading, portfolio, market, exchange, wallet, account, budget, expense, income, tax, invoice, billing, accounting, insurance, compliance, KYC, AML.\n\nJSON FORMAT (NOTHING ELSE):\n{\n  \"server_name\": \"string\",\n  \"server_id\": \"string\", \n  \"is_finance_llm\": \"yes|no|unclear\",\n  \"confidence\": \"high|medium|low\",\n  \"threat_models\": [],\n  \"analysis_notes\": \"Brief reason\"\n}\n\nIf financial keywords found: is_finance_llm=\"yes\". If not: is_finance_llm=\"no\". If unclear: is_finance_llm=\"unclear\".\n\nRESPOND ONLY WITH JSON.\n\nMCP Server Data:\n{\"server_name\": \"SSE-MCP-Toolkit\", \"server_id\": \"kayz3nn/sse-mcp-toolkit\", \"description\": \"All you need to build your own SSE MCP Clients and Servers to equip any LLM agent with all kinds of tools.\", \"readme\": \"# SSE-MCP-Toolkit\\n\\nAll you need to build your own SSE MCP Clients and Servers to equip any LLM agent with all kinds of tools.\\n\\n# Features\\n\\n- [**McpSseClient**](./src/mcp_sse_client/client.py): A client that connects to an SSE MCP server and provides a simple interface to interact with the server. Its abilities include:\\n\\n  - Opening and closing connections to the server\\n  - Registering available MCP server tools\\n  - Processing prompts\\n  - Executing returned tool calls\\n\\n- [**McpSseServer**](./src/mcp_sse_server/server.py): An SSE MCP server template that provides tools to the implemented LLM agents. Its abilities include:\\n\\n  - Make your own tools/functions and expose them using the mcp tool decorator\\n  - List available tools to the MCP client\\n  - Run an MCP SSE Server using [Starlette]() and [uvicorn]() on the specified port\\n  - Can be started using `python ./mcp_sse_server/server.py`\\n\\n- [**OllamaAgent**](./src/ollama_agent/agent.py): An agent that uses Ollama's LLMs to process prompts and return tool calls. It provides:\\n  - A simple interface to send prompts to a locally ran Ollama LLM\\n  - Support for tools integration: you can provide the tools to the LLM either directly or from the MCP server\\n  - Returns the tool calls to the MCP client for execution\\n  - Support for chat history to provide context for the LLM\\n  - [**OllamaToolsRegistry**](./src/ollama_agent/tools_registry.py): A registry to manage tools for the Ollama agent. It currently allows you to parse MCP Tools, which are mainly tailored to Claude, to a format that Ollama can understand.\\n\\n# Implementation Examples\\n\\n- [**Console MCP Client**](./console_mcp_client.py): A simple console client that connects to an MCP server and allows you to interact with it using the command line. It provides a basic interface to send prompts and receive tool calls.\\n\\nRun it using `python console_mcp_client.py` after starting the MCP server.\\n\\n- [**Streamlit MCP Client**](./streamlit_mcp_client.py): A Streamlit application that connects to an MCP server and provides a web interface to interact with it. It allows you to send prompts and receive tool calls in a user-friendly way.\\n\\nRun it using `streamlit run streamlit_mcp_client.py` after starting the MCP server.\\n\\n# Installation\\n\\nFirst start a virtual environment and install the required packages:\\n\\n```bash\\npython -m venv venv\\nsource venv/bin/activate  # On Windows use `. ./venv/Scripts/activate`\\npip install -r requirements.txt\\n```\\n\\n# Usage\\n\\n_Note: Make sure you have a running LLM model, i.e. Ollama llama3.2 that is the default in this repo, and a running MCP server before starting the clients._\\n\\nTo run the MCP server, use the following command:\\n\\n```bash\\npython .\\\\src\\\\mcp_sse_servers\\\\sse-server.py\\n```\\n\\nTo run the console MCP client, use the following command:\\n\\n```bash\\npython console_mcp_client.py\\n```\\n\\nTo run the Streamlit MCP client, use the following command:\\n\\n```bash\\nstreamlit run streamlit_mcp_client.py\\n```\\n\\n# Screenshots\\n\\n## **Streamlit MCP Client**\\n\\n![Streamlit MCP Client](./screenshots/streamlit_mcp_client.jpg)\\n\\n## **Console MCP Client**\\n\\n![Console MCP Client](./screenshots/console_mcp_client.jpg)\\n\\n# License\\n\\nThis project is licensed under the MIT License - see the [LICENSE](./LICENSE) file for details.\\n\\n# Contributing\\n\\nContributions are welcome! Feel free to open issues or pull requests.\\n\", \"tools\": [], \"tools_count\": 0, \"homepage\": \"\", \"url\": \"https://github.com/kayz3nn/SSE-MCP-Toolkit\", \"topics\": [], \"data_sources\": [\"github\"]}", "target": "", "id": "kayz3nn/sse-mcp-toolkit", "metadata": {"stage": "finance_filter"}}
{"input": "ONLY RESPOND WITH JSON. NO EXPLANATIONS. NO MARKDOWN. NO TEXT OUTSIDE JSON.\n\nAnalyze the MCP server for financial relevance. Look for keywords: payment, banking, credit, loan, finance, money, currency, crypto, investment, trading, portfolio, market, exchange, wallet, account, budget, expense, income, tax, invoice, billing, accounting, insurance, compliance, KYC, AML.\n\nJSON FORMAT (NOTHING ELSE):\n{\n  \"server_name\": \"string\",\n  \"server_id\": \"string\", \n  \"is_finance_llm\": \"yes|no|unclear\",\n  \"confidence\": \"high|medium|low\",\n  \"threat_models\": [],\n  \"analysis_notes\": \"Brief reason\"\n}\n\nIf financial keywords found: is_finance_llm=\"yes\". If not: is_finance_llm=\"no\". If unclear: is_finance_llm=\"unclear\".\n\nRESPOND ONLY WITH JSON.\n\nMCP Server Data:\n{\"server_name\": \"GooseTeam\", \"server_id\": \"cliffhall/gooseteam\", \"description\": \"Look, a flock of geese! An MCP server and protocol for Goose agent collaboration.\", \"readme\": \"# GooseTeam\\n![GooseTeam Logo](images/GooseTeam.png)\\n\\n## Enabling Goose Agents to Collaborate\\n### **Protocol:** \\nAn operational procedure for agents to follow, expressed in two flavors:\\n  - [**Natural Language**](instructions/protocol-as-text.md): Streamlined, human-readable instructions about how to behave and use the tools.\\n  - [**Mermaid Markdown**](instructions/protocol-as-chart.md): A concise flowchart for expected behavior, described in an efficient text format.\\n\\n### **Extension:** \\nGoose extension ([MCP Server](https://github.com/modelcontextprotocol)) that provides tools for the agents to use for tasks and messaging.\\n  - **Agent Registration:** Facilitates agent registration with unique ID assignments and message sending.\\n  - **Message Management:** Stores messages from agents, making them available for retrieval.\\n  - **Task Management:** Project Coordinator role creates and assigns tasks and roles to other agents. \\n  - **Agent Waiting:** Allows connected agents to wait for a specified period before taking another action. \\n  - **Remote Server:** With an MCP Proxy, multiple agents can connect to the same MCP server, necessary for collaboration.\\n\\n### Work in Progress\\n* Current focus is on [Goose CLI](https://block.github.io/goose/docs/getting-started/installation/) integration, so you must have it installed. \\n  * Other agent platforms could integrate with this project easily. \\n  * The protocol and the MCP server are not tightly coupled to goose, only the npm `agent:` scripts and in the protocol preamble.\\n\\n## NEW: Behavioral Control with Mermaid markdown!\\n* Agent protocol expressed as a [mermaid chart](https://mermaid.live/edit#pako:eNp1VG1v2jAQ_isnf-kX2hVKAkRTJwSbhjRa1FJVW0CVl5gQQWxmO3Rdyn_f2YkTyrp8iM5399w992IXJBIxIwFJJN2tYT5ecMDvXlOpQ_tfwvn5NdyxJFWaydAJQBPG9cef8sO1FpAwDZPxsgTXLgY4ZihlKWezUVjLFhblUmIImI0QVyKPnC14omajYaTTPSsmCvSaSQaUWzS1agR_OpTYxtdAX2_EK8zpht3ukbQRQOwNa4UQG-Ce8TiAswnQDLh4NtHRdLZ8N9p3pl7hmxA7x9SFtjSNIfzMTclbFOtyjN46jNYs2kyZUtg0FdoTSBa5BmaVpcr9xtviZ1JEeK4jVGdwwMCGOYeHXUw1g-wFNFWbSnkjULXOM8oh5UrLHMsSXL2FYMOVpjpXkK4gWlOesLiu4yR9NZopTqkYZjCpWtcMYlrNr2zblHJEzZGQCkvZsqtJu2L-S3GoVJrwEgS4bHbznPGOqZ3gsdFL9itnSqvlPzzMMnyle0uiMAJUy1fuL2oN-RLm_JoCHoXc3HKjC40IouSyfMffJBqqzRchrTuKprMrIZuBVHs32zKqcJvL2jKUrMtZ3fQma9Xvkch2W7wgxdyFiipN03nn05B3GstnSpG-SQMOauM8KBbUmqej2k4CmuoeaapD84MOKBZh61UTw07m6dla60KOGdhSDLo0Na06MRztzInFpnaXjrRIhg8GTWN8wQrjsCC4jBlbkADFmK1ovtULsuAHdKW5FvcvPCIBbhhrESnyZE2CFd0qPOX2IoxTii9hVmt3lP8QInMQPJKgIL9J0O56F12v3en6V_1u3-u3ey3yQgJ_cNG76vg9r-O3_atev3dokT82wOWF1-l2PG_g9QcD37v0-4e_wqjSEw).\\n\\n* See if your favorite LLM can follow it using the [`agent:chart`](#agent---protocol-as-chart) script to launch your agent!\\n\\n## Screenshots\\n### GooseTeam Protocol as a Chart\\n![goose-protocol-chart.png](images/goose-team-protocol-chart.png)\\n\\n### GPT-4o Says OK to this as a control mechanism\\n![Goose PC Follows Mermaid](images/mermaid-ok-sez-gpt-4o.png)\\n\\n### Goose Agents\\n![Goose Agents](images/goose-agents.png)\\n\\n### Inspector - List Tools\\n![Inspector](images/inspector.png)\\n\\n### Inspector - Add Message\\n![inspector-add-message.png](images/inspector-add-message.png)\\n\\n### Inspector - List Tasks\\n![inspector-list-tasks.png](images/inspector-list-tasks.png)\\n\\n## How to Run \\n### Tell Goose about the extension\\n* Run `goose configure`\\n* Choose **[Add Extension]()**\\n* Choose **Remote Extension**\\n* Enter `goose-team` for name\\n* Enter http://localhost:3001/sse for SSE endpoint URI\\n\\n### Run these npm scripts in order:\\n* First, clone this repo to your local machine and [install dependencies](#install-dependencies)\\n* `npm run build` - to build the server from source.\\n* `npm run mcp-proxy` to start an SSE proxy to talk to a single instance of the goose-team MCP server,\\n* `npm run inspector` to launch the MCP inspector in a browser \\n  * Here you click **connect**, then `list_tools`, then `add_message`, then from `Human` send a message describing a task or project for the team to work on.\\n* `npm run agent` to launch an agent that will read the protocol and instructions, connect to the `goose-team` server, assign itself as project coordinator, then begin creating tasks.\\n  * In the inspector window, click `list_tasks` to see the tasks it is adding, \\n  * When there are some tasks, you can `npm run agent` again and again to launch agents to be assigned tasks by the Project Coordinator.\\n\\n## Troubleshooting\\n### HOW WELL GOOSE TEAM WORKS DEPENDS ON THE MODEL!!!\\nFollow these steps to test if you have a model that will work.\\n* `npm run build` - to build the server from source.\\n* `npm run mcp-proxy` to start an SSE proxy to talk to a single instance of the goose-team MCP server,\\n* `npm run agent:test` This launches an agent hitting the same MCP, but it has a simpler protocol: Say hello in a different language, wait 2 seconds and do it again.\\n* [Here is a video](https://youtu.be/we1ESnafqy4?si=mg2bxQ1k4SePf5yh) of a successful `agent:test` run.\\n\\nCurrently, the only models I can get to stay in the loop with are `google/gemini-2.0-flash-\\n[...truncated for length...]\", \"tools\": [{\"name\": \"list_tools\", \"description\": \", then `add_message`, then from `Human` send a message describing a task or project for the team to work on.\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"message\": {\"type\": \"string\", \"description\": \"Text content or message\"}}, \"required\": [\"message\"]}, \"source\": \"readme\", \"access_level\": \"execute\"}, {\"name\": \"list_tasks\", \"description\": \"to see the tasks it is adding,\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"input\": {\"type\": \"string\", \"description\": \"Input parameter for list_tasks\"}}, \"required\": [\"input\"]}, \"source\": \"readme\", \"access_level\": \"write\"}, {\"name\": \"build\", \"description\": \",` mcp-proxy`, and `agent:test` and if the model you have configured does some work then stops with a \\\"message loop ended\\\" error, you have a model that just isn't very good at using tools. Try different models and see what works. If you get anything other than the above-mentioned models to actually stay on the job, then please let me know!\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"message\": {\"type\": \"string\", \"description\": \"Text content or message\"}}, \"required\": [\"message\"]}, \"source\": \"readme\", \"access_level\": \"write\"}, {\"name\": \"register_agent\", \"description\": \"**\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"input\": {\"type\": \"string\", \"description\": \"Input parameter for register_agent\"}}, \"required\": [\"input\"]}, \"source\": \"readme\", \"access_level\": \"read\"}, {\"name\": \"id\", \"description\": \"and assigned `color`.\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"input\": {\"type\": \"string\", \"description\": \"Input parameter for id\"}}, \"required\": [\"input\"]}, \"source\": \"readme\", \"access_level\": \"read\"}, {\"name\": \"list_agents\", \"description\": \"**\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"input\": {\"type\": \"string\", \"description\": \"Input parameter for list_agents\"}}, \"required\": [\"input\"]}, \"source\": \"readme\", \"access_level\": \"read\"}, {\"name\": \"agent_leave\", \"description\": \"**\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"input\": {\"type\": \"string\", \"description\": \"Input parameter for agent_leave\"}}, \"required\": [\"input\"]}, \"source\": \"readme\", \"access_level\": \"read\"}, {\"name\": \"agent_wait\", \"description\": \"**\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"input\": {\"type\": \"string\", \"description\": \"Input parameter for agent_wait\"}}, \"required\": [\"input\"]}, \"source\": \"readme\", \"access_level\": \"read\"}, {\"name\": \"seconds\", \"description\": \"the number of seconds to wait.\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"input\": {\"type\": \"string\", \"description\": \"Input parameter for seconds\"}}, \"required\": [\"input\"]}, \"source\": \"readme\", \"access_level\": \"read\"}, {\"name\": \"add_message\", \"description\": \"**\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"message\": {\"type\": \"string\", \"description\": \"Text content or message\"}}, \"required\": [\"message\"]}, \"source\": \"readme\", \"access_level\": \"write\"}, {\"name\": \"senderId\", \"description\": \"ID of the agent sending the message.\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"message\": {\"type\": \"string\", \"description\": \"Text content or message\"}}, \"required\": [\"message\"]}, \"source\": \"readme\", \"access_level\": \"execute\"}, {\"name\": \"content\", \"description\": \"Content of the message.\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"message\": {\"type\": \"string\", \"description\": \"Text content or message\"}}, \"required\": [\"message\"]}, \"source\": \"readme\", \"access_level\": \"read\"}, {\"name\": \"recent_messages\", \"description\": \"**\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"message\": {\"type\": \"string\", \"description\": \"Text content or message\"}}, \"required\": [\"message\"]}, \"source\": \"readme\", \"access_level\": \"read\"}, {\"name\": \"list_messages\", \"description\": \"**\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"message\": {\"type\": \"string\", \"description\": \"Text content or message\"}}, \"required\": [\"message\"]}, \"source\": \"readme\", \"access_level\": \"read\"}, {\"name\": \"clear_messages\", \"description\": \"**\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"message\": {\"type\": \"string\", \"description\": \"Text content or message\"}}, \"required\": [\"message\"]}, \"source\": \"readme\", \"access_level\": \"read\"}, {\"name\": \"add_task\", \"description\": \"**\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"input\": {\"type\": \"string\", \"description\": \"Input parameter for add_task\"}}, \"required\": [\"input\"]}, \"source\": \"readme\", \"access_level\": \"write\"}, {\"name\": \"description\", \"description\": \"Description of the task.\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"input\": {\"type\": \"string\", \"description\": \"Input parameter for description\"}}, \"required\": [\"input\"]}, \"source\": \"readme\", \"access_level\": \"read\"}, {\"name\": \"assign_task\", \"description\": \"**\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"input\": {\"type\": \"string\", \"description\": \"Input parameter for assign_task\"}}, \"required\": [\"input\"]}, \"source\": \"readme\", \"access_level\": \"read\"}, {\"name\": \"taskId\", \"description\": \"ID of the task.\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"input\": {\"type\": \"string\", \"description\": \"Input parameter for taskId\"}}, \"required\": [\"input\"]}, \"source\": \"readme\", \"access_level\": \"read\"}, {\"name\": \"agentId\", \"description\": \"ID of the agent to assign the task to.\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"input\": {\"type\": \"string\", \"description\": \"Input parameter for agentId\"}}, \"required\": [\"input\"]}, \"source\": \"readme\", \"access_level\": \"read\"}, {\"name\": \"complete_task\", \"description\": \"**\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"input\": {\"type\": \"string\", \"description\": \"Input parameter for complete_task\"}}, \"required\": [\"input\"]}, \"source\": \"readme\", \"access_level\": \"read\"}, {\"name\": \"StreamableHttp\", \"description\": \"- Make sure `URL` is set to http://localhost:3001/mcp\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"url\": {\"type\": \"string\", \"description\": \"URL or link to process\"}}, \"required\": [\"url\"]}, \"source\": \"readme\", \"access_level\": \"write\"}, {\"name\": \"prettier\", \"description\": \"on the code, adjusting formatting\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"input\": {\"type\": \"string\", \"description\": \"Input parameter for prettier\"}}, \"required\": [\"input\"]}, \"source\": \"readme\", \"access_level\": \"read\"}, {\"name\": \"tsc\", \"description\": \"with args to check and report type issues\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"input\": {\"type\": \"string\", \"description\": \"Input parameter for tsc\"}}, \"required\": [\"input\"]}, \"source\": \"readme\", \"access_level\": \"read\"}, {\"name\": \"eslint\", \"description\": \"to non-destructively check for and report syntax problems\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"input\": {\"type\": \"string\", \"description\": \"Input parameter for eslint\"}}, \"required\": [\"input\"]}, \"source\": \"readme\", \"access_level\": \"read\"}], \"tools_count\": 25, \"homepage\": \"\", \"url\": \"https://github.com/cliffhall/GooseTeam\", \"topics\": [], \"data_sources\": [\"github\"]}", "target": "", "id": "cliffhall/gooseteam", "metadata": {"stage": "finance_filter"}}
{"input": "ONLY RESPOND WITH JSON. NO EXPLANATIONS. NO MARKDOWN. NO TEXT OUTSIDE JSON.\n\nAnalyze the MCP server for financial relevance. Look for keywords: payment, banking, credit, loan, finance, money, currency, crypto, investment, trading, portfolio, market, exchange, wallet, account, budget, expense, income, tax, invoice, billing, accounting, insurance, compliance, KYC, AML.\n\nJSON FORMAT (NOTHING ELSE):\n{\n  \"server_name\": \"string\",\n  \"server_id\": \"string\", \n  \"is_finance_llm\": \"yes|no|unclear\",\n  \"confidence\": \"high|medium|low\",\n  \"threat_models\": [],\n  \"analysis_notes\": \"Brief reason\"\n}\n\nIf financial keywords found: is_finance_llm=\"yes\". If not: is_finance_llm=\"no\". If unclear: is_finance_llm=\"unclear\".\n\nRESPOND ONLY WITH JSON.\n\nMCP Server Data:\n{\"server_name\": \"fdic-bank-find-mcp-server\", \"server_id\": \"clafollett/fdic-bank-find-mcp-server\", \"description\": \"The is a MCPserver that brings the power of FDIC BankFind APIs straight to your AI tools and workflows. Structured U.S. banking data, delivered with maximum vibes. \\ud83d\\ude0e\\ud83d\\udcca\", \"readme\": \"# \\ud83c\\udfe6 FDIC BankFind MCP Server \\ud83e\\udd20\\ud83d\\udcbb\\n\\n---\\n\\nThe **FDIC BankFind MCP Server** is a [Model Context Protocol (MCP)](https://modelcontextprotocol.io/introduction) server that brings the power of FDIC BankFind APIs straight to your AI tools and workflows. Structured U.S. banking data, delivered with maximum vibes. \\ud83d\\ude0e\\ud83d\\udcca\\n\\n[![Rust](https://img.shields.io/badge/Rust-stable-blue?logo=rust)](https://www.rust-lang.org/) ![OpenAPI](https://img.shields.io/badge/OpenAPI-3.0-green?logo=openapi-initiative) \\ud83e\\udd80\\n\\n---\\n\\n## \\ud83d\\udca1 Use Cases\\n\\n- Powering agent/LLM research on U.S. banks and institutions \\ud83e\\udd16\\ud83c\\udfe6\\n- Automating financial analytics, compliance, and reporting workflows \\ud83d\\udcc8\\ud83e\\uddfe\\n- Building AI-driven dashboards, bots, or custom fintech tools \\ud83e\\udd20\\ud83e\\udd16\\n- Rapid prototyping for academic or market analysis \\ud83c\\udf93\\ud83d\\udcca\\n\\n---\\n\\n## \\ud83d\\udee0\\ufe0f Prerequisites\\n\\n---\\n\\n1. To run the server in a container, you\\u2019ll need to have [Docker](https://www.docker.com/) installed. \\ud83d\\udc33\\n2. Once Docker is installed, make sure it\\u2019s running! \\ud83c\\udfc3\\u200d\\u2642\\ufe0f\\ud83d\\udca8\\n\\n---\\n\\n## Installation\\n\\n### \\ud83d\\ude80 Run the Official Public Docker Image (Recommended)\\n\\nThe FDIC BankFind MCP Server is published and ready to use from GitHub Container Registry (GHCR).\\n\\nTo run it (Docker will pull the image automatically if it's not present):\\n\\n```sh\\ndocker run -i --rm ghcr.io/clafollett/fdic-bank-find-mcp-server:main\\n```\\n\\nYou do NOT need to build the image yourself unless you want to develop or customize the server. For most users, just running the command above is all you need!\\n\\n---\\n\\n### Build Steps (Manual Docker Build)\\n\\nIf you want to build the image yourself (for local development or custom changes):\\n\\n1. **Clone the repository:**\\n\\n   ```bash\\n   git clone https://github.com/YOUR-ORG/fdic-bank-find-mcp-server.git\\n   cd fdic-bank-find-mcp-server\\n   ```\\n\\n2. **Build the Docker image:**\\n\\n   ```bash\\n   docker build -t fdic-bank-find-mcp-server:main .\\n   ```\\n\\n   This uses the included `Dockerfile` to build a release-mode Rust binary and package it into a minimal container.\\n\\n3. **Test the image locally:**\\n\\n   ```bash\\n   docker run -i --rm fdic-bank-find-mcp-server:main\\n   ```\\n\\n   (The `-i` flag is required for stdio/MCP integration.)\\n\\n4. **Use the image in your MCP host config:**\\n   Follow the VS Code or Claude Desktop instructions below, referencing your local image as `fdic-bank-find-mcp-server:main`.\\n\\n> If you\\u2019d like to tag/push to a registry, simply update the `docker build` and `docker tag` commands accordingly.\\n\\n### \\ud83e\\uddd1\\u200d\\ud83d\\udcbb Usage with VS Code\\n\\nOnce the image is published to GHCR you\\u2019ll be able to click a one-click install badge here. Until then, follow the manual steps below. \\ud83d\\udee0\\ufe0f\\n\\nAdd the following JSON block to your **User Settings (JSON)** file. Open it with `Ctrl + Shift + P` \\u2192 \\u201cPreferences: Open User Settings (JSON)\\u201d.\\n\\n```json\\n{\\n  \\\"mcp\\\": {\\n    \\\"servers\\\": {\\n      \\\"fdic\\\": {\\n        \\\"command\\\": \\\"docker\\\",\\n        \\\"args\\\": [\\n          \\\"run\\\",\\n          \\\"-i\\\",\\n          \\\"--rm\\\",\\n          \\\"ghcr.io/YOUR-ORG/fdic-bank-find-mcp-server:main\\\"\\n        ]\\n      }\\n    }\\n  }\\n}\\n```\\n\\n> \\ud83d\\udca1 For workspace-specific config, place the same block (without the outer `\\\"mcp\\\"` key) in `.vscode/mcp.json`. Easy peasy! \\ud83c\\udf4b\\n\\n### \\ud83e\\udd16 Usage with Claude Desktop (Conceptual)\\n\\n```json\\n{\\n  \\\"mcpServers\\\": {\\n    \\\"fdic-bank-find\\\": {\\n      \\\"command\\\": \\\"docker\\\",\\n      \\\"args\\\": [\\n        \\\"run\\\",\\n        \\\"-i\\\",\\n        \\\"--rm\\\",\\n        \\\"ghcr.io/YOUR-ORG/fdic-bank-find-mcp-server:main\\\"\\n      ]\\n    }\\n  }\\n}\\n```\\n\\n### \\ud83e\\udd80 Build from Source (Manual)\\n\\nIf you prefer not to use Docker (or want to hack on the server itself), you can compile the binary with the Rust toolchain and run it in **stdio** mode. \\ud83e\\uddbe\\n\\n```bash\\n# Clone & build\\n$ git clone https://github.com/YOUR-ORG/fdic-bank-find-mcp-server.git\\n$ cd fdic-bank-find-mcp-server\\n$ cargo build --release\\n```\\n\\nOnce built, configure your MCP host to invoke the executable directly. For example, in **VS Code User Settings (JSON)**:\\n\\n```json\\n{\\n  \\\"mcp\\\": {\\n    \\\"servers\\\": {\\n      \\\"fdic\\\": {\\n        \\\"command\\\": \\\"/path/to/repository/fdic-bank-find-mcp-server/target/release/fdic-bank-find-mcp-server\\\"\\n      }\\n    }\\n  }\\n}\\n```\\n\\n---\\n\\n## \\ud83d\\udd75\\ufe0f\\u200d\\u2642\\ufe0f MCP Inspector Setup & Usage\\n\\nWant to test, debug, or vibe with your MCP server in a beautiful UI? Enter the **MCP Inspector**! \\ud83d\\udd0d\\u2728\\n\\n### Running the MCP Inspector\\n\\nYou can run it directly (no install needed):\\n\\n```sh\\nnpx @modelcontextprotocol/inspector docker run -i --rm fdic-bank-find-mcp-server:main\\n```\\n\\nOr install globally for convenience:\\n\\n```sh\\nnpm install -g @modelcontextprotocol/inspector\\nmodelcontextprotocol-inspector docker run -i --rm fdic-bank-find-mcp-server:main\\n```\\n\\n> The Inspector launches a local UI and pipes MCP requests/responses between your server and the interface. Perfect for debugging, prototyping, and showing off your API to friends, robots, or your boss. \\ud83d\\ude0e\\ud83e\\udd16\\n\\n---\\n\\n## \\ud83c\\udfaf Tool Overview \\ud83c\\udfaf\\n\\nAll tools accept the following common parameters:\\n\\n- `api_key`: Your FDIC API key (optional)\\n- `filters`: Filter expression for advanced querying using FDIC BankFind syntax\\n- `fields`: Comma-delimited list of fields to return\\n- `limit`: Number of reco\\n[...truncated for length...]\", \"tools\": [{\"name\": \"Dockerfile\", \"description\": \"to build a release-mode Rust binary and package it into a minimal container.\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"file_path\": {\"type\": \"string\", \"description\": \"File path or file to process\"}}, \"required\": [\"file_path\"]}, \"source\": \"readme\", \"access_level\": \"write\"}, {\"name\": \"api_key\", \"description\": \"Your FDIC API key (optional)\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"input\": {\"type\": \"string\", \"description\": \"Input parameter for api_key\"}}, \"required\": [\"input\"]}, \"source\": \"readme\", \"access_level\": \"read\"}, {\"name\": \"filters\", \"description\": \"Filter expression for advanced querying using FDIC BankFind syntax\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"query\": {\"type\": \"string\", \"description\": \"Search query or term\"}}, \"required\": [\"query\"]}, \"source\": \"readme\", \"access_level\": \"read\"}, {\"name\": \"fields\", \"description\": \"Comma-delimited list of fields to return\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"input\": {\"type\": \"string\", \"description\": \"Input parameter for fields\"}}, \"required\": [\"input\"]}, \"source\": \"readme\", \"access_level\": \"read\"}, {\"name\": \"limit\", \"description\": \"Number of records to return\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"input\": {\"type\": \"string\", \"description\": \"Input parameter for limit\"}}, \"required\": [\"input\"]}, \"source\": \"readme\", \"access_level\": \"read\"}, {\"name\": \"offset\", \"description\": \"Pagination offset\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"input\": {\"type\": \"string\", \"description\": \"Input parameter for offset\"}}, \"required\": [\"input\"]}, \"source\": \"readme\", \"access_level\": \"write\"}, {\"name\": \"sort_by\", \"description\": \"Field to sort by\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"input\": {\"type\": \"string\", \"description\": \"Input parameter for sort_by\"}}, \"required\": [\"input\"]}, \"source\": \"readme\", \"access_level\": \"read\"}, {\"name\": \"sort_order\", \"description\": \"Sort order (ASC/DESC)\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"input\": {\"type\": \"string\", \"description\": \"Input parameter for sort_order\"}}, \"required\": [\"input\"]}, \"source\": \"readme\", \"access_level\": \"read\"}, {\"name\": \"file_format\", \"description\": \"Response format (json/csv/xml)\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"file_path\": {\"type\": \"string\", \"description\": \"File path or file to process\"}}, \"required\": [\"file_path\"]}, \"source\": \"readme\", \"access_level\": \"read\"}, {\"name\": \"file_download\", \"description\": \"Download flag (if set, triggers file download)\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"file_path\": {\"type\": \"string\", \"description\": \"File path or file to process\"}}, \"required\": [\"file_path\"]}, \"source\": \"readme\", \"access_level\": \"execute\"}, {\"name\": \"file_name\", \"description\": \"Custom filename for download\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"file_path\": {\"type\": \"string\", \"description\": \"File path or file to process\"}}, \"required\": [\"file_path\"]}, \"source\": \"readme\", \"access_level\": \"execute\"}, {\"name\": \"get_demographics\", \"description\": \"| Demographic summaries         |                                                                                           |\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"input\": {\"type\": \"string\", \"description\": \"Input parameter for get_demographics\"}}, \"required\": [\"input\"]}, \"source\": \"readme\", \"access_level\": \"read\"}, {\"name\": \"get_failures\", \"description\": \"| Historical bank failures      | `agg_by`, `agg_limit`, `agg_sum_fields`, `agg_term_fields`, `total_fields`, `subtotal_by` |\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"input\": {\"type\": \"string\", \"description\": \"Input parameter for get_failures\"}}, \"required\": [\"input\"]}, \"source\": \"readme\", \"access_level\": \"read\"}, {\"name\": \"get_history\", \"description\": \"| Structure change events       | `search`, `agg_by`, `agg_limit`, `agg_term_fields`                                        |\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"query\": {\"type\": \"string\", \"description\": \"Search query or term\"}}, \"required\": [\"query\"]}, \"source\": \"readme\", \"access_level\": \"write\"}, {\"name\": \"get_institutions\", \"description\": \"| Institution demographics      | `search`                                                                                  |\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"query\": {\"type\": \"string\", \"description\": \"Search query or term\"}}, \"required\": [\"query\"]}, \"source\": \"readme\", \"access_level\": \"read\"}, {\"name\": \"get_locations\", \"description\": \"| Branch locations              |                                                                                           |\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"input\": {\"type\": \"string\", \"description\": \"Input parameter for get_locations\"}}, \"required\": [\"input\"]}, \"source\": \"readme\", \"access_level\": \"read\"}, {\"name\": \"get_sod\", \"description\": \"| Summary of Deposits           | `agg_by`, `agg_limit`, `agg_sum_fields`, `agg_term_fields`                                |\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"input\": {\"type\": \"string\", \"description\": \"Input parameter for get_sod\"}}, \"required\": [\"input\"]}, \"source\": \"readme\", \"access_level\": \"read\"}, {\"name\": \"get_summary\", \"description\": \"| Historical aggregates by year | `agg_by`, `agg_limit`, `agg_sum_fields`, `agg_term_fields`, `max_value`, `max_value_by`   |\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"amount\": {\"type\": \"number\", \"description\": \"Numeric amount or value\"}}, \"required\": [\"amount\"]}, \"source\": \"readme\", \"access_level\": \"read\"}], \"tools_count\": 18, \"homepage\": \"\", \"url\": \"https://github.com/clafollett/fdic-bank-find-mcp-server\", \"topics\": [], \"data_sources\": [\"github\", \"official\"]}", "target": "", "id": "clafollett/fdic-bank-find-mcp-server", "metadata": {"stage": "finance_filter"}}
{"input": "ONLY RESPOND WITH JSON. NO EXPLANATIONS. NO MARKDOWN. NO TEXT OUTSIDE JSON.\n\nAnalyze the MCP server for financial relevance. Look for keywords: payment, banking, credit, loan, finance, money, currency, crypto, investment, trading, portfolio, market, exchange, wallet, account, budget, expense, income, tax, invoice, billing, accounting, insurance, compliance, KYC, AML.\n\nJSON FORMAT (NOTHING ELSE):\n{\n  \"server_name\": \"string\",\n  \"server_id\": \"string\", \n  \"is_finance_llm\": \"yes|no|unclear\",\n  \"confidence\": \"high|medium|low\",\n  \"threat_models\": [],\n  \"analysis_notes\": \"Brief reason\"\n}\n\nIf financial keywords found: is_finance_llm=\"yes\". If not: is_finance_llm=\"no\". If unclear: is_finance_llm=\"unclear\".\n\nRESPOND ONLY WITH JSON.\n\nMCP Server Data:\n{\"server_name\": \"eagv1-s4-mcp\", \"server_id\": \"milindchawre/eagv1-s4-mcp\", \"description\": \"MCP server for Math Agent with Microsoft Word and Gmail Integration\", \"readme\": \"# Math Agent with Microsoft Word and Gmail Integration\\n\\nA Python-based mathematical agent that solves problems iteratively using various mathematical tools and visualizes results using Microsoft Word and Gmail.\\n\\n## Features\\n\\n- Mathematical Operations\\n  - Basic arithmetic (add, subtract, multiply, divide)\\n  - Advanced operations (power, square root, cube root)\\n  - Trigonometric functions (sin, cos, tan)\\n  - Logarithmic calculations\\n  - Factorial computation\\n  - Fibonacci sequence generation\\n  - ASCII value conversion\\n  - Exponential sum calculations\\n\\n- AI Integration\\n  - Google Gemini Pro model for intelligent problem-solving\\n  - Iterative problem-solving approach\\n  - Automatic tool selection and execution\\n\\n- Enhanced Logging\\n  - Detailed execution logs\\n  - Debug information for tool operations\\n  - Error tracking and reporting\\n  - Comprehensive email reports with execution history\\n\\n- Email Integration\\n  - Automatic email reports after completion\\n  - Detailed execution logs in email body\\n  - Final result summary\\n  - Gmail SMTP integration\\n\\n- Word Integration\\n  - Automatic Word document creation\\n  - Rectangle drawing with results\\n  - Automated result visualization\\n  - Configurable text placement\\n\\n## Prerequisites\\n\\n- Python 3.7+\\n- Microsoft Word for macOS\\n- macOS 10.15 or later\\n- Google Cloud API key (for Gemini Pro)\\n\\n## Installation\\n\\n1. Clone the repository\\n2. Install dependencies:\\n```bash\\npip3 install -r requirements.txt\\n```\\n3. Set up environment variables:\\n\\nOption 1: Export in terminal (recommended for testing):\\n```bash\\nexport GEMINI_API_KEY=your_api_key_here\\nexport GMAIL_USER=your.email@gmail.com\\nexport GMAIL_APP_PASSWORD=your16digitpassword\\n```\\nOption 2: Create a .env file:\\n```bash\\nGEMINI_API_KEY=your_api_key_here\\nGMAIL_USER=your.email@gmail.com\\nGMAIL_APP_PASSWORD=your16digitpassword\\n```\\n\\n## Usage\\nRecommended Method: Run the client (automatically starts the server):\\n```bash\\npython math_agent_client.py\\n```\\nAlternative Method (for debugging): Run server and client separately:\\n1. Start the MCP server:\\n```bash\\n# Terminal 1\\npython math_agent_server.py\\n\\n# Terminal 2\\npython math_agent_client.py\\n```\\n\\nThe agent will:\\n\\n- Start the MCP server internally\\n- Process mathematical queries using Gemini AI\\n- Execute calculations using available tools\\n- Create a Word document with the result\\n- Draw a rectangle containing the final answer\\n- Send an email report with execution logs\\n\\n## Example Queries\\n```plaintext\\n- Find the ASCII values of characters in INDIA and then return sum of exponentials of those values\\n- Calculate the factorial of 5\\n- Find the sum of first 10 Fibonacci numbers\\n```\\n\\n## Architecture\\n- `math_agent_client.py` : Main client handling:\\n    - Gemini AI integration\\n    - Query processing\\n    - Tool execution\\n    - Word visualization\\n\\n- `math_agent_server.py` : Server providing:\\n    - Mathematical tools\\n    - Word integration tools\\n    - Resource handlers\\n\\n## Error Handling\\n- Timeout protection for AI generation\\n- Robust error handling for tool execution\\n- Automatic state reset\\n- Debug logging\\n\\n## Logging\\n- All operations are logged with timestamps\\n- Log levels: INFO, DEBUG, ERROR\\n- Logs are included in email reports\\n- Console output for real-time monitoring\\n\\n## Troubleshooting\\n\\n### Email Configuration\\n- Ensure GMAIL_USER is your full email address\\n- GMAIL_APP_PASSWORD must be a 16-character app password\\n- Enable 2-Step Verification in your Google Account\\n- Check execution logs for detailed error messages\\n\\n### Word Integration\\n- Ensure Microsoft Word is installed and running\\n- Allow automation permissions if prompted\\n- Check execution logs for any automation errors\\n\\n### Common Issues\\n- If environment variables are not detected, try restarting your terminal\\n- For Word automation issues, ensure Word is not in full-screen mode\\n- Check console output for detailed error messages and stack traces\\n\\n## Limitations\\n- Requires macOS environment\\n- Microsoft Word for macOS must be installed\\n- Maximum 8 iterations per problem\\n- Requires Google Cloud API access\\n\", \"tools\": [], \"tools_count\": 0, \"homepage\": \"\", \"url\": \"https://github.com/milindchawre/eagv1-s4-mcp\", \"topics\": [], \"data_sources\": [\"github\"]}", "target": "", "id": "milindchawre/eagv1-s4-mcp", "metadata": {"stage": "finance_filter"}}
{"input": "ONLY RESPOND WITH JSON. NO EXPLANATIONS. NO MARKDOWN. NO TEXT OUTSIDE JSON.\n\nAnalyze the MCP server for financial relevance. Look for keywords: payment, banking, credit, loan, finance, money, currency, crypto, investment, trading, portfolio, market, exchange, wallet, account, budget, expense, income, tax, invoice, billing, accounting, insurance, compliance, KYC, AML.\n\nJSON FORMAT (NOTHING ELSE):\n{\n  \"server_name\": \"string\",\n  \"server_id\": \"string\", \n  \"is_finance_llm\": \"yes|no|unclear\",\n  \"confidence\": \"high|medium|low\",\n  \"threat_models\": [],\n  \"analysis_notes\": \"Brief reason\"\n}\n\nIf financial keywords found: is_finance_llm=\"yes\". If not: is_finance_llm=\"no\". If unclear: is_finance_llm=\"unclear\".\n\nRESPOND ONLY WITH JSON.\n\nMCP Server Data:\n{\"server_name\": \"brlaw_mcp_server\", \"server_id\": \"pdmtt/brlaw_mcp_server\", \"description\": \"A MCP (Model Context Protocol) server for agent-driven research on Brazilian law\", \"readme\": \"# Brazilian Law Research MCP Server\\n\\n[\\ud83c\\udde7\\ud83c\\uddf7 Leia em portugu\\u00eas](README.br.md)\\n\\nA MCP (Model Context Protocol) server for agent-driven research on Brazilian law.\\n\\n## Requirements\\n\\n- git\\n- uv (recommended) or Python >= 3.11\\n- Google Chrome\\n\\n## How to use\\n\\n1. Clone the repository:\\n```bash\\ngit clone https://github.com/pdmtt/brlaw_mcp_server.git\\n```\\n\\n2. Install the dependencies\\n```bash\\nuv run patchright install\\n```\\n\\n3. Setup your MCP client (e.g. Claude Desktop):\\n```json\\n{\\n  \\\"mcpServers\\\": {\\n    \\\"brlaw_mcp_server\\\": {\\n      \\\"command\\\": \\\"uv\\\",\\n      \\\"args\\\": [\\n        \\\"--directory\\\",\\n        \\\"/<path>/brlaw_mcp_server\\\",\\n        \\\"run\\\",\\n        \\\"serve\\\"\\n      ]\\n    }\\n  }\\n}\\n```\\n\\n### Available Tools\\n\\n- `StjLegalPrecedentsRequest`: Research legal precedents made by the National High Court of Brazil \\n  (STJ) that meet the specified criteria.\\n- `TstLegalPrecedentsRequest`: Research legal precedents made by the National High Labor Court of \\n  Brazil (TST) that meet the specified criteria.\\n\\n## Development\\n\\n### Tooling\\n\\nThe project uses:\\n- Ruff for linting and formatting.\\n- BasedPyright for type checking.\\n- Pytest for testing.\\n\\n### Language\\n\\nResources, tools and prompts related stuff must be written in Portuguese, because this project aims \\nto be used by non-dev folks, such as lawyers and law students. \\n\\nTechnical legal vocabulary is highly dependent on a country's legal tradition and translating it is \\nno trivial task.\\n\\nDevelopment related stuff should stick to English as conventional, such as source code.\\n\\n## License\\n\\nThis project is licensed under the MIT License - see the LICENSE file for details.\", \"tools\": [{\"name\": \"StjLegalPrecedentsRequest\", \"description\": \"Research legal precedents made by the National High Court of Brazil\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"query\": {\"type\": \"string\", \"description\": \"Search query or term\"}}, \"required\": [\"query\"]}, \"source\": \"readme\", \"access_level\": \"read\"}, {\"name\": \"TstLegalPrecedentsRequest\", \"description\": \"Research legal precedents made by the National High Labor Court of\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"query\": {\"type\": \"string\", \"description\": \"Search query or term\"}}, \"required\": [\"query\"]}, \"source\": \"readme\", \"access_level\": \"read\"}], \"tools_count\": 2, \"homepage\": \"\", \"url\": \"https://github.com/pdmtt/brlaw_mcp_server\", \"topics\": [], \"data_sources\": [\"github\"]}", "target": "", "id": "pdmtt/brlaw_mcp_server", "metadata": {"stage": "finance_filter"}}
{"input": "ONLY RESPOND WITH JSON. NO EXPLANATIONS. NO MARKDOWN. NO TEXT OUTSIDE JSON.\n\nAnalyze the MCP server for financial relevance. Look for keywords: payment, banking, credit, loan, finance, money, currency, crypto, investment, trading, portfolio, market, exchange, wallet, account, budget, expense, income, tax, invoice, billing, accounting, insurance, compliance, KYC, AML.\n\nJSON FORMAT (NOTHING ELSE):\n{\n  \"server_name\": \"string\",\n  \"server_id\": \"string\", \n  \"is_finance_llm\": \"yes|no|unclear\",\n  \"confidence\": \"high|medium|low\",\n  \"threat_models\": [],\n  \"analysis_notes\": \"Brief reason\"\n}\n\nIf financial keywords found: is_finance_llm=\"yes\". If not: is_finance_llm=\"no\". If unclear: is_finance_llm=\"unclear\".\n\nRESPOND ONLY WITH JSON.\n\nMCP Server Data:\n{\"server_name\": \"sqlite-literature-management-fastmcp-mcp-server\", \"server_id\": \"zongmin-yu/sqlite-literature-management-fastmcp-mcp-server\", \"description\": \"A flexible system for managing various types of sources (papers, books, webpages, etc.) and integrating them with knowledge graphs.\", \"readme\": \"# Universal Source Management System\\n\\nA flexible system for managing various types of sources (papers, books, webpages, etc.) and integrating them with knowledge graphs.\\n\\n## Features\\n\\n### Core Features\\n\\n- Universal source identification with internal UUID system\\n- Support for multiple source types (papers, webpages, books, videos, blogs)\\n- Multiple identifier support per source (arxiv, DOI, semantic scholar, ISBN, URL)\\n- Structured note-taking with titles and content\\n- Status tracking (unread, reading, completed, archived)\\n\\n### Entity Integration\\n\\n- Link sources to knowledge graph entities\\n- Track relationships between sources and entities\\n- Flexible relation types (discusses, introduces, extends, etc.)\\n- Integration with memory graph\\n\\n## Prerequisites\\n\\nThis system integrates with the [MCP Memory Server](https://github.com/modelcontextprotocol/servers/tree/main/src/memory) for persistent knowledge graph storage.\\n\\n## Quick Start\\n\\n1. Create a new SQLite database with our schema:\\n\\n```bash\\n# Create a new database\\nsqlite3 sources.db < create_sources_db.sql\\n```\\n\\n2. Install the source management server:\\n\\n```bash\\n# Install for Claude Desktop with your database path\\nfastmcp install source-manager-server.py --name \\\"Source Manager\\\" -e SQLITE_DB_PATH=/path/to/sources.db\\n```\\n\\n## Schema\\n\\n### Core Tables\\n\\n```sql\\n-- Sources table\\nCREATE TABLE sources (\\n    id UUID PRIMARY KEY,\\n    title TEXT NOT NULL,\\n    type TEXT CHECK(type IN ('paper', 'webpage', 'book', 'video', 'blog')) NOT NULL,\\n    identifiers JSONB NOT NULL,\\n    status TEXT CHECK(status IN ('unread', 'reading', 'completed', 'archived')) DEFAULT 'unread'\\n);\\n\\n-- Source notes\\nCREATE TABLE source_notes (\\n    source_id UUID REFERENCES sources(id),\\n    note_title TEXT NOT NULL,\\n    content TEXT NOT NULL,\\n    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\\n    PRIMARY KEY (source_id, note_title)\\n);\\n\\n-- Entity links\\nCREATE TABLE source_entity_links (\\n    source_id UUID REFERENCES sources(id),\\n    entity_name TEXT,\\n    relation_type TEXT CHECK(relation_type IN ('discusses', 'introduces', 'extends', 'evaluates', 'applies', 'critiques')),\\n    notes TEXT,\\n    PRIMARY KEY (source_id, entity_name)\\n);\\n```\\n\\n## Usage Examples\\n\\n### 1. Managing Sources\\n\\nAdd a paper with multiple identifiers:\\n\\n```python\\nadd_source(\\n    title=\\\"Attention Is All You Need\\\",\\n    type=\\\"paper\\\",\\n    identifier_type=\\\"arxiv\\\",\\n    identifier_value=\\\"1706.03762\\\",\\n    initial_note={\\n        \\\"title\\\": \\\"Initial thoughts\\\",\\n        \\\"content\\\": \\\"Groundbreaking paper introducing transformers...\\\"\\n    }\\n)\\n\\n# Add another identifier to the same paper\\nadd_identifier(\\n    title=\\\"Attention Is All You Need\\\",\\n    type=\\\"paper\\\",\\n    current_identifier_type=\\\"arxiv\\\",\\n    current_identifier_value=\\\"1706.03762\\\",\\n    new_identifier_type=\\\"semantic_scholar\\\",\\n    new_identifier_value=\\\"204e3073870fae3d05bcbc2f6a8e263d9b72e776\\\"\\n)\\n```\\n\\nAdd a webpage:\\n\\n```python\\nadd_source(\\n    title=\\\"Understanding Transformers\\\",\\n    type=\\\"webpage\\\",\\n    identifier_type=\\\"url\\\",\\n    identifier_value=\\\"https://example.com/transformers\\\",\\n)\\n```\\n\\n### 2. Note Taking\\n\\nAdd notes to a source:\\n\\n```python\\nadd_note(\\n    title=\\\"Attention Is All You Need\\\",\\n    type=\\\"paper\\\",\\n    identifier_type=\\\"arxiv\\\",\\n    identifier_value=\\\"1706.03762\\\",\\n    note_title=\\\"Implementation details\\\",\\n    note_content=\\\"The paper describes the architecture...\\\"\\n)\\n```\\n\\n### 3. Entity Linking\\n\\nLink source to entities:\\n\\n```python\\nlink_to_entity(\\n    title=\\\"Attention Is All You Need\\\",\\n    type=\\\"paper\\\",\\n    identifier_type=\\\"arxiv\\\",\\n    identifier_value=\\\"1706.03762\\\",\\n    entity_name=\\\"transformer\\\",\\n    relation_type=\\\"introduces\\\",\\n    notes=\\\"First paper to introduce the transformer architecture\\\"\\n)\\n```\\n\\nQuery sources by entity:\\n\\n```python\\nget_entity_sources(\\n    entity_name=\\\"transformer\\\",\\n    type_filter=\\\"paper\\\",\\n    relation_filter=\\\"discusses\\\"\\n)\\n```\\n\\n## Best Practices\\n\\n1. Source Management\\n\\n   - Use consistent titles across references\\n   - Provide as many identifiers as available\\n   - Keep notes structured with clear titles\\n   - Use appropriate source types\\n\\n2. Entity Linking\\n   - Be specific with relation types\\n   - Add contextual notes to relationships\\n   - Verify entity names against memory graph\\n   - Keep entity relationships focused\\n\\n## Technical Details\\n\\n1. Source Identification\\n\\n   - Internal UUID system for consistent referencing\\n   - Multiple external identifiers per source\\n   - Flexible identifier types (arxiv, doi, url, etc.)\\n   - Title and type based fuzzy matching\\n\\n2. Data Organization\\n   - Structured notes with titles\\n   - Clear source type categorization\\n   - Entity relationship tracking\\n   - Status management\\n\\n## Contributing\\n\\n1. Fork the repository\\n2. Create a feature branch\\n3. Add tests for new features\\n4. Submit a pull request\\n\", \"tools\": [], \"tools_count\": 0, \"homepage\": \"\", \"url\": \"https://github.com/zongmin-yu/sqlite-literature-management-fastmcp-mcp-server\", \"topics\": [\"agent\", \"fastmcp\", \"llm\", \"mcp\", \"memory\", \"sqlite\"], \"data_sources\": [\"github\"]}", "target": "", "id": "zongmin-yu/sqlite-literature-management-fastmcp-mcp-server", "metadata": {"stage": "finance_filter"}}
{"input": "ONLY RESPOND WITH JSON. NO EXPLANATIONS. NO MARKDOWN. NO TEXT OUTSIDE JSON.\n\nAnalyze the MCP server for financial relevance. Look for keywords: payment, banking, credit, loan, finance, money, currency, crypto, investment, trading, portfolio, market, exchange, wallet, account, budget, expense, income, tax, invoice, billing, accounting, insurance, compliance, KYC, AML.\n\nJSON FORMAT (NOTHING ELSE):\n{\n  \"server_name\": \"string\",\n  \"server_id\": \"string\", \n  \"is_finance_llm\": \"yes|no|unclear\",\n  \"confidence\": \"high|medium|low\",\n  \"threat_models\": [],\n  \"analysis_notes\": \"Brief reason\"\n}\n\nIf financial keywords found: is_finance_llm=\"yes\". If not: is_finance_llm=\"no\". If unclear: is_finance_llm=\"unclear\".\n\nRESPOND ONLY WITH JSON.\n\nMCP Server Data:\n{\"server_name\": \"awesome-a2a\", \"server_id\": \"marius12-oss/awesome-a2a\", \"description\": \"Agent2Agent (A2A) \\u2013 awesome A2A agents, tools, servers & clients, all in one place. \", \"readme\": \"# Awesome A2A \\ud83c\\udf1f\\n\\n![Awesome A2A](https://img.shields.io/badge/awesome--a2a-brightgreen?style=flat&logo=github)\\n\\nWelcome to **Awesome A2A**! This repository is your go-to source for everything related to Agent2Agent (A2A). Here, you will find a curated collection of A2A agents, tools, servers, and clients, all in one place. Whether you're a developer, researcher, or enthusiast, this repository has something for you.\\n\\n## Table of Contents\\n\\n- [Introduction](#introduction)\\n- [Features](#features)\\n- [Getting Started](#getting-started)\\n- [Usage](#usage)\\n- [Contributing](#contributing)\\n- [License](#license)\\n- [Contact](#contact)\\n- [Releases](#releases)\\n\\n## Introduction\\n\\nAgent2Agent (A2A) technology allows agents to communicate with one another effectively. This can lead to enhanced collaboration, improved performance, and innovative solutions in various fields. Our aim is to gather all relevant resources and make them easily accessible to everyone interested in A2A.\\n\\n## Features\\n\\n- **Comprehensive Collection**: A wide range of A2A agents, tools, and servers.\\n- **User-Friendly**: Easy to navigate and find what you need.\\n- **Community Driven**: Contributions from developers and users around the world.\\n- **Regular Updates**: Stay current with the latest releases and improvements.\\n\\n## Getting Started\\n\\nTo get started with Awesome A2A, follow these steps:\\n\\n1. **Clone the Repository**: Use the following command to clone the repository to your local machine.\\n\\n   ```bash\\n   git clone https://github.com/Marius12-oss/awesome-a2a.git\\n   ```\\n\\n2. **Explore the Content**: Navigate through the repository to find agents, tools, and servers that interest you.\\n\\n3. **Download and Execute Releases**: Visit the [Releases section](https://github.com/Marius12-oss/awesome-a2a/releases) to download the latest versions of the tools and agents. Follow the instructions provided in the release notes for execution.\\n\\n## Usage\\n\\nOnce you have downloaded the necessary files, you can start using the A2A agents and tools. Each tool may have its own set of instructions, so be sure to check the documentation included in the release.\\n\\n### Example\\n\\nHere's a simple example of how to set up an A2A agent:\\n\\n1. **Download the Agent**: Get the latest version from the [Releases section](https://github.com/Marius12-oss/awesome-a2a/releases).\\n2. **Install Dependencies**: Make sure you have all the required libraries installed.\\n3. **Run the Agent**: Use the command line to execute the agent.\\n\\n```bash\\n./your-a2a-agent\\n```\\n\\n### Tips\\n\\n- Check the README files for each agent for specific setup instructions.\\n- Explore the community contributions for additional tools and enhancements.\\n\\n## Contributing\\n\\nWe welcome contributions from everyone! If you have an A2A agent, tool, or server that you would like to add, please follow these steps:\\n\\n1. **Fork the Repository**: Create your own copy of the repository.\\n2. **Make Your Changes**: Add your content or improve existing entries.\\n3. **Submit a Pull Request**: Share your changes with the community.\\n\\n### Guidelines\\n\\n- Ensure your contributions align with the theme of A2A.\\n- Keep the content clear and concise.\\n- Follow the existing structure of the repository.\\n\\n## License\\n\\nThis project is licensed under the MIT License. See the [LICENSE](LICENSE) file for more details.\\n\\n## Contact\\n\\nFor any questions or suggestions, feel free to reach out:\\n\\n- **Email**: your.email@example.com\\n- **Twitter**: [@yourhandle](https://twitter.com/yourhandle)\\n\\n## Releases\\n\\nTo stay updated with the latest releases, visit the [Releases section](https://github.com/Marius12-oss/awesome-a2a/releases). Here, you can download and execute the latest files to make the most out of your A2A experience.\\n\\n---\\n\\nThank you for checking out Awesome A2A! We hope you find this repository useful. Happy exploring! \\ud83c\\udf10\", \"tools\": [], \"tools_count\": 0, \"homepage\": \"\", \"url\": \"https://github.com/Marius12-oss/awesome-a2a\", \"topics\": [\"a2a\", \"agent\", \"agent2agent\", \"ai\", \"mcp\"], \"data_sources\": [\"github\"]}", "target": "", "id": "marius12-oss/awesome-a2a", "metadata": {"stage": "finance_filter"}}
{"input": "ONLY RESPOND WITH JSON. NO EXPLANATIONS. NO MARKDOWN. NO TEXT OUTSIDE JSON.\n\nAnalyze the MCP server for financial relevance. Look for keywords: payment, banking, credit, loan, finance, money, currency, crypto, investment, trading, portfolio, market, exchange, wallet, account, budget, expense, income, tax, invoice, billing, accounting, insurance, compliance, KYC, AML.\n\nJSON FORMAT (NOTHING ELSE):\n{\n  \"server_name\": \"string\",\n  \"server_id\": \"string\", \n  \"is_finance_llm\": \"yes|no|unclear\",\n  \"confidence\": \"high|medium|low\",\n  \"threat_models\": [],\n  \"analysis_notes\": \"Brief reason\"\n}\n\nIf financial keywords found: is_finance_llm=\"yes\". If not: is_finance_llm=\"no\". If unclear: is_finance_llm=\"unclear\".\n\nRESPOND ONLY WITH JSON.\n\nMCP Server Data:\n{\"server_name\": \"pubmed-mcp-server\", \"server_id\": \"cyanheads/pubmed-mcp-server\", \"description\": \"A Model Context Protocol (MCP) server enabling AI agents to intelligently search, retrieve, and analyze biomedical literature from PubMed via NCBI E-utilities. Includes a research agent scaffold. STDIO & HTTP\", \"readme\": \"# PubMed MCP Server\\n\\n[![TypeScript](https://img.shields.io/badge/TypeScript-^5.8.3-blue.svg)](https://www.typescriptlang.org/)\\n[![Model Context Protocol](https://img.shields.io/badge/MCP%20SDK-^1.12.1-green.svg)](https://modelcontextprotocol.io/)\\n[![Version](https://img.shields.io/badge/Version-1.1.4-blue.svg)](./CHANGELOG.md)\\n[![License](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](https://opensource.org/licenses/Apache-2.0)\\n[![Status](https://img.shields.io/badge/Status-Stable-green.svg)](https://github.com/cyanheads/pubmed-mcp-server/issues)\\n[![GitHub](https://img.shields.io/github/stars/cyanheads/pubmed-mcp-server?style=social)](https://github.com/cyanheads/pubmed-mcp-server)\\n\\n**Empower your AI agents and research tools with seamless PubMed integration!**\\n\\nAn MCP (Model Context Protocol) server providing comprehensive access to PubMed's biomedical literature database. Enables LLMs and AI agents to search, retrieve, analyze, and visualize scientific publications through NCBI's E-utilities API with advanced research workflow capabilities.\\n\\nBuilt on the [`cyanheads/mcp-ts-template`](https://github.com/cyanheads/mcp-ts-template), this server follows a modular architecture with robust error handling, logging, and security features.\\n\\n## \\ud83d\\ude80 Core Capabilities: PubMed Tools \\ud83d\\udee0\\ufe0f\\n\\nThis server equips your AI with specialized tools to interact with PubMed:\\n\\n| Tool Name                                                                               | Description                                                                                                                                                                                                  | Key Features                                                                                                                                                                                                                                                                                                                                                                                         |\\n| :-------------------------------------------------------------------------------------- | :----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\\n| [`search_pubmed_articles`](./src/mcp-server/tools/searchPubMedArticles/)                | Searches PubMed for articles based on your query. (See [Example](./examples/search_pubmed_articles_example.md))                                                                                              | - Filter by max results, sort order, date range, publication types.<br/>- Uses NCBI ESearch for PMIDs.<br/>- Optionally fetches brief summaries (title, authors, source, dates) via ESummary.                                                                                                                                                                                                        |\\n| [`fetch_pubmed_content`](./src/mcp-server/tools/fetchPubMedContent/)                    | Retrieves detailed information for PubMed articles. Can use a list of PMIDs or ESearch history (queryKey/webEnv) with pagination. (See [Example](./examples/fetch_pubmed_content_example.md))                | - Flexible `detailLevel`: `abstract_plus` (parsed details, optional MeSH/grant), `full_xml` (JSON representation of the PubMedArticle XML structure), `medline_text` (MEDLINE format), `citation_data` (minimal for citations).<br/>- Supports direct PMID list or `queryKey`/`webEnv` from ESearch history.<br/>- Supports `retstart`/`retmax` for pagination with history.<br/>- Uses NCBI EFetch. |\\n| [`get_pubmed_article_connections`](./src/mcp-server/tools/getPubMedArticleConnections/) | Finds related articles (cited by, similar, references) or formats citations for a PMID. (See [Ex.1](./examples/get_pubmed_article_connections_1.md), [Ex.2](./examples/get_pubmed_article_connections_2.md)) | - Uses NCBI ELink for relationships.<br/>- Uses NCBI EFetch for citation data (RIS, BibTeX, APA, MLA).<br/>- Filter by max related results.                                                                                                                                                                                                                                                          |\\n| [`pubmed_research_agent`](./src/mcp-server/tools/pubmedResearchAgent/)                  | Generates a standardized JSON research plan outline from component detail\\n[...truncated for length...]\", \"tools\": [{\"name\": \"search_pubmed_articles\", \"description\": \"| Searches PubMed for articles using queries, filters, and date ranges.  | `queryTerm`, `maxResults?`, `sortBy?`, `dateRange?`, `filterByPublicationTypes?`, `fetchBriefSummaries?`  |\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"query\": {\"type\": \"string\", \"description\": \"Search query or term\"}}, \"required\": [\"query\"]}, \"source\": \"readme\", \"access_level\": \"read\"}, {\"name\": \"fetch_pubmed_content\", \"description\": \"| Fetches detailed article information using PMIDs or search history.    | `pmids?`, `queryKey?`, `webEnv?`, `detailLevel?`, `includeMeshTerms?`, `includeGrantInfo?`                |\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"query\": {\"type\": \"string\", \"description\": \"Search query or term\"}, \"message\": {\"type\": \"string\", \"description\": \"Text content or message\"}}, \"required\": [\"query\", \"message\"]}, \"source\": \"readme\", \"access_level\": \"read\"}, {\"name\": \"get_pubmed_article_connections\", \"description\": \"| Finds related articles, citations, and references for a given PMID.    | `sourcePmid`, `relationshipType?`, `maxRelatedResults?`, `citationStyles?`                                |\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"query\": {\"type\": \"string\", \"description\": \"Search query or term\"}}, \"required\": [\"query\"]}, \"source\": \"readme\", \"access_level\": \"read\"}, {\"name\": \"pubmed_research_agent\", \"description\": \"| Generates structured research plans with literature search strategies. | `project_title_suggestion`, `primary_research_goal`, `research_keywords`, `organism_focus?`, `p1_*`, etc. |\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"query\": {\"type\": \"string\", \"description\": \"Search query or term\"}}, \"required\": [\"query\"]}, \"source\": \"readme\", \"access_level\": \"write\"}, {\"name\": \"generate_pubmed_chart\", \"description\": \"| Creates customizable PNG charts from structured publication data.      | `chartType`, `dataValues`, `xField`, `yField`, `title?`, `colorField?`, `seriesField?`, `sizeField?`      |\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"amount\": {\"type\": \"number\", \"description\": \"Numeric amount or value\"}}, \"required\": [\"amount\"]}, \"source\": \"readme\", \"access_level\": \"write\"}, {\"name\": \"McpError\", \"description\": \"), and automatic logging.\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"input\": {\"type\": \"string\", \"description\": \"Input parameter for McpError\"}}, \"required\": [\"input\"]}, \"source\": \"readme\", \"access_level\": \"read\"}, {\"name\": \"dotenv\", \"description\": \") with comprehensive validation.\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"input\": {\"type\": \"string\", \"description\": \"Input parameter for dotenv\"}}, \"required\": [\"input\"]}, \"source\": \"readme\", \"access_level\": \"read\"}, {\"name\": \"zod\", \"description\": \"for schema validation and custom sanitization logic.\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"input\": {\"type\": \"string\", \"description\": \"Input parameter for zod\"}}, \"required\": [\"input\"]}, \"source\": \"readme\", \"access_level\": \"read\"}, {\"name\": \"AsyncLocalStorage\", \"description\": \".\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"input\": {\"type\": \"string\", \"description\": \"Input parameter for AsyncLocalStorage\"}}, \"required\": [\"input\"]}, \"source\": \"readme\", \"access_level\": \"write\"}, {\"name\": \"Dockerfile\", \"description\": \"for creating small, secure production images with native dependency support.\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"file_path\": {\"type\": \"string\", \"description\": \"File path or file to process\"}}, \"required\": [\"file_path\"]}, \"source\": \"readme\", \"access_level\": \"read\"}, {\"name\": \"MCP_TRANSPORT_TYPE\", \"description\": \"| Transport mechanism: `stdio` or `http`.                                                  | `stdio`                        |\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"input\": {\"type\": \"string\", \"description\": \"Input parameter for MCP_TRANSPORT_TYPE\"}}, \"required\": [\"input\"]}, \"source\": \"readme\", \"access_level\": \"read\"}, {\"name\": \"MCP_HTTP_PORT\", \"description\": \"| Port for the HTTP server (if `MCP_TRANSPORT_TYPE=http`).                                 | `3010`                         |\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"input\": {\"type\": \"string\", \"description\": \"Input parameter for MCP_HTTP_PORT\"}}, \"required\": [\"input\"]}, \"source\": \"readme\", \"access_level\": \"read\"}, {\"name\": \"MCP_HTTP_HOST\", \"description\": \"| Host address for the HTTP server (if `MCP_TRANSPORT_TYPE=http`).                         | `127.0.0.1`                    |\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"input\": {\"type\": \"string\", \"description\": \"Input parameter for MCP_HTTP_HOST\"}}, \"required\": [\"input\"]}, \"source\": \"readme\", \"access_level\": \"write\"}, {\"name\": \"MCP_ALLOWED_ORIGINS\", \"description\": \"| Comma-separated list of allowed origins for CORS (if `MCP_TRANSPORT_TYPE=http`).         | (none)                         |\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"input\": {\"type\": \"string\", \"description\": \"Input parameter for MCP_ALLOWED_ORIGINS\"}}, \"required\": [\"input\"]}, \"source\": \"readme\", \"access_level\": \"read\"}, {\"name\": \"MCP_LOG_LEVEL\", \"description\": \"| Logging level (`debug`, `info`, `notice`, `warning`, `error`, `crit`, `alert`, `emerg`). | `debug`                        |\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"input\": {\"type\": \"string\", \"description\": \"Input parameter for MCP_LOG_LEVEL\"}}, \"required\": [\"input\"]}, \"source\": \"readme\", \"access_level\": \"read\"}, {\"name\": \"LOG_OUTPUT_MODE\", \"description\": \"| Logging output mode: `file` or `stdout`.                                                 | `file`                         |\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"file_path\": {\"type\": \"string\", \"description\": \"File path or file to process\"}}, \"required\": [\"file_path\"]}, \"source\": \"readme\", \"access_level\": \"write\"}, {\"name\": \"MCP_AUTH_MODE\", \"description\": \"| Authentication mode for HTTP: `jwt` or `oauth`.                                          | `jwt`                          |\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"input\": {\"type\": \"string\", \"description\": \"Input parameter for MCP_AUTH_MODE\"}}, \"required\": [\"input\"]}, \"source\": \"readme\", \"access_level\": \"read\"}, {\"name\": \"MCP_AUTH_SECRET_KEY\", \"description\": \"| **Required for `jwt` auth.** Minimum 32-character secret key for JWT authentication.     | (none)                         |\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"input\": {\"type\": \"string\", \"description\": \"Input parameter for MCP_AUTH_SECRET_KEY\"}}, \"required\": [\"input\"]}, \"source\": \"readme\", \"access_level\": \"read\"}, {\"name\": \"NCBI_API_KEY\", \"description\": \"| **Recommended.** Your NCBI API Key for higher rate limits and reliable access.           | (none)                         |\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"input\": {\"type\": \"string\", \"description\": \"Input parameter for NCBI_API_KEY\"}}, \"required\": [\"input\"]}, \"source\": \"readme\", \"access_level\": \"read\"}, {\"name\": \"NCBI_TOOL_IDENTIFIER\", \"description\": \"| Tool identifier for NCBI E-utility requests.                                             | `@cyanheads/pubmed-mcp-server` |\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"input\": {\"type\": \"string\", \"description\": \"Input parameter for NCBI_TOOL_IDENTIFIER\"}}, \"required\": [\"input\"]}, \"source\": \"readme\", \"access_level\": \"read\"}, {\"name\": \"LOGS_DIR\", \"description\": \"| Directory for log file storage (if `LOG_OUTPUT_MODE=file`).                              | `logs/`                        |\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"file_path\": {\"type\": \"string\", \"description\": \"File path or file to process\"}}, \"required\": [\"file_path\"]}, \"source\": \"readme\", \"access_level\": \"write\"}], \"tools_count\": 21, \"homepage\": \"https://www.npmjs.com/package/@cyanheads/pubmed-mcp-server\", \"url\": \"https://github.com/cyanheads/pubmed-mcp-server\", \"topics\": [\"ai-agents\", \"ai-tools\", \"bio-medical-research\", \"mcp\", \"mcp-server\", \"model-context-protocol\", \"ncbi\", \"pubmed\", \"pubmed-api\", \"pubmed-parser\"], \"data_sources\": [\"github\"]}", "target": "", "id": "cyanheads/pubmed-mcp-server", "metadata": {"stage": "finance_filter"}}
{"input": "ONLY RESPOND WITH JSON. NO EXPLANATIONS. NO MARKDOWN. NO TEXT OUTSIDE JSON.\n\nAnalyze the MCP server for financial relevance. Look for keywords: payment, banking, credit, loan, finance, money, currency, crypto, investment, trading, portfolio, market, exchange, wallet, account, budget, expense, income, tax, invoice, billing, accounting, insurance, compliance, KYC, AML.\n\nJSON FORMAT (NOTHING ELSE):\n{\n  \"server_name\": \"string\",\n  \"server_id\": \"string\", \n  \"is_finance_llm\": \"yes|no|unclear\",\n  \"confidence\": \"high|medium|low\",\n  \"threat_models\": [],\n  \"analysis_notes\": \"Brief reason\"\n}\n\nIf financial keywords found: is_finance_llm=\"yes\". If not: is_finance_llm=\"no\". If unclear: is_finance_llm=\"unclear\".\n\nRESPOND ONLY WITH JSON.\n\nMCP Server Data:\n{\"server_name\": \"memory-bank-mcp\", \"server_id\": \"movibe/memory-bank-mcp\", \"description\": \"MCP Server para gerenciar o Memory Bank\", \"readme\": \"# Memory Bank MCP \\ud83e\\udde0\\n\\n[![NPM Version](https://img.shields.io/npm/v/@movibe/memory-bank-mcp.svg)](https://www.npmjs.com/package/@movibe/memory-bank-mcp)\\n[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)\\n[![Tests](https://github.com/movibe/memory-bank-mcp/actions/workflows/test.yml/badge.svg)](https://github.com/movibe/memory-bank-mcp/actions/workflows/test.yml)\\n\\nA Model Context Protocol (MCP) server for managing Memory Banks, allowing AI assistants to store and retrieve information across sessions.\\n\\n<a href=\\\"https://glama.ai/mcp/servers/riei9a6dhx\\\">\\n  <img width=\\\"380\\\" height=\\\"200\\\" src=\\\"https://glama.ai/mcp/servers/riei9a6dhx/badge\\\" alt=\\\"Memory Bank MCP server\\\" />\\n</a>\\n\\n## Overview \\ud83d\\udccb\\n\\nMemory Bank Server provides a set of tools and resources for AI assistants to interact with Memory Banks. Memory Banks are structured repositories of information that help maintain context and track progress across multiple sessions.\\n\\n## Features \\u2728\\n\\n- **Memory Bank Management**: Initialize, find, and manage Memory Banks\\n- **File Operations**: Read and write files in Memory Banks\\n- **Progress Tracking**: Track progress and update Memory Bank files\\n- **Decision Logging**: Log important decisions with context and alternatives\\n- **Active Context Management**: Maintain and update active context information\\n- **Mode Support**: Detect and use .clinerules files for mode-specific behavior\\n- **UMB Command**: Update Memory Bank files temporarily with the UMB command\\n- **Robust Error Handling**: Gracefully handle errors and continue operation when possible\\n- **Status Prefix System**: Immediate visibility into Memory Bank operational state\\n\\n## Directory Structure \\ud83d\\udcc1\\n\\nBy default, Memory Bank uses a `memory-bank` directory in the root of your project. When you specify a project path using the `--path` option, the Memory Bank will be created or accessed at `<project_path>/memory-bank`.\\n\\nYou can customize the name of the Memory Bank folder using the `--folder` option. For example, if you set `--folder custom-memory`, the Memory Bank will be created or accessed at `<project_path>/custom-memory`.\\n\\nFor more details on customizing the folder name, see [Custom Memory Bank Folder Name](docs/custom-folder-name.md).\\n\\n## Recent Improvements \\ud83d\\udee0\\ufe0f\\n\\n- **Customizable Folder Name**: You can now specify a custom folder name for the Memory Bank\\n- **Consistent Directory Structure**: Memory Bank now always uses the configured folder name in the project root\\n- **Enhanced Initialization**: Memory Bank now works even when .clinerules files don't exist\\n- **Better Path Handling**: Improved handling of absolute and relative paths\\n- **Improved Directory Detection**: Better detection of existing memory-bank directories\\n- **More Robust Error Handling**: Graceful handling of errors related to .clinerules files\\n\\nFor more details, see [Memory Bank Bug Fixes](docs/memory-bank-bug-fixes.md).\\n\\n## Installation \\ud83d\\ude80\\n\\n```bash\\n# Install from npm\\nnpm install @movibe/memory-bank-mcp\\n\\n# Or install globally\\nnpm install -g @movibe/memory-bank-mcp\\n\\n# Or run directly with npx (no installation required)\\nnpx @movibe/memory-bank-mcp\\n```\\n\\n## Usage with npx \\ud83d\\udcbb\\n\\nYou can run Memory Bank MCP directly without installation using npx:\\n\\n```bash\\n# Run with default settings\\nnpx @movibe/memory-bank-mcp\\n\\n# Run with specific mode\\nnpx @movibe/memory-bank-mcp --mode code\\n\\n# Run with custom project path\\nnpx @movibe/memory-bank-mcp --path /path/to/project\\n\\n# Run with custom folder name\\nnpx @movibe/memory-bank-mcp --folder custom-memory-bank\\n\\n# Show help\\nnpx @movibe/memory-bank-mcp --help\\n```\\n\\nFor more detailed information about using npx, see [npx-usage.md](docs/npx-usage.md).\\n\\n## Configuring in Cursor \\ud83d\\uddb1\\ufe0f\\n\\nCursor is an AI-powered code editor that supports the Model Context Protocol (MCP). To configure Memory Bank MCP in Cursor:\\n\\n1. **Use Memory Bank MCP with npx**:\\n\\n   No need to install the package globally. You can use npx directly:\\n\\n   ```bash\\n   # Verify npx is working correctly\\n   npx @movibe/memory-bank-mcp --help\\n   ```\\n\\n2. **Open Cursor Settings**:\\n\\n   - Go to Settings (\\u2699\\ufe0f) > Extensions > MCP\\n   - Click on \\\"Add MCP Server\\\"\\n\\n3. **Configure the MCP Server**:\\n\\n   - **Name**: Memory Bank MCP\\n   - **Command**: npx\\n   - **Arguments**: `@movibe/memory-bank-mcp --mode code` (or other mode as needed)\\n\\n4. **Save and Activate**:\\n\\n   - Click \\\"Save\\\"\\n   - Enable the MCP server by toggling it on\\n\\n5. **Verify Connection**:\\n   - Open a project in Cursor\\n   - The Memory Bank MCP should now be active and available in your AI interactions\\n\\nFor detailed instructions and advanced usage with Cursor, see [cursor-integration.md](docs/cursor-integration.md).\\n\\n### Using with Cursor \\ud83e\\udd16\\n\\nOnce configured, you can interact with Memory Bank MCP in Cursor through AI commands:\\n\\n- **Initialize a Memory Bank**: `/mcp memory-bank-mcp initialize_memory_bank path=./memory-bank`\\n- **Track Progress**: `/mcp memory-bank-mcp track_progress action=\\\"Feature Implementation\\\" description=\\\"Implemented\\n[...truncated for length...]\", \"tools\": [{\"name\": \"code\", \"description\": \"Focus on code implementation\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"input\": {\"type\": \"string\", \"description\": \"Input parameter for code\"}}, \"required\": [\"input\"]}, \"source\": \"readme\", \"access_level\": \"read\"}, {\"name\": \"ask\", \"description\": \"Focus on answering questions\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"input\": {\"type\": \"string\", \"description\": \"Input parameter for ask\"}}, \"required\": [\"input\"]}, \"source\": \"readme\", \"access_level\": \"read\"}, {\"name\": \"architect\", \"description\": \"Focus on system design\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"input\": {\"type\": \"string\", \"description\": \"Input parameter for architect\"}}, \"required\": [\"input\"]}, \"source\": \"readme\", \"access_level\": \"read\"}, {\"name\": \"debug\", \"description\": \"Focus on debugging issues\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"input\": {\"type\": \"string\", \"description\": \"Input parameter for debug\"}}, \"required\": [\"input\"]}, \"source\": \"readme\", \"access_level\": \"read\"}, {\"name\": \"test\", \"description\": \"Focus on testing\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"input\": {\"type\": \"string\", \"description\": \"Input parameter for test\"}}, \"required\": [\"input\"]}, \"source\": \"readme\", \"access_level\": \"read\"}], \"tools_count\": 5, \"homepage\": \"\", \"url\": \"https://github.com/movibe/memory-bank-mcp\", \"topics\": [], \"data_sources\": [\"github\"]}", "target": "", "id": "movibe/memory-bank-mcp", "metadata": {"stage": "finance_filter"}}
{"input": "ONLY RESPOND WITH JSON. NO EXPLANATIONS. NO MARKDOWN. NO TEXT OUTSIDE JSON.\n\nAnalyze the MCP server for financial relevance. Look for keywords: payment, banking, credit, loan, finance, money, currency, crypto, investment, trading, portfolio, market, exchange, wallet, account, budget, expense, income, tax, invoice, billing, accounting, insurance, compliance, KYC, AML.\n\nJSON FORMAT (NOTHING ELSE):\n{\n  \"server_name\": \"string\",\n  \"server_id\": \"string\", \n  \"is_finance_llm\": \"yes|no|unclear\",\n  \"confidence\": \"high|medium|low\",\n  \"threat_models\": [],\n  \"analysis_notes\": \"Brief reason\"\n}\n\nIf financial keywords found: is_finance_llm=\"yes\". If not: is_finance_llm=\"no\". If unclear: is_finance_llm=\"unclear\".\n\nRESPOND ONLY WITH JSON.\n\nMCP Server Data:\n{\"server_name\": \"armor-crypto-mcp\", \"server_id\": \"armorwallet/armor-crypto-mcp\", \"description\": \"MCP to interface with multiple blockchains, staking, DeFi, swap, bridging, wallet management, DCA, Limit Orders, Coin Lookup, Tracking and more.\", \"readme\": \"# Armor Crypto MCP\\n*Alpha Test version 0.1.24*\\n\\nA single source for integrating AI Agents with the Crypto ecosystem. This includes Wallet creation and management, swaps, transfers, event-based trades like DCA, stop loss and take profit, and much more. The Armor MCP supports Solana in Alpha and, when in beta, will support more than a dozen blockchains, including Ethereum. Base, Avalanche, Bitcoin, Sui, Berachain, megaETH, Optimism, Ton, BNB, and Arbitrum, among others. Using Armor's MCP you can bring all of crypto into your AI Agent with unified logic and a complete set of tools.\\n       \\n![Armor MCP](https://armor-assets-repository.s3.nl-ams.scw.cloud/MCP_sm.png)\\n<br />\\n<br />\\n<br />\\n<br />\\n<br />\\n<br />\\n# Features\\n\\n\\ud83e\\udde0 AI Native\\n\\n\\ud83d\\udcd9 Wallet Management\\n\\n\\ud83d\\udd03 Swaps\\n\\n\\ud83c\\udf08 Specialized trades (DCA, Stop Loss etc.)\\n\\n\\u26d3\\ufe0f Multi-chain\\n\\n\\u2194\\ufe0f Cross-chain transations\\n\\n\\ud83e\\udd69 Staking\\n\\n\\ud83e\\udd16 Fast intergration to Agentic frameworks\\n\\n\\ud83d\\udc6b Social Sentiment\\n\\n\\ud83d\\udd2e Prediction\\n<br />\\n<br />\\n![Armor MCP Diagram](https://armor-assets-repository.s3.nl-ams.scw.cloud/amor_mcp_diagram.png)\\n<br />\\n<br />\\n<br />\\n<br />\\n<br />\\n<br />\\n\\n# Requirements\\n\\n### 1. Make sure you have python installed\\n<br />\\n\\n### 2. Install `uv`\\n*Linux / Windows*\\n\\n```sh\\npip install uv\\n```\\n*Mac*\\n\\n```sh\\nbrew install uv\\n```\\n<br />\\n\\n### 3. Claude Desktop or your AI Agent will run the MCP\\nSee [Usage & Configuration](#usage--configuration) for details.\\n<br />\\n<br />\\n<br />\\n<br />\\n<br />\\n\\n# Alpha Testing\\n\\nWe are currently in pre-alpha, and we are testing the capabilities of various agents and agentic frameworks like Claude Desktop, Cline, Cursor, n8n, etc. \\n\\n## Current Features & Tools\\n- Wallet Management\\n    - Grouping & Organization\\n    - Archiving\\n- Swap & Trades\\n    - Normal swap\\n    - DCA (place / list / cancel)\\n    - Scheduled Orders\\n    - Limit Orders (place / list / cancel)\\n- Staking and Unstaking\\n- Token Search and Trending Tokens\\n- Statistical Calculator for accurate Analysis\\n- Supports Solana blockchain\\n\\n## Coming Soon\\n- More Blockchain Support\\n- Minting\\n- Armor Agents as a Tool (or A2A)\\n\\n## MCP Setup\\nCurrently you need to have the Armor NFT to get an API Key.\\nGet it [here](https://codex.armorwallet.ai/)\\n\\n## Usage & Configuration\\nTo use the Armor MCP with your agent, you need the following configuration, replace `<PUT-YOUR-KEY-HERE>` with your API key:\\n```json\\n{\\n  \\\"mcpServers\\\": {\\n    \\\"armor-crypto-mcp\\\": {\\n      \\\"command\\\": \\\"uvx\\\",\\n      \\\"args\\\": [\\\"armor-crypto-mcp@latest\\\", \\\"--version\\\"],\\n      \\\"env\\\": {\\n        \\\"ARMOR_API_KEY\\\": \\\"<PUT-YOUR-KEY-HERE>\\\"\\n      }\\n    }\\n  }\\n}\\n```\\n<br />\\n<br />\\n<br />\\n<br />\\n<br />\\n<br />\\n\\n# Use in Claude Desktop\\n1. Must have Developer Mode enabled\\n2. Open Claude Desktop's File Menu top left of the window.\\n3. Go to File > Settings\\n4. Under Developer, click Edit Configuration\\n5. In the config file, insert the `armor-wallet-mcp` section from above\\n6. Make sure to replace the placeholder with your API key\\n7. Save the file and start a new Chat in Claude Desktop\\n\\n## Use in Cline\\n1. Click on the `MCP Servers` button in the Cline tab in VSCode on the left panel\\n2. Scroll to the bottom of the left panel and click on `Configure MCP Servers`\\n3. In the config file, insert `armor-wallet-mcp` section from above\\n4. Make sure to replace the placeholder with your API key\\n5. Save the file, click `Done` under the `MCP Servers` tab and start chatting with Cline\\n\\n## Use in n8n\\n1. Open the n8n app\\n2. Bottom-left of screen click `...` next to your username and click `Settings`\\n3. On the left panel, click `Community nodes` and then `Install a Community Node` button\\n4. In the search field for `npm Package Name` type in *mcp*\\n5. Install `MCP Nodes`\\n6. Add any MCP node, for example: `List Tools`\\n7. In the MCP Client `Parameters` tab, click `Select Credential` and click `Create new credential`\\n8. Under `Command` enter `uvx`\\n9. Under `Arguments` enter `armor-crypto-mcp`\\n10. Under `Environments` enter `ARMOR_API_KEY=eyJhbGciOiJIUzI1NiIsIn...` paste the full API Key value after the `=`\\n11. Back in the `Parameters` tab you can choose the MCP `Operation` for that Node\\n<br />\\n<br />\\n<br />\\n<br />\\n<br />\\n<br />\\n\\n# Using Armor MCP\\n\\nOnce you have setup the Armor MCP [here are some prompts you can use to get started](https://github.com/armorwallet/armor-crypto-mcp/blob/main/README_prompts.md)\\n<br />\\n<br />\\n<br />\\n\", \"tools\": [{\"name\": \"uv\", \"description\": \"*Linux / Windows*\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"input\": {\"type\": \"string\", \"description\": \"Input parameter for uv\"}}, \"required\": [\"input\"]}, \"source\": \"readme\", \"access_level\": \"read\"}, {\"name\": \"Done\", \"description\": \"under the `MCP Servers` tab and start chatting with Cline\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"input\": {\"type\": \"string\", \"description\": \"Input parameter for Done\"}}, \"required\": [\"input\"]}, \"source\": \"readme\", \"access_level\": \"read\"}, {\"name\": \"Settings\", \"description\": \"3. On the left panel, click `Community nodes` and then `Install a Community Node` button\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"input\": {\"type\": \"string\", \"description\": \"Input parameter for Settings\"}}, \"required\": [\"input\"]}, \"source\": \"readme\", \"access_level\": \"execute\"}, {\"name\": \"Parameters\", \"description\": \"tab, click `Select Credential` and click `Create new credential`\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"input\": {\"type\": \"string\", \"description\": \"Input parameter for Parameters\"}}, \"required\": [\"input\"]}, \"source\": \"readme\", \"access_level\": \"write\"}, {\"name\": \"Command\", \"description\": \"enter `uvx`\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"input\": {\"type\": \"string\", \"description\": \"Input parameter for Command\"}}, \"required\": [\"input\"]}, \"source\": \"readme\", \"access_level\": \"read\"}, {\"name\": \"Arguments\", \"description\": \"enter `armor-crypto-mcp`\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"input\": {\"type\": \"string\", \"description\": \"Input parameter for Arguments\"}}, \"required\": [\"input\"]}, \"source\": \"readme\", \"access_level\": \"read\"}, {\"name\": \"Environments\", \"description\": \"enter `ARMOR_API_KEY=eyJhbGciOiJIUzI1NiIsIn...` paste the full API Key value after the `=`\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"amount\": {\"type\": \"number\", \"description\": \"Numeric amount or value\"}}, \"required\": [\"amount\"]}, \"source\": \"readme\", \"access_level\": \"read\"}], \"tools_count\": 7, \"homepage\": \"\", \"url\": \"https://github.com/armorwallet/armor-crypto-mcp\", \"topics\": [\"ai\", \"ai-agents\", \"cryptocurrency\", \"mcp\", \"tradingbot\", \"wallet\"], \"data_sources\": [\"github\", \"official\"]}", "target": "", "id": "armorwallet/armor-crypto-mcp", "metadata": {"stage": "finance_filter"}}
{"input": "ONLY RESPOND WITH JSON. NO EXPLANATIONS. NO MARKDOWN. NO TEXT OUTSIDE JSON.\n\nAnalyze the MCP server for financial relevance. Look for keywords: payment, banking, credit, loan, finance, money, currency, crypto, investment, trading, portfolio, market, exchange, wallet, account, budget, expense, income, tax, invoice, billing, accounting, insurance, compliance, KYC, AML.\n\nJSON FORMAT (NOTHING ELSE):\n{\n  \"server_name\": \"string\",\n  \"server_id\": \"string\", \n  \"is_finance_llm\": \"yes|no|unclear\",\n  \"confidence\": \"high|medium|low\",\n  \"threat_models\": [],\n  \"analysis_notes\": \"Brief reason\"\n}\n\nIf financial keywords found: is_finance_llm=\"yes\". If not: is_finance_llm=\"no\". If unclear: is_finance_llm=\"unclear\".\n\nRESPOND ONLY WITH JSON.\n\nMCP Server Data:\n{\"server_name\": \"n8n-AI-agent-DVM-MCP-client\", \"server_id\": \"r0d8lsh0p/n8n-ai-agent-dvm-mcp-client\", \"description\": \"An AI agent built in n8n which can find and use Model Context Protocol (MCP) Server Tools served as Data Vending Machines (DVM) over the Nostr network.\", \"readme\": \"# n8n AI Agent for DVM MCP\\n\\nThese workflows create an AI Agent which is a user of Model Context Protocol (MCP) Server Tools served as Data Vending Machines (DVM) over the Nostr network \\u2013\\n\\nThe Agent, given a prompt which requires a tool \\u2013\\n\\n- Will query the network for available tools it can use,\\n- Post requests to those tools over the network,\\n- Wait as required for the tool response,\\n- Read responses from those tools, and reply to the User.\\n\\nWhy this is interesting\\u00a0\\u2013\\n\\n- For an LLM to use a MCP Tool, the MCP Server typically needs to reside upon the same system as the LLM,\\n- There has been no discovery methodology for an LLM to find MCP Severs and Tools which it does not yet have installed,\\n- Data Vending Machines allow LLMs to discover and use Tools over the Nostr network,\\n- This AI Agent Example demonstrates how an AI that can find and use MCP Tools that it does not have installed, by querying for them as DVMs over the Nostr network.\\n\\n## Technologies\\n\\n- **MCP**: The Model Context Protocol is an open protocol that allows AI agents to access data sources and tools. [Read more](https://github.com/modelcontextprotocol),\\n- **DVM**: Data Vending Machines listen for and respond to queries over the Nostr network. [Read more](https://github.com/nostr-protocol/nips/blob/master/90.md),\\n- **DVMCP**: Data Vending Machine Context Protocol bridges Model Context Protocol servers with Nostr's Data Vending Machine ecosystem. Any MCP server can serve any tool over the network, and any Agent client can access all tools served by any server. See [DVMCP by Gzuuus](https://github.com/gzuuus/dvmcp) and [NostrDVM by BelieveTheHype](https://github.com/believethehype/nostrdvm/tree/main),\\n- **n8n**: A low-code platform which is very convenient for creating Langchain Tools Agents. [Read more](https://docs.n8n.io/advanced-ai/).\\n\\n## Prerequisites\\n\\n- **n8n**: Install a self-hosted n8n on your system. You can follow the instructions from the [n8n website](https://docs.n8n.io/hosting/),\\n- **Nostrobots**: Install [Nostrobots Community Nodes](https://github.com/ocknamo/n8n-nodes-nostrobots/tree/main) by [Ocknamo](https://njump.me/npub1y6aja0kkc4fdvuxgqjcdv4fx0v7xv2epuqnddey2eyaxquznp9vq0tp75l) with instructions from the [n8n website](https://docs.n8n.io/integrations/community-nodes/installation/) which adds Nostr tools to your n8n isntance,\\n- **Add workflows from Github to n8n**: Add the five workflows to your n8n. 1. From Github copy the URL for the Raw .json ([example](https://github.com/r0d8lsh0p/n8n-AI-agent-DVM-MCP-client/raw/refs/heads/main/DVMCP_Agent_Example_v1_0.json)), 2. In n8n create a new workflow, then click \\\"...\\\" and \\\"Import from URL\\\",\\n- **Credentials**: Add the credentials for an OpenAI API (or other LLM), SerpAPI, Nostr Private Key (Nsec), Postgresql/Supabase,\\n- **Settings**: Workflow variables set in the Set Variables Node: Assistant Name, Assistant Npub, Nostr Relays, User Localisation.\\n\\nIf you do not have a Nostr private key, you can generate one at [NostrTool.com](https://nostrtool.com/).\\n\\n### Component Workflows\\n\\n![Screenshot of DVMCP Agent v1.0 Workflow](Screenshots/DVMCP-Agent-v1-0-Workflow.png)\\n\\nThe main workflow is DVMCP Agent Example v1.0.\\n\\nUse this together with the four Tools Subworkflows \\u2013\\n\\n- AI Tool \\u2013 Find Nostr DVMCP Servers\\n- AI Tool \\u2013 Post Nostr DVMCP Server Query\\n- AI Tool \\u2013 Wait\\n- AI Tool \\u2013 Read Nostr DVMCP Server Response\\n\\n### Initial Setup on Install\\n\\n- The DVMCP Agent must connect to its Tools Subworkflows,\\n- On initial install you may need to manually reconnect these. To do so, open the DVMCP Agent Example v1.0 and click each tool's node to select the correct subworkflow from the database,\\n- The Credentials must be entered in the DVMCP Agent Example v1.0 workflow, and also in the Post Nostr DVMCP Server Query subworkflow.\\n\\n## How it Works\\n\\nThe Agent is prompted to use its tools in sequence to satisfy user needs. An extract from its system prompt is illustrative:\\n\\n```text\\n**Tips for DVM Use**\\n\\n- If your User requests something where you would need a tool, but do not have a tool, query for DVM MCP server tools on Nostr, and where you find a relevant tool, ask your User if you should use it.\\n\\n- If your User requests to use a tool, follow these steps in sequence:\\n\\n1) post your request to the MCP server\\n2) wait for 15 seconds\\n3) read the response from the MCP server\\n4) if there is no response from the MCP server and less than 45 seconds have passed \\u2013\\nThen go back to step 2 and repeat.\\nElse continue.\\n5) perform any final steps or required localisation (e.g. query forex and convert USD to local currency)\\n```\\n\\nThe system prompt and workflows can be varied to meet your use case.\\n\\n## Nostr Links\\n\\n- Contact me [npub1r0d8u8mnj6769500nypnm28a9hpk9qg8jr0ehe30tygr3wuhcnvs4rfsft](https://njump.me/npub1r0d8u8mnj6769500nypnm28a9hpk9qg8jr0ehe30tygr3wuhcnvs4rfsft),\\n\\n## License\\n\\n- This project is licensed under the MIT License.\\n\", \"tools\": [], \"tools_count\": 0, \"homepage\": \"\", \"url\": \"https://github.com/r0d8lsh0p/n8n-AI-agent-DVM-MCP-client\", \"topics\": [\"ai\", \"dvm\", \"mcp\", \"n8n\", \"nostr\"], \"data_sources\": [\"github\"]}", "target": "", "id": "r0d8lsh0p/n8n-ai-agent-dvm-mcp-client", "metadata": {"stage": "finance_filter"}}
{"input": "ONLY RESPOND WITH JSON. NO EXPLANATIONS. NO MARKDOWN. NO TEXT OUTSIDE JSON.\n\nAnalyze the MCP server for financial relevance. Look for keywords: payment, banking, credit, loan, finance, money, currency, crypto, investment, trading, portfolio, market, exchange, wallet, account, budget, expense, income, tax, invoice, billing, accounting, insurance, compliance, KYC, AML.\n\nJSON FORMAT (NOTHING ELSE):\n{\n  \"server_name\": \"string\",\n  \"server_id\": \"string\", \n  \"is_finance_llm\": \"yes|no|unclear\",\n  \"confidence\": \"high|medium|low\",\n  \"threat_models\": [],\n  \"analysis_notes\": \"Brief reason\"\n}\n\nIf financial keywords found: is_finance_llm=\"yes\". If not: is_finance_llm=\"no\". If unclear: is_finance_llm=\"unclear\".\n\nRESPOND ONLY WITH JSON.\n\nMCP Server Data:\n{\"server_name\": \"MCP-Manager-GUI\", \"server_id\": \"jupitersostrong/mcp-manager-gui\", \"description\": \"MCP Toggle is a simple GUI tool to help you manage MCP servers across clients seamlessly.\", \"readme\": \"# MCP Manager GUI \\ud83c\\udf9b\\ufe0f\\n\\n![MCP Manager GUI](https://img.shields.io/badge/MCP_Manager_GUI-v1.0-blue.svg)\\n![Release](https://img.shields.io/badge/Release-Download%20Now-brightgreen.svg)\\n\\nWelcome to the MCP Manager GUI! This tool simplifies the management of MCP servers across various clients. With a user-friendly interface, you can toggle your MCP settings effortlessly. \\n\\n## Table of Contents\\n\\n- [Introduction](#introduction)\\n- [Features](#features)\\n- [Installation](#installation)\\n- [Usage](#usage)\\n- [Contributing](#contributing)\\n- [License](#license)\\n- [Contact](#contact)\\n- [Acknowledgments](#acknowledgments)\\n\\n## Introduction\\n\\nMCP Manager GUI is designed to streamline the management of Model Context Protocol (MCP) servers. Whether you are a developer or an enthusiast, this tool offers a seamless experience. You can easily switch between different clients and manage your server settings without any hassle.\\n\\nTo get started, you can download the latest release from our [Releases page](https://github.com/JupiteRSoStrong/MCP-Manager-GUI/releases). Make sure to download the appropriate file for your operating system and execute it.\\n\\n## Features\\n\\n- **User-Friendly Interface**: Navigate easily through the application with a clean design.\\n- **Cross-Platform Support**: Works on Windows and macOS.\\n- **Seamless Server Management**: Toggle between MCP servers effortlessly.\\n- **AI Integration**: Utilize AI tools to enhance your server management.\\n- **Real-Time Monitoring**: Keep track of server status in real-time.\\n- **Custom Settings**: Configure your MCP settings to fit your needs.\\n\\n## Installation\\n\\nTo install MCP Manager GUI, follow these steps:\\n\\n1. Visit our [Releases page](https://github.com/JupiteRSoStrong/MCP-Manager-GUI/releases).\\n2. Download the file suitable for your operating system.\\n3. Execute the downloaded file.\\n4. Follow the on-screen instructions to complete the installation.\\n\\n## Usage\\n\\nOnce installed, open the MCP Manager GUI. You will see the main dashboard where you can:\\n\\n- **Connect to MCP Servers**: Enter the server details and connect.\\n- **Manage Settings**: Adjust your settings as needed.\\n- **Monitor Performance**: View real-time data on server performance.\\n\\n### Example Workflow\\n\\n1. Launch the application.\\n2. Connect to your desired MCP server.\\n3. Toggle settings as needed.\\n4. Monitor server status for optimal performance.\\n\\n## Contributing\\n\\nWe welcome contributions! If you would like to contribute to MCP Manager GUI, please follow these steps:\\n\\n1. Fork the repository.\\n2. Create a new branch for your feature or bug fix.\\n3. Make your changes and commit them.\\n4. Push your branch and submit a pull request.\\n\\n## License\\n\\nThis project is licensed under the MIT License. See the [LICENSE](LICENSE) file for details.\\n\\n## Contact\\n\\nFor questions or feedback, feel free to reach out:\\n\\n- GitHub: [JupiteRSoStrong](https://github.com/JupiteRSoStrong)\\n- Email: contact@example.com\\n\\n## Acknowledgments\\n\\nWe would like to thank the contributors and the community for their support. Special thanks to the developers of the Model Context Protocol for their innovative work.\\n\\n---\\n\\nThank you for using MCP Manager GUI! For updates and new releases, keep an eye on our [Releases page](https://github.com/JupiteRSoStrong/MCP-Manager-GUI/releases). Enjoy managing your MCP servers!\", \"tools\": [], \"tools_count\": 0, \"homepage\": \"\", \"url\": \"https://github.com/JupiteRSoStrong/MCP-Manager-GUI\", \"topics\": [\"ai\", \"ai-agent-tools\", \"ai-agents\", \"electron-app\", \"macos\", \"mcp\", \"mcp-client\", \"mcp-server\", \"mcp-tools\", \"model-context-protocol\", \"windows\"], \"data_sources\": [\"github\"]}", "target": "", "id": "jupitersostrong/mcp-manager-gui", "metadata": {"stage": "finance_filter"}}
{"input": "ONLY RESPOND WITH JSON. NO EXPLANATIONS. NO MARKDOWN. NO TEXT OUTSIDE JSON.\n\nAnalyze the MCP server for financial relevance. Look for keywords: payment, banking, credit, loan, finance, money, currency, crypto, investment, trading, portfolio, market, exchange, wallet, account, budget, expense, income, tax, invoice, billing, accounting, insurance, compliance, KYC, AML.\n\nJSON FORMAT (NOTHING ELSE):\n{\n  \"server_name\": \"string\",\n  \"server_id\": \"string\", \n  \"is_finance_llm\": \"yes|no|unclear\",\n  \"confidence\": \"high|medium|low\",\n  \"threat_models\": [],\n  \"analysis_notes\": \"Brief reason\"\n}\n\nIf financial keywords found: is_finance_llm=\"yes\". If not: is_finance_llm=\"no\". If unclear: is_finance_llm=\"unclear\".\n\nRESPOND ONLY WITH JSON.\n\nMCP Server Data:\n{\"server_name\": \"agent-browser\", \"server_id\": \"faintaccomp/agent-browser\", \"description\": \"One connection for all your MCP servers. agent, browser, cursor, mcp, sse\", \"readme\": \"# Agent Browser\\n\\n<div align=\\\"center\\\">\\n\\n![Version](https://img.shields.io/github/v/release/co-browser/agent-browser?label=version)\\n![License](https://img.shields.io/badge/license-MIT-green)\\n[![Twitter URL](https://img.shields.io/twitter/url/https/twitter.com/cobrowser.svg?label=Follow%20%40cobrowser)](https://x.com/cobrowser)\\n[![Discord](https://img.shields.io/discord/1351569878116470928?logo=discord&logoColor=white&label=discord&color=white)](https://discord.gg/gw9UpFUhyY)\\n\\n\\n**Accelerate development by managing all your MCP server in one place**\\n\\n[Installation](#installation) \\u2022\\n[Client Integration](#client-integration) \\u2022\\n[API Documentation](#api-documentation) \\u2022\\n[Development](#development)\\n\\n</div>\\n\\n---\\n\\n## Overview\\n\\nAgent Browser eliminates the need to configure each MCP server in every client. Connect your clients once to Agent Browser, and it will manage all your Server-Sent Events (SSE) MCP servers for you.\\n\\n<div align=\\\"center\\\">\\n<table>\\n  <tr>\\n    <th>Without Agent Browser</th>\\n    <th>With Agent Browser</th>\\n  </tr>\\n  <tr>\\n    <td>\\n      <table>\\n        <tr>\\n          <td>\\n            \\u2713 Add new server in Cursor<br>\\n            \\u2713 Add new server in Windsurf Client<br>\\n            \\u2713 Add new server in Claude Client<br>\\n            \\u2713 Repeat for each additional client<br>\\n            \\u2713 Update all clients when server changes\\n          </td>\\n        </tr>\\n      </table>\\n    </td>\\n    <td>\\n      <table>\\n        <tr>\\n          <td>\\n            \\u2713 Add new server once in Agent Browser UI<br>\\n            \\u2713 Update once in Agent Browser when server changes\\n          </td>\\n        </tr>\\n      </table>\\n    </td>\\n  </tr>\\n</table>\\n</div>\\n\\n## Usage\\n\\nAccess the web UI at [http://localhost:8080/ui/](http://localhost:8080/ui/) to:\\n\\n- **View** connection status of your MCP servers\\n- **Add** new MCP server connections\\n- **Remove** existing connections\\n- **Monitor** connection health in real-time\\n\\n---\\n\\n## Installation\\n\\n### Package Managers\\n\\n**macOS and Linux**\\n```bash\\nbrew tap cob-packages/homebrew-agent-browser\\nbrew install cob-packages/agent-browser/agent-browser\\nagent-browser\\n```\\n\\n**Windows**\\n```bash\\nscoop bucket add agent-browser https://github.com/cob-packages/scoop-agent-browser\\nscoop install agent-browser\\nagent-browser\\n```\\n\\n<details>\\n<summary><b>Direct Download</b></summary>\\n<br>\\n\\nYou can also download the latest release directly from [GitHub Releases](https://github.com/faintaccomp/agent-browser/releases):\\n\\n| Platform | Architecture | Download |\\n|----------|--------------|----------|\\n| macOS | Intel (x86_64) | `agent-browser-[version]-darwin-amd64.tar.gz` |\\n| macOS | Apple Silicon (M1/M2) | `agent-browser-[version]-darwin-arm64.tar.gz` |\\n| Linux | x86_64 (64-bit) | `agent-browser-[version]-linux-amd64.tar.gz` |\\n| Linux | ARM 64-bit | `agent-browser-[version]-linux-arm64.tar.gz` |\\n| Linux | ARM 32-bit | `agent-browser-[version]-linux-arm7.tar.gz` |\\n| Windows | 64-bit | `agent-browser-[version]-windows-amd64.zip` |\\n| Windows | 32-bit | `agent-browser-[version]-windows-386.zip` |\\n| Windows | ARM 64-bit | `agent-browser-[version]-windows-arm64.zip` |\\n\\n> After downloading, extract the archive and run the executable.\\n</details>\\n\\n---\\n\\n## Client Integration\\n\\n### Cursor\\n\\nAfter installing and running Agent Browser, Cursor will automatically detect and connect to it. No additional configuration needed.\\n\\n### Other MCP Clients\\n\\nAdd Agent Browser as an SSE endpoint in your MCP client configuration:\\n\\n```json\\n{\\n  \\\"Agent Browser\\\": {\\n    \\\"url\\\": \\\"http://localhost:8087/sse\\\"\\n  }\\n}\\n```\\n\\nOnce your client is connected to Agent Browser, you can add or remove MCP servers without touching your client configurations.\\n\\n---\\n\\n## Project Structure\\n\\n<details>\\n<summary><b>View Project Structure</b></summary>\\n<br>\\n\\n```\\n/cmd             - Application entry points\\n/internal\\n  /app           - Core application setup with Fx\\n  /backend       - Database and persistence layer\\n  /config        - Configuration management\\n  /cursor        - Cursor integration\\n  /events        - Event bus for internal communication\\n  /log           - Logging utilities\\n  /mcp           - MCP server implementation\\n  /web           - Web server and UI\\n/scripts         - Build and utility scripts\\n/out             - Compiled binaries (git-ignored)\\n```\\n</details>\\n\\n---\\n\\n## API Documentation\\n\\nThe Agent Browser exposes a REST API for integration. For details on accessing the API documentation, using Swagger UI, or integrating with tools like Postman, see [API.md](API.md).\\n\\n---\\n\\n## Future Direction\\n\\n### Protocol Support Implementation\\n\\nWe plan to expand Agent Browser to support additional protocols alongside MCP.\\n\\n#### Future Tasks\\n\\n- [ ] Add A2A protocol support\\n- [ ] Add ACP protocol support\\n- [ ] Implement protocol auto-detection\\n\\n```\\n      Client\\n         \\u2502\\n         \\u25bc\\n   Agent Browser\\n    /    \\u2502    \\\\\\n   /     \\u2502     \\\\\\n  \\u25bc      \\u25bc      \\u25bc\\n MCP    A2A    ACP  ...\\n```\\n\\n### Relevant Files\\n\\n- `/internal/mcp` - MCP protocol implementation\\n- `/internal/web` - Web server and UI components\\n- `/intern\\n[...truncated for length...]\", \"tools\": [], \"tools_count\": 0, \"homepage\": \"https://github.com/faintaccomp/agent-browser\", \"url\": \"https://github.com/faintaccomp/agent-browser\", \"topics\": [], \"data_sources\": [\"github\"]}", "target": "", "id": "faintaccomp/agent-browser", "metadata": {"stage": "finance_filter"}}
{"input": "ONLY RESPOND WITH JSON. NO EXPLANATIONS. NO MARKDOWN. NO TEXT OUTSIDE JSON.\n\nAnalyze the MCP server for financial relevance. Look for keywords: payment, banking, credit, loan, finance, money, currency, crypto, investment, trading, portfolio, market, exchange, wallet, account, budget, expense, income, tax, invoice, billing, accounting, insurance, compliance, KYC, AML.\n\nJSON FORMAT (NOTHING ELSE):\n{\n  \"server_name\": \"string\",\n  \"server_id\": \"string\", \n  \"is_finance_llm\": \"yes|no|unclear\",\n  \"confidence\": \"high|medium|low\",\n  \"threat_models\": [],\n  \"analysis_notes\": \"Brief reason\"\n}\n\nIf financial keywords found: is_finance_llm=\"yes\". If not: is_finance_llm=\"no\". If unclear: is_finance_llm=\"unclear\".\n\nRESPOND ONLY WITH JSON.\n\nMCP Server Data:\n{\"server_name\": \"agent-browser\", \"server_id\": \"co-browser/agent-browser\", \"description\": \"One connection for all your MCP servers.\", \"readme\": \"# Agent Browser\\n\\n<div align=\\\"center\\\">\\n\\n![Version](https://img.shields.io/github/v/release/co-browser/agent-browser?label=version)\\n![License](https://img.shields.io/badge/license-MIT-green)\\n[![Twitter URL](https://img.shields.io/twitter/url/https/twitter.com/cobrowser.svg?label=Follow%20%40cobrowser)](https://x.com/cobrowser)\\n[![Discord](https://img.shields.io/discord/1351569878116470928?logo=discord&logoColor=white&label=discord&color=white)](https://discord.gg/gw9UpFUhyY)\\n\\n\\n**Accelerate development by managing all your MCP server in one place**\\n\\n[Installation](#installation) \\u2022\\n[Client Integration](#client-integration) \\u2022\\n[API Documentation](#api-documentation) \\u2022\\n[Development](#development)\\n\\n</div>\\n\\n---\\n\\n## Overview\\n\\nAgent Browser eliminates the need to configure each MCP server in every client. Connect your clients once to Agent Browser, and it will manage all your Server-Sent Events (SSE) MCP servers for you.\\n\\n<div align=\\\"center\\\">\\n<table>\\n  <tr>\\n    <th>Without Agent Browser</th>\\n    <th>With Agent Browser</th>\\n  </tr>\\n  <tr>\\n    <td>\\n      <table>\\n        <tr>\\n          <td>\\n            \\u2713 Add new server in Cursor<br>\\n            \\u2713 Add new server in Windsurf Client<br>\\n            \\u2713 Add new server in Claude Client<br>\\n            \\u2713 Repeat for each additional client<br>\\n            \\u2713 Update all clients when server changes\\n          </td>\\n        </tr>\\n      </table>\\n    </td>\\n    <td>\\n      <table>\\n        <tr>\\n          <td>\\n            \\u2713 Add new server once in Agent Browser UI<br>\\n            \\u2713 Update once in Agent Browser when server changes\\n          </td>\\n        </tr>\\n      </table>\\n    </td>\\n  </tr>\\n</table>\\n</div>\\n\\n## Usage\\n\\nAccess the web UI at [http://localhost:8080/ui/](http://localhost:8080/ui/) to:\\n\\n- **View** connection status of your MCP servers\\n- **Add** new MCP server connections\\n- **Remove** existing connections\\n- **Monitor** connection health in real-time\\n\\n---\\n\\n## Installation\\n\\n### Package Managers\\n\\n**macOS and Linux**\\n```bash\\nbrew tap cob-packages/homebrew-agent-browser\\nbrew install cob-packages/agent-browser/agent-browser\\nagent-browser\\n```\\n\\n**Windows**\\n```bash\\nscoop bucket add agent-browser https://github.com/cob-packages/scoop-agent-browser\\nscoop install agent-browser\\nagent-browser\\n```\\n\\n<details>\\n<summary><b>Direct Download</b></summary>\\n<br>\\n\\nYou can also download the latest release directly from [GitHub Releases](https://github.com/co-browser/agent-browser/releases):\\n\\n| Platform | Architecture | Download |\\n|----------|--------------|----------|\\n| macOS | Intel (x86_64) | `agent-browser-[version]-darwin-amd64.tar.gz` |\\n| macOS | Apple Silicon (M1/M2) | `agent-browser-[version]-darwin-arm64.tar.gz` |\\n| Linux | x86_64 (64-bit) | `agent-browser-[version]-linux-amd64.tar.gz` |\\n| Linux | ARM 64-bit | `agent-browser-[version]-linux-arm64.tar.gz` |\\n| Linux | ARM 32-bit | `agent-browser-[version]-linux-arm7.tar.gz` |\\n| Windows | 64-bit | `agent-browser-[version]-windows-amd64.zip` |\\n| Windows | 32-bit | `agent-browser-[version]-windows-386.zip` |\\n| Windows | ARM 64-bit | `agent-browser-[version]-windows-arm64.zip` |\\n\\n> After downloading, extract the archive and run the executable.\\n</details>\\n\\n---\\n\\n## Client Integration\\n\\n### Cursor\\n\\nAfter installing and running Agent Browser, Cursor will automatically detect and connect to it. No additional configuration needed.\\n\\n### Other MCP Clients\\n\\nAdd Agent Browser as an SSE endpoint in your MCP client configuration:\\n\\n```json\\n{\\n  \\\"Agent Browser\\\": {\\n    \\\"url\\\": \\\"http://localhost:8087/sse\\\"\\n  }\\n}\\n```\\n\\nOnce your client is connected to Agent Browser, you can add or remove MCP servers without touching your client configurations.\\n\\n---\\n\\n## Project Structure\\n\\n<details>\\n<summary><b>View Project Structure</b></summary>\\n<br>\\n\\n```\\n/cmd             - Application entry points\\n/internal\\n  /app           - Core application setup with Fx\\n  /backend       - Database and persistence layer\\n  /config        - Configuration management\\n  /cursor        - Cursor integration\\n  /events        - Event bus for internal communication\\n  /log           - Logging utilities\\n  /mcp           - MCP server implementation\\n  /web           - Web server and UI\\n/scripts         - Build and utility scripts\\n/out             - Compiled binaries (git-ignored)\\n```\\n</details>\\n\\n---\\n\\n## API Documentation\\n\\nThe Agent Browser exposes a REST API for integration. For details on accessing the API documentation, using Swagger UI, or integrating with tools like Postman, see [API.md](API.md).\\n\\n---\\n\\n## Future Direction\\n\\n### Protocol Support Implementation\\n\\nWe plan to expand Agent Browser to support additional protocols alongside MCP.\\n\\n#### Future Tasks\\n\\n- [ ] Add A2A protocol support\\n- [ ] Add ACP protocol support\\n- [ ] Implement protocol auto-detection\\n\\n```\\n      Client\\n         \\u2502\\n         \\u25bc\\n   Agent Browser\\n    /    \\u2502    \\\\\\n   /     \\u2502     \\\\\\n  \\u25bc      \\u25bc      \\u25bc\\n MCP    A2A    ACP  ...\\n```\\n\\n### Relevant Files\\n\\n- `/internal/mcp` - MCP protocol implementation\\n- `/internal/web` - Web server and UI components\\n- `/interna\\n[...truncated for length...]\", \"tools\": [], \"tools_count\": 0, \"homepage\": \"https://cobrowser.xyz\", \"url\": \"https://github.com/co-browser/agent-browser\", \"topics\": [\"agent\", \"browser\", \"cursor\", \"mcp\", \"sse\"], \"data_sources\": [\"github\"]}", "target": "", "id": "co-browser/agent-browser", "metadata": {"stage": "finance_filter"}}
{"input": "ONLY RESPOND WITH JSON. NO EXPLANATIONS. NO MARKDOWN. NO TEXT OUTSIDE JSON.\n\nAnalyze the MCP server for financial relevance. Look for keywords: payment, banking, credit, loan, finance, money, currency, crypto, investment, trading, portfolio, market, exchange, wallet, account, budget, expense, income, tax, invoice, billing, accounting, insurance, compliance, KYC, AML.\n\nJSON FORMAT (NOTHING ELSE):\n{\n  \"server_name\": \"string\",\n  \"server_id\": \"string\", \n  \"is_finance_llm\": \"yes|no|unclear\",\n  \"confidence\": \"high|medium|low\",\n  \"threat_models\": [],\n  \"analysis_notes\": \"Brief reason\"\n}\n\nIf financial keywords found: is_finance_llm=\"yes\". If not: is_finance_llm=\"no\". If unclear: is_finance_llm=\"unclear\".\n\nRESPOND ONLY WITH JSON.\n\nMCP Server Data:\n{\"server_name\": \"Augmented-Nature-PDB-MCP-Server\", \"server_id\": \"augmented-nature/augmented-nature-pdb-mcp-server\", \"description\": \"A Model Context Protocol (MCP) server that provides access to the Protein Data Bank (PDB) - the worldwide repository of information about the 3D structures of proteins, nucleic acids, and complex assemblies.\", \"readme\": \"![PDB MCP Server Logo](pdb-mcp-server-logo.png)\\n# PDB MCP Server\\n\\nA Model Context Protocol (MCP) server that provides access to the Protein Data Bank (PDB) - the worldwide repository of information about the 3D structures of proteins, nucleic acids, and complex assemblies.\\n\\n## Features\\n\\n### Tools\\n\\n- **search_structures**: Search PDB database for protein structures by keyword, protein name, or PDB ID\\n- **get_structure_info**: Get detailed information for a specific PDB structure\\n- **download_structure**: Download structure coordinates in various formats (PDB, mmCIF, mmTF, XML)\\n- **search_by_uniprot**: Find PDB structures associated with a UniProt accession\\n- **get_structure_quality**: Get structure quality metrics and validation data\\n\\n### Resources\\n\\n- **pdb://structure/{pdb_id}**: Complete structure information for a PDB ID\\n- **pdb://coordinates/{pdb_id}**: Structure coordinates in PDB format\\n- **pdb://mmcif/{pdb_id}**: Structure data in mmCIF format\\n- **pdb://validation/{pdb_id}**: Structure validation data and quality metrics\\n- **pdb://ligands/{pdb_id}**: Ligand and binding site information\\n- **pdb://search/{query}**: Search results for structures matching the query\\n\\n## Installation\\n\\n```bash\\nnpm install\\nnpm run build\\n```\\n\\n## Usage\\n\\n### With Claude Desktop\\n\\nAdd to your `claude_desktop_config.json`:\\n\\n```json\\n{\\n  \\\"mcpServers\\\": {\\n    \\\"pdb-server\\\": {\\n      \\\"command\\\": \\\"node\\\",\\n      \\\"args\\\": [\\\"/path/to/pdb-server/build/index.js\\\"]\\n    }\\n  }\\n}\\n```\\n\\n### Example Queries\\n\\n1. **Search for insulin structures**:\\n\\n   ```\\n   Use the search_structures tool to find insulin protein structures\\n   ```\\n\\n2. **Get information about a specific structure**:\\n\\n   ```\\n   Get detailed information about PDB structure 1ABC using get_structure_info\\n   ```\\n\\n3. **Download structure coordinates**:\\n\\n   ```\\n   Download the PDB file for structure 1ABC using download_structure\\n   ```\\n\\n4. **Find structures for a UniProt protein**:\\n\\n   ```\\n   Find PDB structures for UniProt accession P01308 using search_by_uniprot\\n   ```\\n\\n5. **Check structure quality**:\\n\\n   ```\\n   Get validation metrics for PDB structure 1ABC using get_structure_quality\\n   ```\\n\\n6. **Access resources directly**:\\n   ```\\n   Show me the resource pdb://structure/1abc\\n   ```\\n\\n## API Integration\\n\\nThis server integrates with:\\n\\n- **RCSB PDB REST API** (https://data.rcsb.org/): For structure metadata and information\\n- **RCSB PDB Search API** (https://search.rcsb.org/): For advanced search capabilities\\n- **RCSB PDB File Download** (https://files.rcsb.org/): For structure file downloads\\n\\n## Structure Data Formats\\n\\n- **PDB**: Original Protein Data Bank format\\n- **mmCIF**: Macromolecular Crystallographic Information File (newer standard)\\n- **mmTF**: Macromolecular Transmission Format (binary, compressed)\\n- **XML**: Extensible Markup Language format\\n\\n## Quality Metrics\\n\\nThe server provides various structure quality indicators:\\n\\n- Resolution (for X-ray crystallography)\\n- R-work and R-free values\\n- Ramachandran plot statistics\\n- Clash scores\\n- Rotamer outliers\\n- Model validation scores\\n\\n## Complementary Servers\\n\\nThis PDB server works well with:\\n\\n- **UniProt MCP Server**: For protein sequence and functional information\\n- **AlphaFold MCP Server**: For predicted protein structures\\n\\nTogether, these provide comprehensive access to protein structure and function data.\\n\\n## Error Handling\\n\\nThe server includes robust error handling for:\\n\\n- Invalid PDB IDs\\n- Network connectivity issues\\n- API rate limiting\\n- Missing structure files\\n- Malformed requests\\n\\n## Development\\n\\n```bash\\n# Install dependencies\\nnpm install\\n\\n# Build the server\\nnpm run build\\n\\n# Run in development mode\\nnpm run dev\\n```\\n\\n## Attribution\\n\\nThis project is developed by **Augmented Nature**\\n\\ud83c\\udf10 Website: [augmentednature.ai](https://augmentednature.ai)\\n\", \"tools\": [], \"tools_count\": 0, \"homepage\": \"\", \"url\": \"https://github.com/Augmented-Nature/Augmented-Nature-PDB-MCP-Server\", \"topics\": [\"bioinformatics\", \"drug-discovery\", \"mcp-server\", \"model-context-protocol\", \"protein-data-bank\", \"protein-structure\"], \"data_sources\": [\"github\"]}", "target": "", "id": "augmented-nature/augmented-nature-pdb-mcp-server", "metadata": {"stage": "finance_filter"}}
{"input": "ONLY RESPOND WITH JSON. NO EXPLANATIONS. NO MARKDOWN. NO TEXT OUTSIDE JSON.\n\nAnalyze the MCP server for financial relevance. Look for keywords: payment, banking, credit, loan, finance, money, currency, crypto, investment, trading, portfolio, market, exchange, wallet, account, budget, expense, income, tax, invoice, billing, accounting, insurance, compliance, KYC, AML.\n\nJSON FORMAT (NOTHING ELSE):\n{\n  \"server_name\": \"string\",\n  \"server_id\": \"string\", \n  \"is_finance_llm\": \"yes|no|unclear\",\n  \"confidence\": \"high|medium|low\",\n  \"threat_models\": [],\n  \"analysis_notes\": \"Brief reason\"\n}\n\nIf financial keywords found: is_finance_llm=\"yes\". If not: is_finance_llm=\"no\". If unclear: is_finance_llm=\"unclear\".\n\nRESPOND ONLY WITH JSON.\n\nMCP Server Data:\n{\"server_name\": \"domain-check-mcp\", \"server_id\": \"sebastianboehler/domain-check-mcp\", \"description\": \"A Model Context Protocol (MCP) server for checking domain availability using IONOS endpoints\", \"readme\": \"# Domain Check MCP Server\\n\\nA Model Context Protocol (MCP) server for checking domain availability using IONOS endpoints.\\n\\n## Important Legal Notice\\n\\nThe IONOS API endpoints used in this project are:\\n\\n- **Not publicly documented**\\n- **Used at your own risk**\\n\\nThis project is provided for educational purposes only. Usage of these endpoints may violate IONOS's Terms of Service. The author assumes no liability for any legal consequences resulting from the use of this software.\\n\\n## Installation\\n\\n```bash\\nnpm install -g domain-check-mcp\\n```\\n\\nOr using npx:\\n\\n```bash\\nnpx domain-check-mcp\\n```\\n\\n## Available Tools\\n\\n- `check_domain_availability` - Checks if a domain is available\\n- `get_domain_recommendations` - Gets alternative domain suggestions\\n- `get_sedo_offers` - Checks Sedo marketplace for domain offers\\n\\n## Recommended MCP Configuration\\n\\nTo use the `domain-check-mcp` server in your windsuf/mcp_config.json, configure it as follows:\\n\\n```json\\n{\\n  \\\"mcpServers\\\": {\\n    \\\"domain\\\": {\\n      \\\"command\\\": \\\"npx\\\",\\n      \\\"args\\\": [\\\"-y\\\", \\\"domain-check-mcp\\\"]\\n    }\\n  }\\n}\\n```\\n\\nThis will launch the domain MCP server using `npx` directly, ensuring you always use the latest published version.\\n\\n## Quick Start\\n\\n1. Install (if not using npx):\\n   ```sh\\n   npm install -g domain-check-mcp\\n   # or\\n   bun add -g domain-check-mcp\\n   ```\\n2. Or run directly (recommended):\\n   ```sh\\n   npx -y domain-check-mcp\\n   ```\\n\\n## Development\\n\\n- For local development, build with:\\n  ```sh\\n  bun run build\\n  # or\\n  npm run build\\n  ```\\n- Then run:\\n  ```sh\\n  node build/index.js\\n  ```\\n\\n## Configuration\\n\\nRefer to the example above for the recommended setup in `mcp_config.json`.\\n\\n## Disclaimer\\n\\nThe author assumes no liability for any legal consequences resulting from the use of this software.\\n\", \"tools\": [{\"name\": \"check_domain_availability\", \"description\": \"- Checks if a domain is available\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"input\": {\"type\": \"string\", \"description\": \"Input parameter for check_domain_availability\"}}, \"required\": [\"input\"]}, \"source\": \"readme\", \"access_level\": \"read\"}, {\"name\": \"get_domain_recommendations\", \"description\": \"- Gets alternative domain suggestions\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"input\": {\"type\": \"string\", \"description\": \"Input parameter for get_domain_recommendations\"}}, \"required\": [\"input\"]}, \"source\": \"readme\", \"access_level\": \"read\"}, {\"name\": \"get_sedo_offers\", \"description\": \"- Checks Sedo marketplace for domain offers\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"input\": {\"type\": \"string\", \"description\": \"Input parameter for get_sedo_offers\"}}, \"required\": [\"input\"]}, \"source\": \"readme\", \"access_level\": \"read\"}, {\"name\": \"npx\", \"description\": \"directly, ensuring you always use the latest published version.\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"input\": {\"type\": \"string\", \"description\": \"Input parameter for npx\"}}, \"required\": [\"input\"]}, \"source\": \"readme\", \"access_level\": \"read\"}], \"tools_count\": 4, \"homepage\": \"\", \"url\": \"https://github.com/SebastianBoehler/domain-check-mcp\", \"topics\": [\"domain-checker\", \"domain-pricing\", \"ionos\", \"mcp\", \"mcp-server\"], \"data_sources\": [\"github\"]}", "target": "", "id": "sebastianboehler/domain-check-mcp", "metadata": {"stage": "finance_filter"}}
{"input": "ONLY RESPOND WITH JSON. NO EXPLANATIONS. NO MARKDOWN. NO TEXT OUTSIDE JSON.\n\nAnalyze the MCP server for financial relevance. Look for keywords: payment, banking, credit, loan, finance, money, currency, crypto, investment, trading, portfolio, market, exchange, wallet, account, budget, expense, income, tax, invoice, billing, accounting, insurance, compliance, KYC, AML.\n\nJSON FORMAT (NOTHING ELSE):\n{\n  \"server_name\": \"string\",\n  \"server_id\": \"string\", \n  \"is_finance_llm\": \"yes|no|unclear\",\n  \"confidence\": \"high|medium|low\",\n  \"threat_models\": [],\n  \"analysis_notes\": \"Brief reason\"\n}\n\nIf financial keywords found: is_finance_llm=\"yes\". If not: is_finance_llm=\"no\". If unclear: is_finance_llm=\"unclear\".\n\nRESPOND ONLY WITH JSON.\n\nMCP Server Data:\n{\"server_name\": \"ethereum-rpc-mpc\", \"server_id\": \"phillip-kemper/ethereum-rpc-mpc\", \"description\": \"A TypeScript MCP server that leverages the MCP SDK to support all Ethereum JSON-RPC calls, enabling AI models to interact with blockchain data.\", \"readme\": \"# Ethereum RPC MPC Server\\n\\n[![npm version](https://img.shields.io/npm/v/ethereum-rpc-mpc.svg)](https://www.npmjs.com/package/ethereum-rpc-mpc)\\n[![npm downloads](https://img.shields.io/npm/dm/ethereum-rpc-mpc.svg)](https://www.npmjs.com/package/ethereum-rpc-mpc)\\n\\nA TypeScript MCP server that leverages the MCP SDK to support all Ethereum JSON-RPC calls, enabling AI models to interact with blockchain data.\\n\\n## Overview\\n\\nThis project provides a Model Context Protocol (MCP) server that allows AI assistants like Cursor or Claude (or any MCP Client implementation) to interact with Ethereum blockchain data through standardized JSON-RPC interfaces. It acts as a bridge between AI models and EVM blockchains, enabling seamless access to on-chain data and functionality.\\n\\n## Installation\\n\\n```bash\\n# Clone the repository\\ngit clone git@github.com:Phillip-Kemper/ethereum-rpc-mpc.git\\ncd ethereum-rpc-mpc\\n\\n# Install dependencies\\nyarn install\\n\\n# Build the project\\nyarn build\\n\\n# Start Inspector with default Ethereum RPC (you can change in the inspector settings on )\\nyarn inspector\\n```\\n\\n## Usage\\n\\n### Using with Cursor\\n\\nTo use this MPC server with Cursor:\\n\\n1. In Cursor, go to Settings > Cursor Settings > MCP\\n2. Add a new MCP server with the following configuration:\\n   - Name: Ethereum RPC\\n   - Type: Command\\n   - Command: `npx -y ethereum-rpc-mpc https://eth.llamarpc.com Ethereum`\\n   or\\n   - Command: `node /path/to/ethereum-rpc-mpc/dist/server/index.js https://eth.llamarpc.com Ethereum`\\n\\n<img width=\\\"938\\\" alt=\\\"Screenshot 2025-03-13 at 19 41 56\\\" src=\\\"https://github.com/user-attachments/assets/f9e09d44-ea43-4ef2-9950-88300f6f9667\\\" />\\n\\n### Analytics\\n\\nYou can also enable analytics using [MCP Analytics Middleware](https://github.com/Phillip-Kemper/mcp-analytics-middleware) to get an overview about number of requests, duration of requests as well as error reporting for all your tools and resources. To enable it, just pass the --analytics flag and additionally a path for the Sqlite File.\\n\\n- Command: `npx -y ethereum-rpc-mpc https://eth.llamarpc.com Ethereum --analytics --db-path /Users/satoshi/Desktop/analytics.db`\\n\\n\\n### Starting the Server\\n\\nYou can start the server by providing an Ethereum RPC URL and an optional chain name:\\n\\n```bash\\nyarn start [RPC_URL] [CHAIN_NAME]\\n\\n# Using npx (without installing)\\nnpx -y ethereum-rpc-mpc [RPC_URL] [CHAIN_NAME]\\n```\\n\\nIf no RPC URL is provided, it will default to \\\"https://eth.llamarpc.com\\\".\\n\\nExample:\\n\\n```bash\\n# Connect to Ethereum mainnet\\nyarn start https://eth.llamarpc.com Ethereum\\n\\n# Connect to Zircuit\\nyarn start https://mainnet.zircuit.com Zircuit\\n```\\n\\n## Examples\\n\\nHere are some examples of how to use the Ethereum RPC MPC server with Claude:\\n\\n### Getting the Current Block Number\\n\\n```\\nWhat's the current block number?\\n```\\n\\n### Checking an Address Balance\\n\\n```\\nWhat's the ETH balance of 0x742d35Cc6634C0532925a3b844Bc454e4438f44e?\\n```\\n\\n### Getting Contract Information\\n\\n```\\nIs 0x6B175474E89094C44Da98b954EedeAC495271d0F a smart contract? If yes, what kind of contract is it?\\n```\\n\\n### Retrieving Transaction Details\\n\\n```\\nCan you show me the details of transaction 0x5c504ed432cb51138bcf09aa5e8a410dd4a1e204ef84bfed1be16dfba1b22060?\\n```\\n\\n## Zircuit SLS (Sequencer Level Security) Methods\\n\\nThis server includes special support for Zircuit-specific RPC methods. These methods are not enabled by default but are automatically activated when connecting to a Zircuit endpoint (Chain ID: 48900).\\n\\nThe supported Zircuit methods include:\\n\\n- `zirc_isQuarantined`: Check if a specific transaction is quarantined\\n- `zirc_getQuarantined`: Query all quarantined transactions with optional address filtering\\n\\nThese methods are particularly useful for monitoring transaction quarantine status.\\n\\n## Future Steps\\n\\n### Next to RPC, also support indexed API access\\n\\nWe plan to extend the functionality beyond basic RPC calls to include support for indexed blockchain data APIs. This will enable more efficient querying of historical data and complex on-chain analytics.\\n\\n### Multi Chain, Multi RPC Support\\n\\nFuture versions will support connecting to multiple chains and RPC endpoints simultaneously, allowing AI models to access data across different blockchains in a single session.\\n\\n### Client Implementation\\n\\nA future enhancement will be to develop a client-side implementation that makes it easier to interact with this MCP server from various applications.\\n\\n### Server Analytics\\n\\nWe plan to add analytics capabilities to track usage patterns, popular RPC methods, and performance metrics. This will help optimize the server and provide insights into how AI models are interacting with blockchain data.\\n\\n## License\\n\\nMIT \\n\", \"tools\": [{\"name\": \"zirc_isQuarantined\", \"description\": \"Check if a specific transaction is quarantined\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"input\": {\"type\": \"string\", \"description\": \"Input parameter for zirc_isQuarantined\"}}, \"required\": [\"input\"]}, \"source\": \"readme\", \"access_level\": \"read\"}, {\"name\": \"zirc_getQuarantined\", \"description\": \"Query all quarantined transactions with optional address filtering\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"query\": {\"type\": \"string\", \"description\": \"Search query or term\"}}, \"required\": [\"query\"]}, \"source\": \"readme\", \"access_level\": \"write\"}], \"tools_count\": 2, \"homepage\": \"\", \"url\": \"https://github.com/Phillip-Kemper/ethereum-rpc-mpc\", \"topics\": [\"ai\", \"claude\", \"cursor\", \"ethereum\", \"evm\", \"json-rpc\", \"mcp\"], \"data_sources\": [\"github\"]}", "target": "", "id": "phillip-kemper/ethereum-rpc-mpc", "metadata": {"stage": "finance_filter"}}
{"input": "ONLY RESPOND WITH JSON. NO EXPLANATIONS. NO MARKDOWN. NO TEXT OUTSIDE JSON.\n\nAnalyze the MCP server for financial relevance. Look for keywords: payment, banking, credit, loan, finance, money, currency, crypto, investment, trading, portfolio, market, exchange, wallet, account, budget, expense, income, tax, invoice, billing, accounting, insurance, compliance, KYC, AML.\n\nJSON FORMAT (NOTHING ELSE):\n{\n  \"server_name\": \"string\",\n  \"server_id\": \"string\", \n  \"is_finance_llm\": \"yes|no|unclear\",\n  \"confidence\": \"high|medium|low\",\n  \"threat_models\": [],\n  \"analysis_notes\": \"Brief reason\"\n}\n\nIf financial keywords found: is_finance_llm=\"yes\". If not: is_finance_llm=\"no\". If unclear: is_finance_llm=\"unclear\".\n\nRESPOND ONLY WITH JSON.\n\nMCP Server Data:\n{\"server_name\": \"mcp-web3-stats\", \"server_id\": \"crazyrabbitltc/mcp-web3-stats\", \"description\": \"A high-performance MCP server providing blockchain wallet analysis and token data via the Dune API for AI assistants and MCP clients.\", \"readme\": \"\\n![ChatGPT Image May 23, 2025, 10_25_41 AM](https://github.com/user-attachments/assets/fe40d718-d1d8-44e9-a8a4-a5ad39153218)\\n\\n# Dune API MCP Server\\n\\nThis project implements a Model Context Protocol (MCP) server that exposes functionality from the Dune API, allowing LLM agents and other MCP clients to analyze blockchain information.\\n\\n## Features\\n\\nThe server provides the following MCP tools and resources based on the Dune API:\\n\\n**EVM Tools:**\\n*   `get_evm_balances`: Fetches EVM token balances for a wallet.\\n*   `get_evm_activity`: Fetches EVM account activity.\\n*   `get_evm_collectibles`: Fetches EVM NFT collectibles.\\n*   `get_evm_transactions`: Retrieves granular EVM transaction details.\\n*   `get_evm_token_info`: Fetches metadata and price for EVM tokens.\\n*   `get_evm_token_holders`: Discovers EVM token holder distributions.\\n\\n**SVM Tools:**\\n*   `get_svm_balances`: Fetches SVM token balances.\\n*   `get_svm_transactions`: Fetches SVM transactions (Solana only).\\n\\n**Resources:**\\n*   `dune://evm/supported-chains`: Provides a list of EVM chains supported by the Dune API.\\n\\n**Prompts:**\\n*   `/evm_wallet_overview {walletAddress}`: Get a quick overview of an EVM wallet.\\n*   `/analyze_erc20_token {chainId} {tokenAddress}`: Analyze a specific ERC20 token.\\n*   `/svm_address_check {walletAddress}`: Check basic information for an SVM address.\\n\\n## Quick Start\\n\\n```bash\\n# Clone the repository\\ngit clone https://github.com/crazyrabbitLTC/mcp-web3-stats.git\\ncd mcp-web3-stats\\n\\n# Install dependencies\\nbun install\\n\\n# Create .env file with your Dune API key\\necho \\\"DUNE_API_KEY=your_actual_dune_api_key_here\\\" > .env\\n\\n# Start the server\\nbun start\\n\\n# In a separate terminal, run the MCP Inspector to test the tools\\nnpx @modelcontextprotocol/inspector bun run index.ts\\n```\\n\\n## Installation from npm\\n\\nYou can install the Web3 Stats Server globally via npm:\\n\\n```bash\\n# Install globally\\nnpm install -g mcp-web3-stats\\n\\n# Set your Dune API key as an environment variable\\nexport DUNE_API_KEY=your_actual_dune_api_key_here\\n\\n# Run the server\\nmcp-web3-stats\\n\\n# In a separate terminal, test with the MCP Inspector\\nnpx @modelcontextprotocol/inspector mcp-web3-stats\\n```\\n\\nAlternatively, you can run it directly with npx:\\n\\n```bash\\n# Set your Dune API key as an environment variable\\nexport DUNE_API_KEY=your_actual_dune_api_key_here\\n\\n# Run the server with npx\\nnpx mcp-web3-stats\\n\\n# In a separate terminal, test with the MCP Inspector\\nnpx @modelcontextprotocol/inspector npx mcp-web3-stats\\n```\\n\\n## What You Can Do With This\\n\\nThis MCP server allows you and your AI assistant to analyze blockchain data and wallet information directly. Here are some example use cases:\\n\\n### 1. Check Wallet Balances\\n\\nYou can quickly view all tokens (including ERC20s and NFTs) held by any wallet address:\\n\\n```\\nAssistant: Let me check the balances in this wallet for you.\\n\\n[Uses get_evm_balances with walletAddress=0xYourWalletAddress]\\n\\nThis wallet contains:\\n- 1.25 ETH (~$3,800)\\n- 500 USDC ($500)\\n- Several NFTs including a CryptoPunk and two Bored Apes\\n```\\n\\n### 2. Analyze Token Information and Holders\\n\\nYou can research specific tokens and their distribution:\\n\\n```\\nAssistant: Let me analyze this token for you.\\n\\n[Uses get_evm_token_info with chainId=1 and tokenAddress=0x1f9840a85d5aF5bf1D1762F925BDADdC4201F984]\\n\\nUNI Token Information:\\n- Current price: $5.32\\n- Market cap: $2.7B \\n- 24h trading volume: $89M\\n\\n[Uses get_evm_token_holders with chainId=1 and tokenAddress=0x1f9840a85d5aF5bf1D1762F925BDADdC4201F984]\\n\\nTop UNI Token Holders:\\n1. 0x47173B170C64d16393a52e6C480b3Ad8c302ba1e: 5.2% of supply\\n2. 0x1a9C8182C09F50C8318d769245beA52c32BE35BC: 3.8% of supply\\n...\\n```\\n\\n### 3. Review Recent Transactions\\n\\nYou can analyze transaction history for any address:\\n\\n```\\nAssistant: Here's a summary of recent transactions.\\n\\n[Uses get_evm_transactions with walletAddress=0xYourWalletAddress]\\n\\nRecent activity:\\n- Yesterday: Swapped 2 ETH for 3,500 UNI on Uniswap\\n- 3 days ago: Withdrew 5 ETH from Binance\\n- Last week: Minted an NFT for 0.08 ETH\\n```\\n\\n### 4. Check Solana Balances\\n\\nYou can also analyze Solana wallets:\\n\\n```\\nAssistant: Let me check your Solana wallet balances.\\n\\n[Uses get_svm_balances with walletAddress=YourSolanaAddress]\\n\\nThis wallet contains:\\n- 12.5 SOL (~$875)\\n- 2,500 USDC ($2,500)\\n- Several SPL tokens including 150 BONK\\n```\\n\\nConfigure this server with Claude Desktop or other MCP clients to enable your AI assistant to retrieve and analyze on-chain data in real time.\\n\\n## Prerequisites\\n\\n*   [Bun](https://bun.sh/) (latest version recommended)\\n*   A Dune API Key from [Sim API](https://docs.sim.dune.com/)\\n\\n## Setup\\n\\n1.  **Clone the repository (if applicable) or ensure you have the project files.**\\n\\n2.  **Install dependencies:**\\n    ```bash\\n    bun install\\n    ```\\n\\n3.  **Configure Environment Variables:**\\n    Create a `.env` file in the project root and add your Dune API key:\\n    ```env\\n    DUNE_API_KEY=your_actual_dune_api_key_here\\n    ```\\n    Replace `your_actual_dune_api_key_here` with your valid key.\\n\\n## Running the Se\\n[...truncated for length...]\", \"tools\": [{\"name\": \"get_evm_balances\", \"description\": \"Fetches EVM token balances for a wallet.\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"input\": {\"type\": \"string\", \"description\": \"Input parameter for get_evm_balances\"}}, \"required\": [\"input\"]}, \"source\": \"readme\", \"access_level\": \"read\"}, {\"name\": \"get_evm_activity\", \"description\": \"Fetches EVM account activity.\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"input\": {\"type\": \"string\", \"description\": \"Input parameter for get_evm_activity\"}}, \"required\": [\"input\"]}, \"source\": \"readme\", \"access_level\": \"read\"}, {\"name\": \"get_evm_collectibles\", \"description\": \"Fetches EVM NFT collectibles.\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"input\": {\"type\": \"string\", \"description\": \"Input parameter for get_evm_collectibles\"}}, \"required\": [\"input\"]}, \"source\": \"readme\", \"access_level\": \"read\"}, {\"name\": \"get_evm_transactions\", \"description\": \"Retrieves granular EVM transaction details.\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"input\": {\"type\": \"string\", \"description\": \"Input parameter for get_evm_transactions\"}}, \"required\": [\"input\"]}, \"source\": \"readme\", \"access_level\": \"read\"}, {\"name\": \"get_evm_token_info\", \"description\": \"Fetches metadata and price for EVM tokens.\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"amount\": {\"type\": \"number\", \"description\": \"Numeric amount or value\"}}, \"required\": [\"amount\"]}, \"source\": \"readme\", \"access_level\": \"read\"}, {\"name\": \"get_evm_token_holders\", \"description\": \"Discovers EVM token holder distributions.\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"input\": {\"type\": \"string\", \"description\": \"Input parameter for get_evm_token_holders\"}}, \"required\": [\"input\"]}, \"source\": \"readme\", \"access_level\": \"read\"}, {\"name\": \"get_svm_balances\", \"description\": \"Fetches SVM token balances.\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"input\": {\"type\": \"string\", \"description\": \"Input parameter for get_svm_balances\"}}, \"required\": [\"input\"]}, \"source\": \"readme\", \"access_level\": \"read\"}, {\"name\": \"get_svm_transactions\", \"description\": \"Fetches SVM transactions (Solana only).\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"input\": {\"type\": \"string\", \"description\": \"Input parameter for get_svm_transactions\"}}, \"required\": [\"input\"]}, \"source\": \"readme\", \"access_level\": \"read\"}, {\"name\": \"your_actual_dune_api_key_here\", \"description\": \"with your valid key.\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"input\": {\"type\": \"string\", \"description\": \"Input parameter for your_actual_dune_api_key_here\"}}, \"required\": [\"input\"]}, \"source\": \"readme\", \"access_level\": \"read\"}, {\"name\": \"tsc\", \"description\": \"):\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"input\": {\"type\": \"string\", \"description\": \"Input parameter for tsc\"}}, \"required\": [\"input\"]}, \"source\": \"readme\", \"access_level\": \"read\"}, {\"name\": \"dune_api_server\", \"description\": \"or `web3_stats_server`) that makes sense to you.\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"input\": {\"type\": \"string\", \"description\": \"Input parameter for dune_api_server\"}}, \"required\": [\"input\"]}, \"source\": \"readme\", \"access_level\": \"write\"}, {\"name\": \"env\", \"description\": \"block with your actual Dune API key. While the server script includes `dotenv` to load a local `.env` file, relying on the client (like Claude Desktop) to pass the environment variable via its configuration is more reliable for servers launched by external hosts.\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"file_path\": {\"type\": \"string\", \"description\": \"File path or file to process\"}}, \"required\": [\"file_path\"]}, \"source\": \"readme\", \"access_level\": \"execute\"}, {\"name\": \"command\", \"description\": \"might need to be the full, absolute path to your Bun executable (e.g., `~/.bun/bin/bun` on macOS/Linux, or the equivalent path on Windows) if it's not universally in the PATH for applications like Claude Desktop.\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"file_path\": {\"type\": \"string\", \"description\": \"File path or file to process\"}}, \"required\": [\"file_path\"]}, \"source\": \"readme\", \"access_level\": \"read\"}], \"tools_count\": 13, \"homepage\": \"\", \"url\": \"https://github.com/crazyrabbitLTC/mcp-web3-stats\", \"topics\": [], \"data_sources\": [\"github\"]}", "target": "", "id": "crazyrabbitltc/mcp-web3-stats", "metadata": {"stage": "finance_filter"}}
{"input": "ONLY RESPOND WITH JSON. NO EXPLANATIONS. NO MARKDOWN. NO TEXT OUTSIDE JSON.\n\nAnalyze the MCP server for financial relevance. Look for keywords: payment, banking, credit, loan, finance, money, currency, crypto, investment, trading, portfolio, market, exchange, wallet, account, budget, expense, income, tax, invoice, billing, accounting, insurance, compliance, KYC, AML.\n\nJSON FORMAT (NOTHING ELSE):\n{\n  \"server_name\": \"string\",\n  \"server_id\": \"string\", \n  \"is_finance_llm\": \"yes|no|unclear\",\n  \"confidence\": \"high|medium|low\",\n  \"threat_models\": [],\n  \"analysis_notes\": \"Brief reason\"\n}\n\nIf financial keywords found: is_finance_llm=\"yes\". If not: is_finance_llm=\"no\". If unclear: is_finance_llm=\"unclear\".\n\nRESPOND ONLY WITH JSON.\n\nMCP Server Data:\n{\"server_name\": \"neo-n3-mcp\", \"server_id\": \"r3e-network/neo-n3-mcp\", \"description\": \"An MCP server for interacting with the Neo N3 blockchain.\", \"readme\": \"# Neo N3 MCP Server\\n\\n**MCP Server for Neo N3 Blockchain Integration** | Version 1.5.0\\n\\n[![MCP SDK](https://img.shields.io/badge/MCP%20SDK-1.9.0-blue)](https://github.com/modelcontextprotocol/typescript-sdk)\\n[![Neo N3](https://img.shields.io/badge/Neo%20N3-Compatible-green)](https://neo.org/)\\n[![NPM](https://img.shields.io/badge/NPM-@r3e/neo--n3--mcp-red)](https://www.npmjs.com/package/@r3e/neo-n3-mcp)\\n\\nA production-ready MCP server providing Neo N3 blockchain integration with 34 tools and 9 resources for wallet management, asset transfers, contract interactions, and blockchain queries.\\n\\n## \\ud83d\\ude80 Quick Start\\n\\n### Install from NPM\\n```bash\\n# Install globally\\nnpm install -g @r3e/neo-n3-mcp\\n\\n# Or install locally\\nnpm install @r3e/neo-n3-mcp\\n```\\n\\n### Basic Usage\\n```bash\\n# Run with default configuration\\nnpx @r3e/neo-n3-mcp\\n\\n# Or if installed globally\\nneo-n3-mcp\\n```\\n\\n## \\u2699\\ufe0f Configuration\\n\\n### 1. Command Line Configuration\\n\\n```bash\\n# Specify network\\nneo-n3-mcp --network testnet\\n\\n# Custom RPC endpoints\\nneo-n3-mcp --mainnet-rpc https://mainnet1.neo.coz.io:443 --testnet-rpc https://testnet1.neo.coz.io:443\\n\\n# Enable logging\\nneo-n3-mcp --log-level info --log-file ./neo-mcp.log\\n\\n# Complete example\\nneo-n3-mcp \\\\\\n  --network mainnet \\\\\\n  --mainnet-rpc https://mainnet1.neo.coz.io:443 \\\\\\n  --testnet-rpc https://testnet1.neo.coz.io:443 \\\\\\n  --log-level debug \\\\\\n  --log-file ./logs/neo-mcp.log\\n```\\n\\n### 2. JSON Configuration\\n\\nCreate a `neo-mcp-config.json` file:\\n\\n```json\\n{\\n  \\\"network\\\": \\\"mainnet\\\",\\n  \\\"rpc\\\": {\\n    \\\"mainnet\\\": \\\"https://mainnet1.neo.coz.io:443\\\",\\n    \\\"testnet\\\": \\\"https://testnet1.neo.coz.io:443\\\"\\n  },\\n  \\\"logging\\\": {\\n    \\\"level\\\": \\\"info\\\",\\n    \\\"file\\\": \\\"./logs/neo-mcp.log\\\",\\n    \\\"console\\\": true\\n  },\\n  \\\"server\\\": {\\n    \\\"name\\\": \\\"neo-n3-mcp-server\\\",\\n    \\\"version\\\": \\\"1.5.0\\\"\\n  },\\n  \\\"wallets\\\": {\\n    \\\"directory\\\": \\\"./wallets\\\"\\n  }\\n}\\n```\\n\\nRun with config file:\\n```bash\\nneo-n3-mcp --config ./neo-mcp-config.json\\n```\\n\\n### 3. Docker Configuration\\n\\n#### Using Docker Hub Image\\n```bash\\n# Basic run\\ndocker run -p 3000:3000 r3e/neo-n3-mcp:1.5.0\\n\\n# With environment variables\\ndocker run -p 3000:3000 \\\\\\n  -e NEO_NETWORK=mainnet \\\\\\n  -e NEO_MAINNET_RPC=https://mainnet1.neo.coz.io:443 \\\\\\n  -e NEO_TESTNET_RPC=https://testnet1.neo.coz.io:443 \\\\\\n  -e LOG_LEVEL=info \\\\\\n  r3e/neo-n3-mcp:1.5.0\\n\\n# With volume for persistent data\\ndocker run -p 3000:3000 \\\\\\n  -v $(pwd)/wallets:/app/wallets \\\\\\n  -v $(pwd)/logs:/app/logs \\\\\\n  -e NEO_NETWORK=testnet \\\\\\n  r3e/neo-n3-mcp:1.5.0\\n```\\n\\n#### Docker Compose\\nCreate a `docker-compose.yml`:\\n\\n```yaml\\nversion: '3.8'\\nservices:\\n  neo-mcp:\\n    image: r3e/neo-n3-mcp:1.5.0\\n    ports:\\n      - \\\"3000:3000\\\"\\n    environment:\\n      - NEO_NETWORK=mainnet\\n      - NEO_MAINNET_RPC=https://mainnet1.neo.coz.io:443\\n      - NEO_TESTNET_RPC=https://testnet1.neo.coz.io:443\\n      - LOG_LEVEL=info\\n      - LOG_FILE=/app/logs/neo-mcp.log\\n    volumes:\\n      - ./wallets:/app/wallets\\n      - ./logs:/app/logs\\n      - ./config:/app/config\\n    restart: unless-stopped\\n```\\n\\nRun with:\\n```bash\\ndocker-compose up -d\\n```\\n\\n#### Custom Dockerfile\\n```dockerfile\\nFROM node:18-alpine\\n\\nWORKDIR /app\\nCOPY package*.json ./\\nRUN npm ci --only=production\\n\\nCOPY dist/ ./dist/\\nCOPY config/ ./config/\\n\\n# Create necessary directories\\nRUN mkdir -p wallets logs\\n\\nEXPOSE 3000\\n\\nCMD [\\\"node\\\", \\\"dist/index.js\\\"]\\n```\\n\\n## \\ud83d\\udd27 Configuration Options\\n\\n### Environment Variables\\n| Variable | Description | Default |\\n|----------|-------------|---------|\\n| `NEO_NETWORK` | Default network (mainnet/testnet) | `testnet` |\\n| `NEO_MAINNET_RPC` | Mainnet RPC endpoint | `https://mainnet1.neo.coz.io:443` |\\n| `NEO_TESTNET_RPC` | Testnet RPC endpoint | `https://testnet1.neo.coz.io:443` |\\n| `LOG_LEVEL` | Logging level (debug/info/warn/error) | `info` |\\n| `LOG_FILE` | Log file path | `./logs/neo-mcp.log` |\\n| `WALLET_DIR` | Wallet storage directory | `./wallets` |\\n\\n### Command Line Options\\n| Option | Description |\\n|--------|-------------|\\n| `--network` | Set default network |\\n| `--mainnet-rpc` | Mainnet RPC URL |\\n| `--testnet-rpc` | Testnet RPC URL |\\n| `--log-level` | Set logging level |\\n| `--log-file` | Set log file path |\\n| `--config` | Load configuration from JSON file |\\n| `--help` | Show help information |\\n\\n## \\ud83d\\udee0\\ufe0f MCP Client Integration\\n\\n### Claude Desktop\\nAdd to your Claude Desktop config (`~/.cursor/mcp.json` or similar):\\n\\n```json\\n{\\n  \\\"mcpServers\\\": {\\n    \\\"neo-n3\\\": {\\n      \\\"command\\\": \\\"npx\\\",\\n      \\\"args\\\": [\\n        \\\"-y\\\",\\n        \\\"@r3e/neo-n3-mcp\\\",\\n        \\\"--network\\\",\\n        \\\"testnet\\\"\\n      ],\\n      \\\"disabled\\\": false,\\n      \\\"env\\\": {\\n        \\\"NEO_NETWORK\\\": \\\"testnet\\\",\\n        \\\"LOG_LEVEL\\\": \\\"info\\\"\\n      }\\n    }\\n  }\\n}\\n```\\n\\nFor mainnet configuration:\\n```json\\n{\\n  \\\"mcpServers\\\": {\\n    \\\"neo-n3\\\": {\\n      \\\"command\\\": \\\"npx\\\",\\n      \\\"args\\\": [\\n        \\\"-y\\\",\\n        \\\"@r3e/neo-n3-mcp\\\",\\n        \\\"--network\\\",\\n        \\\"mainnet\\\"\\n      ],\\n      \\\"disabled\\\": false,\\n      \\\"env\\\": {\\n        \\\"NEO_NETWORK\\\": \\\"mainnet\\\",\\n        \\\"NEO_MAINNET_RPC\\\": \\\"https://mainnet1.neo.coz.io:443\\\",\\n        \\\"NEO_TESTNET_RPC\\\": \\\"https://testnet1.neo.coz.io:443\\\",\\n        \\\"LOG_LEVEL\\\": \\\"inf\\n[...truncated for length...]\", \"tools\": [{\"name\": \"NEO_NETWORK\", \"description\": \"| Default network (mainnet/testnet) | `testnet` |\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"input\": {\"type\": \"string\", \"description\": \"Input parameter for NEO_NETWORK\"}}, \"required\": [\"input\"]}, \"source\": \"readme\", \"access_level\": \"read\"}, {\"name\": \"NEO_MAINNET_RPC\", \"description\": \"| Mainnet RPC endpoint | `https://mainnet1.neo.coz.io:443` |\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"input\": {\"type\": \"string\", \"description\": \"Input parameter for NEO_MAINNET_RPC\"}}, \"required\": [\"input\"]}, \"source\": \"readme\", \"access_level\": \"read\"}, {\"name\": \"NEO_TESTNET_RPC\", \"description\": \"| Testnet RPC endpoint | `https://testnet1.neo.coz.io:443` |\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"input\": {\"type\": \"string\", \"description\": \"Input parameter for NEO_TESTNET_RPC\"}}, \"required\": [\"input\"]}, \"source\": \"readme\", \"access_level\": \"read\"}, {\"name\": \"LOG_LEVEL\", \"description\": \"| Logging level (debug/info/warn/error) | `info` |\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"input\": {\"type\": \"string\", \"description\": \"Input parameter for LOG_LEVEL\"}}, \"required\": [\"input\"]}, \"source\": \"readme\", \"access_level\": \"read\"}, {\"name\": \"LOG_FILE\", \"description\": \"| Log file path | `./logs/neo-mcp.log` |\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"file_path\": {\"type\": \"string\", \"description\": \"File path or file to process\"}}, \"required\": [\"file_path\"]}, \"source\": \"readme\", \"access_level\": \"read\"}, {\"name\": \"WALLET_DIR\", \"description\": \"| Wallet storage directory | `./wallets` |\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"input\": {\"type\": \"string\", \"description\": \"Input parameter for WALLET_DIR\"}}, \"required\": [\"input\"]}, \"source\": \"readme\", \"access_level\": \"read\"}, {\"name\": \"get_network_mode\", \"description\": \", `set_network_mode`\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"input\": {\"type\": \"string\", \"description\": \"Input parameter for get_network_mode\"}}, \"required\": [\"input\"]}, \"source\": \"readme\", \"access_level\": \"write\"}, {\"name\": \"get_blockchain_info\", \"description\": \", `get_block_count`, `get_block`, `get_transaction`\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"input\": {\"type\": \"string\", \"description\": \"Input parameter for get_blockchain_info\"}}, \"required\": [\"input\"]}, \"source\": \"readme\", \"access_level\": \"read\"}, {\"name\": \"create_wallet\", \"description\": \", `import_wallet`\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"input\": {\"type\": \"string\", \"description\": \"Input parameter for create_wallet\"}}, \"required\": [\"input\"]}, \"source\": \"readme\", \"access_level\": \"write\"}, {\"name\": \"get_balance\", \"description\": \", `transfer_assets`, `estimate_transfer_fees`\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"input\": {\"type\": \"string\", \"description\": \"Input parameter for get_balance\"}}, \"required\": [\"input\"]}, \"source\": \"readme\", \"access_level\": \"write\"}, {\"name\": \"invoke_contract\", \"description\": \", `list_famous_contracts`, `get_contract_info`\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"input\": {\"type\": \"string\", \"description\": \"Input parameter for invoke_contract\"}}, \"required\": [\"input\"]}, \"source\": \"readme\", \"access_level\": \"read\"}, {\"name\": \"claim_gas\", \"description\": \", `estimate_invoke_fees`\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"input\": {\"type\": \"string\", \"description\": \"Input parameter for claim_gas\"}}, \"required\": [\"input\"]}, \"source\": \"readme\", \"access_level\": \"read\"}], \"tools_count\": 12, \"homepage\": \"https://neomcp.xyz\", \"url\": \"https://github.com/r3e-network/neo-n3-mcp\", \"topics\": [], \"data_sources\": [\"github\"]}", "target": "", "id": "r3e-network/neo-n3-mcp", "metadata": {"stage": "finance_filter"}}
{"input": "ONLY RESPOND WITH JSON. NO EXPLANATIONS. NO MARKDOWN. NO TEXT OUTSIDE JSON.\n\nAnalyze the MCP server for financial relevance. Look for keywords: payment, banking, credit, loan, finance, money, currency, crypto, investment, trading, portfolio, market, exchange, wallet, account, budget, expense, income, tax, invoice, billing, accounting, insurance, compliance, KYC, AML.\n\nJSON FORMAT (NOTHING ELSE):\n{\n  \"server_name\": \"string\",\n  \"server_id\": \"string\", \n  \"is_finance_llm\": \"yes|no|unclear\",\n  \"confidence\": \"high|medium|low\",\n  \"threat_models\": [],\n  \"analysis_notes\": \"Brief reason\"\n}\n\nIf financial keywords found: is_finance_llm=\"yes\". If not: is_finance_llm=\"no\". If unclear: is_finance_llm=\"unclear\".\n\nRESPOND ONLY WITH JSON.\n\nMCP Server Data:\n{\"server_name\": \"agent-argocd\", \"server_id\": \"cnoe-io/agent-argocd\", \"description\": \"ArgoCD AI Agent powered by 1st Party MCP Server using OpenAPI Codegen, LangGraph and LangChain MCP Adapters. Agent is exposed on various agent transport protocols (AGNTCY Slim, Google A2A, MCP Server)\", \"readme\": \"# \\ud83d\\ude80 ArgoCD AI Agent\\n\\n[![Python](https://img.shields.io/badge/python-3.13%2B-blue?logo=python)](https://www.python.org/)\\n[![Poetry](https://img.shields.io/badge/poetry-2.1.1%2B-blueviolet?logo=python)](https://python-poetry.org/)\\n[![License](https://img.shields.io/badge/license-Apache%202.0-green)](LICENSE)\\n\\n[![Conventional Commits](https://github.com/cnoe-io/openapi-mcp-codegen/actions/workflows/conventional_commits.yml/badge.svg)](https://github.com/cnoe-io/openapi-mcp-codegen/actions/workflows/conventional_commits.yml)\\n[![Ruff Linter](https://github.com/cnoe-io/openapi-mcp-codegen/actions/workflows/ruff.yml/badge.svg)](https://github.com/cnoe-io/openapi-mcp-codegen/actions/workflows/ruff.yml)\\n[![Unit Tests](https://github.com/cnoe-io/agent-argocd/actions/workflows/unit-tests.yml/badge.svg)](https://github.com/cnoe-io/agent-argocd/actions/workflows/unit-tests.yml)\\n\\n[![A2A Docker Build and Push](https://github.com/cnoe-io/agent-argocd/actions/workflows/a2a-docker-build.yml/badge.svg)](https://github.com/cnoe-io/agent-argocd/actions/workflows/a2a-docker-build.yml)\\n---\\n\\n---\\n\\n- \\ud83e\\udd16 **ArgoCD Agent** is an LLM-powered agent built using the [LangGraph ReAct Agent](https://langchain-ai.github.io/langgraph/agents/agents/) workflow and ArgoCD [MCP Server](https://modelcontextprotocol.io/introduction).\\n- \\ud83c\\udf10 **Protocol Support:** Compatible with [A2A](https://github.com/google/A2A) protocol for integration with external user clients.\\n- \\ud83d\\udee1\\ufe0f **Secure by Design:** Enforces ArgoCD API token-based RBAC and supports secondary external authentication for strong access control.\\n- \\ud83c\\udfed **MCP Server:** The MCP server is generated by our first-party [openapi-mcp-codegen](https://github.com/cnoe-io/openapi-mcp-codegen/tree/main) utility, ensuring version/API compatibility and software supply chain integrity.\\n- \\ud83d\\udd0c **MCP Tools:** Uses [langchain-mcp-adapters](https://github.com/langchain-ai/langchain-mcp-adapters) to glue the tools from ArgoCD MCP server to LangGraph ReAct Agent Graph.\\n\\n---\\n\\n## \\ud83d\\udea6 Getting Started\\n\\n### 1\\ufe0f\\u20e3 Environment Setup\\n\\n- Copy and configure your `.env` based on your LLM provider.\\n- Use [.env.example](.env.example) and refer to the [cnoe-agent-utils guide](https://github.com/cnoe-io/cnoe-agent-utils#-usage).\\n\\n### 2\\ufe0f\\u20e3 Start the Agent (A2A Mode)\\n\\n  > **Note:** `a2a-stable` is the latest stable version of the agent. For production use cases, consider using a pinned version.\\n\\n  ```bash\\n  docker run -p 0.0.0.0:8000:8000 -it \\\\\\n    -v $(pwd)/.env:/app/.env \\\\\\n    ghcr.io/cnoe-io/agent-argocd:a2a-stable\\n  ```\\n\\n> \\ud83d\\udca1 Don\\u2019t have ArgoCD running? See [Local Dev Setup](#local-development-setup).\\n\\n### 3\\ufe0f\\u20e3 Run the A2A Client\\n\\nPick one of the following methods:\\n\\n- **Docker:**\\n\\n  ```bash\\n  docker run -it --network=host ghcr.io/cnoe-io/agent-chat-cli:stable\\n  ```\\n\\n- **Python CLI:**\\n\\n  ```bash\\n  uvx https://github.com/cnoe-io/agent-chat-cli.git a2a\\n  ```\\n\\n---\\n\\n## \\ud83c\\udfd7\\ufe0f Architecture\\n\\n### System Diagram\\n\\n```mermaid\\nflowchart TD\\n  subgraph Client Layer\\n    A[User Client A2A]\\n  end\\n  subgraph Agent Transport Layer\\n    B[Google A2A]\\n  end\\n  subgraph Agent Graph Layer\\n    C[LangGraph ReAct Agent]\\n  end\\n  subgraph Tools Layer\\n    D[LangChain MCP Adapter]\\n    E[ArgoCD MCP Server]\\n    F[ArgoCD API Server]\\n  end\\n\\n  A --> B --> C --> D --> E --> F\\n  F --> E --> D --> C --> B --> A\\n```\\n\\n### Sequence Diagram\\n\\n```mermaid\\nsequenceDiagram\\n  participant User\\n  participant A2A\\n  participant Agent as LangGraph ReAct Agent\\n  participant LLM\\n  participant MCP as ArgoCD MCP Server\\n  participant APIServer as ArgoCD API Server\\n\\n  note over Agent,MCP: \\ud83d\\udee0\\ufe0f Agent Setup Phase\\n  rect rgb(245, 245, 220)\\n    Agent->>MCP: Get Tools\\n    Agent->>LLM: Bind Tools\\n  end\\n\\n  rect rgb(220, 232, 243)\\n    note over User,A2A: \\ud83e\\uddd1\\u200d\\ud83d\\udcbb User Input Phase\\n    User->>A2A: Send request\\n    A2A->>Agent: Forward to LangGraph Agent\\n\\n    note over Agent,LLM: \\ud83e\\udde0 Agent Reasoning & Tool Selection\\n    Agent->>LLM: [Reason] User Input\\n    LLM-->>Agent: [Act] Excecute MCP Tool\\n\\n    note over MCP,APIServer: \\ud83d\\udee0\\ufe0f API Invocation Phase\\n    Agent->>MCP: Invoke tool\\n    MCP->>APIServer: Call API\\n    APIServer-->>MCP: Return data\\n    MCP-->>Agent: Return data\\n\\n    note over Agent,LLM: \\ud83e\\udde0 Agent Reasoning & Output Structuring\\n    Agent->>LLM: Input API result data for further ReAct loop\\n    LLM-->>Agent: Return Structured Output\\n\\n    note over User,A2A: \\ud83d\\udce4 User Output Phase\\n    Agent-->>A2A: Respond with Structured Output\\n    A2A-->>User: Respond to user (Non-stream or streaming)\\n  end\\n```\\n\\n---\\n\\n## \\u2699\\ufe0f Local Development Setup\\n\\nUse this setup to test the agent against a local ArgoCD instance.\\n\\n### \\u25b6\\ufe0f Start ArgoCD with kind cluster\\n\\n> **Note:** KinD (Kubernetes in Docker) is a tool for running local Kubernetes clusters using Docker.\\nFor detailed setup instructions, refer to the [KinD documentation](https://kind.sigs.k8s.io/). Below is a quickstart to launch a local cluster and install ArgoCD:\\n\\n```bash\\nkind create cluster --name cnoe-argocd-agent\\nkubectl create namespace argocd\\nkubectl apply -n argocd -f https://raw.githubuser\\n[...truncated for length...]\", \"tools\": [{\"name\": \"uv\", \"description\": \"](https://github.com/astral-sh/uv) (a fast Python runner) on the port specified by `A2A_PORT` in your `.env` (defaults to `8000` if not set).\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"input\": {\"type\": \"string\", \"description\": \"Input parameter for uv\"}}, \"required\": [\"input\"]}, \"source\": \"readme\", \"access_level\": \"execute\"}, {\"name\": \"A2A_PORT\", \"description\": \"and `A2A_AGENT_IMAGE` from `.env` (uses defaults if not set).\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"input\": {\"type\": \"string\", \"description\": \"Input parameter for A2A_PORT\"}}, \"required\": [\"input\"]}, \"source\": \"readme\", \"access_level\": \"write\"}], \"tools_count\": 2, \"homepage\": \"https://hub.agntcy.org/explore/e632d15e-6587-4368-8eeb-7bf3ccd09758\", \"url\": \"https://github.com/cnoe-io/agent-argocd\", \"topics\": [\"agent\", \"agentic-ai\", \"argocd\", \"platform-engineering\"], \"data_sources\": [\"github\"]}", "target": "", "id": "cnoe-io/agent-argocd", "metadata": {"stage": "finance_filter"}}
{"input": "ONLY RESPOND WITH JSON. NO EXPLANATIONS. NO MARKDOWN. NO TEXT OUTSIDE JSON.\n\nAnalyze the MCP server for financial relevance. Look for keywords: payment, banking, credit, loan, finance, money, currency, crypto, investment, trading, portfolio, market, exchange, wallet, account, budget, expense, income, tax, invoice, billing, accounting, insurance, compliance, KYC, AML.\n\nJSON FORMAT (NOTHING ELSE):\n{\n  \"server_name\": \"string\",\n  \"server_id\": \"string\", \n  \"is_finance_llm\": \"yes|no|unclear\",\n  \"confidence\": \"high|medium|low\",\n  \"threat_models\": [],\n  \"analysis_notes\": \"Brief reason\"\n}\n\nIf financial keywords found: is_finance_llm=\"yes\". If not: is_finance_llm=\"no\". If unclear: is_finance_llm=\"unclear\".\n\nRESPOND ONLY WITH JSON.\n\nMCP Server Data:\n{\"server_name\": \"MessariMCP\", \"server_id\": \"n-45div/messarimcp\", \"description\": \"A MCP server powered by Messari Chat Agent API and an LLM based kit for mindshare and set insights over the time and plots to be the next crime-fighting AI toolkit.\", \"readme\": \"# Messari Influencer Mindshare and Asset Analysis\\r\\n\\r\\nThis repository contains a Python script for analyzing mindshare data of cryptocurrency assets using the Messari API. The script fetches mindshare data, performs anomaly detection, visualizes trends, and provides insights into significant spikes in attention for a given asset. The analysis is tailored for use in Google Colab, with plotting and readable insights displayed directly in the notebook.\\r\\n\\r\\n---\\r\\n\\r\\n## Overview\\r\\n\\r\\nThe Python script provides several functions to facilitate mindshare analysis for both cryptocurrency assets and Key Opinion Leaders (KOLs) on social media platforms like Twitter. Below is a description of each function:\\r\\n\\r\\n---\\r\\n\\r\\n#### `call_mistral`\\r\\n\\r\\n- **Purpose**: Interacts with the Mistral API to perform **sentiment analysis** on text data (e.g., summaries of trending topics).\\r\\n- **Returns**: A JSON object with the sentiment (`positive`, `negative`, or `neutral`) and an insight into how the topic may influence crypto market attention.\\r\\n- **Features**:\\r\\n  - Includes **retry logic** for handling rate limits.\\r\\n  - Caches responses to **avoid redundant API calls**.\\r\\n- **Used In**: KOL mindshare analysis to explain **anomalies** by sentiment-analyzing related trending topics.\\r\\n\\r\\n---\\r\\n\\r\\n#### `get_trending_details`\\r\\n\\r\\n- **Purpose**: Fetches **trending topics** from the Messari API within a given date range and topic classes (e.g., `\\\"Macro Commentary, Project Announcements, Legal and Regulatory\\\"`).\\r\\n- **Returns**: A dictionary of trending topics for the specified criteria.\\r\\n- **Used For**: Providing context for **mindshare anomalies** in the KOL analysis by correlating spikes with relevant market news and events.\\r\\n\\r\\n---\\r\\n\\r\\n#### `analyze_mindshare_data`\\r\\n\\r\\n- **Purpose**: Retrieves **mindshare data** for a specific Twitter handle (e.g., `@AltcoinGordon`) from the Messari API.\\r\\n- **Processes**:\\r\\n  - Detects **anomalies** in mindshare scores using **z-scores** (default threshold: `2.0`).\\r\\n  - **Plots** mindshare scores over time with anomalies **highlighted in red**.\\r\\n  - Provides insights on:\\r\\n    - **Trends** (upward/downward/stable)\\r\\n    - **Score and rank ranges**\\r\\n    - **List of anomalies**\\r\\n  - Uses `call_mistral` + `get_trending_details` to add **sentiment + market explanation** to detected anomalies.\\r\\n- **Display**: Results are shown **directly in Google Colab**.\\r\\n- **Best For**: KOL mindshare tracking and insight generation.\\r\\n\\r\\n---\\r\\n\\r\\n#### `analyze_asset_mindshare`\\r\\n\\r\\n- **Purpose**: Retrieves **mindshare data** for a specific cryptocurrency asset (e.g., `official-trump` for $TRUMP, `mantra-dao` for $OM).\\r\\n- **Processes**:\\r\\n  - Detects **anomalies** in asset mindshare scores using **z-scores** (default threshold: `2.0`).\\r\\n  - **Plots** scores over time with anomalies **highlighted in orange**.\\r\\n  - Provides concise insights about:\\r\\n    - **Mindshare trends**\\r\\n    - **Score and rank ranges**\\r\\n    - **Anomaly dates and scores**\\r\\n- **Display**: Designed to work **directly in Google Colab** for interactive visual exploration.\\r\\n- **Best For**: Analyzing market attention shifts for individual crypto assets.\\r\\n\\r\\n---\\r\\n\\r\\n## \\ud83d\\ude80 Running the MCP Server\\r\\n\\r\\nThe MCP Server provides a backend for broader mindshare comparison functionality.\\r\\n\\r\\n- Navigate to the server code: `server.py`\\r\\n- Ensure the Messari API key is configured correctly.\\r\\n\\r\\n---\\r\\n\\r\\n## API List\\r\\n\\r\\nThe following APIs are used in this project:\\r\\n\\r\\n- **Copilot Agent API**\\r\\n- **Current Topics API**\\r\\n- **X-Users Mindshare Over Time API**\\r\\n- **Mindshare of Asset Over Time API**\\r\\n- **Asset Details API**\\r\\n\\r\\n---\\r\\n\\r\\n## \\ud83d\\udd11 Key Features\\r\\n\\r\\n- **Mindshare Data Fetching**: Uses the Messari API to retrieve daily mindshare data for assets.\\r\\n- **Anomaly Detection**: Identifies significant spikes in mindshare scores using a z-score threshold (default: 2.0).\\r\\n- **Visualization**: Plots mindshare scores over time with anomalies highlighted in Google Colab.\\r\\n- **Insights**: Provides readable insights about trends, score ranges, rank ranges, and anomalies.\\r\\n- **Extensible**: Designed to work alongside KOL mindshare analysis (e.g., for Twitter handles) with potential for combined analysis.\\r\\n\\r\\n---\\r\\n\\r\\n## \\ud83d\\udcc2 Code Links in the repository\\r\\n\\r\\n- **Colab Notebook**: [LLM_Mindshare_asset_analysis.ipynb](https://github.com/N-45div/MessariMCP/blob/main/colab/LLM_Mindshare_asset_analysis.ipynb)\\r\\n- **MCP Server Code**: [server.py](https://github.com/N-45div/MessariMCP/blob/main/server.py)\\r\\n\\r\\n---\\r\\n\\r\\n## \\ud83d\\udcc4 License\\r\\n\\r\\nThis project is licensed under the MIT License. See the [LICENSE](LICENSE) file for details.\\r\\n\\r\\n---\\r\\n\\r\\n## Acknowledgments\\r\\n\\r\\n- **Messari**: For providing the API.\\r\\n- **Google Colab**: For enabling interactive visualization.\\r\\n- **Mistral AI**: For optional sentiment integration.\\r\\n\", \"tools\": [{\"name\": \"call_mistral\", \"description\": \"- **Purpose**: Interacts with the Mistral API to perform **sentiment analysis** on text data (e.g., summaries of trending topics).\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"message\": {\"type\": \"string\", \"description\": \"Text content or message\"}}, \"required\": [\"message\"]}, \"source\": \"readme\", \"access_level\": \"read\"}, {\"name\": \"positive\", \"description\": \", `negative`, or `neutral`) and an insight into how the topic may influence crypto market attention.\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"input\": {\"type\": \"string\", \"description\": \"Input parameter for positive\"}}, \"required\": [\"input\"]}, \"source\": \"readme\", \"access_level\": \"read\"}, {\"name\": \"get_trending_details\", \"description\": \"- **Purpose**: Fetches **trending topics** from the Messari API within a given date range and topic classes (e.g., `\\\"Macro Commentary, Project Announcements, Legal and Regulatory\\\"`).\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"input\": {\"type\": \"string\", \"description\": \"Input parameter for get_trending_details\"}}, \"required\": [\"input\"]}, \"source\": \"readme\", \"access_level\": \"read\"}, {\"name\": \"analyze_mindshare_data\", \"description\": \"- **Purpose**: Retrieves **mindshare data** for a specific Twitter handle (e.g., `@AltcoinGordon`) from the Messari API.\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"input\": {\"type\": \"string\", \"description\": \"Input parameter for analyze_mindshare_data\"}}, \"required\": [\"input\"]}, \"source\": \"readme\", \"access_level\": \"read\"}, {\"name\": \"analyze_asset_mindshare\", \"description\": \"- **Purpose**: Retrieves **mindshare data** for a specific cryptocurrency asset (e.g., `official-trump` for $TRUMP, `mantra-dao` for $OM).\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"input\": {\"type\": \"string\", \"description\": \"Input parameter for analyze_asset_mindshare\"}}, \"required\": [\"input\"]}, \"source\": \"readme\", \"access_level\": \"write\"}], \"tools_count\": 5, \"homepage\": \"\", \"url\": \"https://github.com/N-45div/MessariMCP\", \"topics\": [], \"data_sources\": [\"github\"]}", "target": "", "id": "n-45div/messarimcp", "metadata": {"stage": "finance_filter"}}
{"input": "ONLY RESPOND WITH JSON. NO EXPLANATIONS. NO MARKDOWN. NO TEXT OUTSIDE JSON.\n\nAnalyze the MCP server for financial relevance. Look for keywords: payment, banking, credit, loan, finance, money, currency, crypto, investment, trading, portfolio, market, exchange, wallet, account, budget, expense, income, tax, invoice, billing, accounting, insurance, compliance, KYC, AML.\n\nJSON FORMAT (NOTHING ELSE):\n{\n  \"server_name\": \"string\",\n  \"server_id\": \"string\", \n  \"is_finance_llm\": \"yes|no|unclear\",\n  \"confidence\": \"high|medium|low\",\n  \"threat_models\": [],\n  \"analysis_notes\": \"Brief reason\"\n}\n\nIf financial keywords found: is_finance_llm=\"yes\". If not: is_finance_llm=\"no\". If unclear: is_finance_llm=\"unclear\".\n\nRESPOND ONLY WITH JSON.\n\nMCP Server Data:\n{\"server_name\": \"deep-research-mcp\", \"server_id\": \"ali-kh7/deep-research-mcp\", \"description\": \"A Model Context Protocol (MCP) compliant server designed for comprehensive web research. It uses Tavily's Search and Crawl APIs to gather detailed information on a given topic, then structures this data in a format perfect for LLMs to create high-quality markdown documents.\", \"readme\": \"# Deep Research MCP \\ud83c\\udf10\\n\\n![Deep Research MCP](https://img.shields.io/badge/Release-v1.0.0-blue.svg)  \\n[Download Releases](https://github.com/ali-kh7/deep-research-mcp/releases)\\n\\nWelcome to the **Deep Research MCP** repository! This project provides a server compliant with the Model Context Protocol (MCP). It is designed to facilitate comprehensive web research. By utilizing Tavily's Search and Crawl APIs, the server gathers detailed information on various topics and structures this data to support high-quality markdown document creation using large language models (LLMs).\\n\\n## Table of Contents\\n\\n- [Features](#features)\\n- [Installation](#installation)\\n- [Usage](#usage)\\n- [API Documentation](#api-documentation)\\n- [Contributing](#contributing)\\n- [License](#license)\\n- [Support](#support)\\n\\n## Features\\n\\n- **MCP Compliance**: The server adheres to the Model Context Protocol, ensuring compatibility with various tools and services.\\n- **Data Aggregation**: Efficiently gathers and structures data from multiple sources.\\n- **Markdown Generation**: Converts gathered data into well-structured markdown documents.\\n- **Web Crawling**: Utilizes Tavily's Search and Crawl APIs for in-depth web research.\\n- **Node.js and TypeScript**: Built using modern technologies for better performance and maintainability.\\n\\n## Installation\\n\\nTo get started with Deep Research MCP, follow these steps:\\n\\n1. **Clone the repository**:\\n\\n   ```bash\\n   git clone https://github.com/ali-kh7/deep-research-mcp.git\\n   ```\\n\\n2. **Navigate to the project directory**:\\n\\n   ```bash\\n   cd deep-research-mcp\\n   ```\\n\\n3. **Install the dependencies**:\\n\\n   ```bash\\n   npm install\\n   ```\\n\\n4. **Run the server**:\\n\\n   ```bash\\n   npm start\\n   ```\\n\\nYou can also check the [Releases](https://github.com/ali-kh7/deep-research-mcp/releases) section for downloadable files and specific versions.\\n\\n## Usage\\n\\nOnce the server is running, you can interact with it via the API. Here\\u2019s how to use it effectively:\\n\\n1. **Send a request to gather information**:\\n\\n   You can send a request to the server with a specific topic to gather data. The server will return structured information ready for markdown generation.\\n\\n   Example request:\\n\\n   ```http\\n   POST /api/research\\n   Content-Type: application/json\\n\\n   {\\n     \\\"topic\\\": \\\"Artificial Intelligence\\\"\\n   }\\n   ```\\n\\n2. **Receive structured data**:\\n\\n   The server responds with data in a structured format. This data can be used directly or transformed into markdown documents.\\n\\n3. **Generate markdown documents**:\\n\\n   The structured data can be converted into markdown using the provided functions in the API.\\n\\n### Example Markdown Output\\n\\n```markdown\\n# Artificial Intelligence\\n\\n## Overview\\nArtificial Intelligence (AI) refers to the simulation of human intelligence in machines.\\n\\n## Applications\\n- Healthcare\\n- Finance\\n- Transportation\\n\\n## Conclusion\\nAI is transforming industries and shaping the future.\\n```\\n\\n## API Documentation\\n\\nFor detailed API documentation, please refer to the `docs` folder in this repository. It contains information on all available endpoints, request formats, and response structures.\\n\\n### Endpoints\\n\\n- **POST /api/research**: Gather information on a specific topic.\\n- **GET /api/status**: Check the server status.\\n\\n## Contributing\\n\\nWe welcome contributions to improve Deep Research MCP. If you want to contribute, please follow these steps:\\n\\n1. **Fork the repository**.\\n2. **Create a new branch**:\\n\\n   ```bash\\n   git checkout -b feature/YourFeatureName\\n   ```\\n\\n3. **Make your changes**.\\n4. **Commit your changes**:\\n\\n   ```bash\\n   git commit -m \\\"Add your message here\\\"\\n   ```\\n\\n5. **Push to the branch**:\\n\\n   ```bash\\n   git push origin feature/YourFeatureName\\n   ```\\n\\n6. **Open a Pull Request**.\\n\\n## License\\n\\nThis project is licensed under the MIT License. See the [LICENSE](LICENSE) file for details.\\n\\n## Support\\n\\nIf you encounter any issues or have questions, please check the [Releases](https://github.com/ali-kh7/deep-research-mcp/releases) section or open an issue in the repository.\\n\\n---\\n\\nThank you for checking out Deep Research MCP! We hope this tool enhances your web research capabilities. Happy coding!\", \"tools\": [{\"name\": \"docs\", \"description\": \"folder in this repository. It contains information on all available endpoints, request formats, and response structures.\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"input\": {\"type\": \"string\", \"description\": \"Input parameter for docs\"}}, \"required\": [\"input\"]}, \"source\": \"readme\", \"access_level\": \"read\"}], \"tools_count\": 1, \"homepage\": \"\", \"url\": \"https://github.com/ali-kh7/deep-research-mcp\", \"topics\": [\"agent\", \"agentic-ai\", \"ai-research\", \"aiagent\", \"airesearch\", \"deep-research\", \"gpt-researcher\", \"graph-database\", \"information-retrieval\", \"mcp-server\", \"multi-agent\", \"openrouter\", \"research-and-development\", \"typescript\"], \"data_sources\": [\"github\"]}", "target": "", "id": "ali-kh7/deep-research-mcp", "metadata": {"stage": "finance_filter"}}
{"input": "ONLY RESPOND WITH JSON. NO EXPLANATIONS. NO MARKDOWN. NO TEXT OUTSIDE JSON.\n\nAnalyze the MCP server for financial relevance. Look for keywords: payment, banking, credit, loan, finance, money, currency, crypto, investment, trading, portfolio, market, exchange, wallet, account, budget, expense, income, tax, invoice, billing, accounting, insurance, compliance, KYC, AML.\n\nJSON FORMAT (NOTHING ELSE):\n{\n  \"server_name\": \"string\",\n  \"server_id\": \"string\", \n  \"is_finance_llm\": \"yes|no|unclear\",\n  \"confidence\": \"high|medium|low\",\n  \"threat_models\": [],\n  \"analysis_notes\": \"Brief reason\"\n}\n\nIf financial keywords found: is_finance_llm=\"yes\". If not: is_finance_llm=\"no\". If unclear: is_finance_llm=\"unclear\".\n\nRESPOND ONLY WITH JSON.\n\nMCP Server Data:\n{\"server_name\": \"sfguide-mcp-cortex-agents\", \"server_id\": \"snowflake-labs/sfguide-mcp-cortex-agents\", \"description\": \"Guide to building MCP Server for Cortex Agent\", \"readme\": \"# Build an MCP Server for Cortex Agents\\n\\n## Overview\\n\\nThis guide walks through how to build your own MCP Server for Cortex Agents.\\n\\nThe core functionalities include:\\n\\n- Allow agents to interact with Cortex Agents as a tool\\n- Test the connection with Claude Desktop\\n\\nIn this tutorial, we\\u2019ll build a simple MCP **Cortex Agent** server and connect it to an MCP host (Claude for Desktop).\\n\\n## Step-by-Step Guide\\n\\nFor prerequisites, environment setup, step-by-step guide and instructions, please refer to the [QuickStart Guide](https://quickstarts.snowflake.com/guide/mcp-server-for-cortex-agents/index.html).\\n\\n\", \"tools\": [], \"tools_count\": 0, \"homepage\": \"\", \"url\": \"https://github.com/Snowflake-Labs/sfguide-mcp-cortex-agents\", \"topics\": [], \"data_sources\": [\"github\"]}", "target": "", "id": "snowflake-labs/sfguide-mcp-cortex-agents", "metadata": {"stage": "finance_filter"}}
{"input": "ONLY RESPOND WITH JSON. NO EXPLANATIONS. NO MARKDOWN. NO TEXT OUTSIDE JSON.\n\nAnalyze the MCP server for financial relevance. Look for keywords: payment, banking, credit, loan, finance, money, currency, crypto, investment, trading, portfolio, market, exchange, wallet, account, budget, expense, income, tax, invoice, billing, accounting, insurance, compliance, KYC, AML.\n\nJSON FORMAT (NOTHING ELSE):\n{\n  \"server_name\": \"string\",\n  \"server_id\": \"string\", \n  \"is_finance_llm\": \"yes|no|unclear\",\n  \"confidence\": \"high|medium|low\",\n  \"threat_models\": [],\n  \"analysis_notes\": \"Brief reason\"\n}\n\nIf financial keywords found: is_finance_llm=\"yes\". If not: is_finance_llm=\"no\". If unclear: is_finance_llm=\"unclear\".\n\nRESPOND ONLY WITH JSON.\n\nMCP Server Data:\n{\"server_name\": \"perplexity-mcp-server\", \"server_id\": \"cyanheads/perplexity-mcp-server\", \"description\": \"A Perplexity API Model Context Protocol (MCP) server that unlocks Perplexity's search-augmented AI capabilities for LLM agents. Features robust error handling, secure input validation, and transparent reasoning with the showThinking parameter. Built with type safety, modular architecture, and production-ready utilities.\", \"readme\": \"# Perplexity MCP Server\\n\\n[![TypeScript](https://img.shields.io/badge/TypeScript-^5.8.2-blue.svg)](https://www.typescriptlang.org/)\\n[![Model Context Protocol](https://img.shields.io/badge/MCP-^1.8.0-green.svg)](https://modelcontextprotocol.io/)\\n[![Version](https://img.shields.io/badge/Version-1.0.0-blue.svg)]()\\n[![License](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](https://opensource.org/licenses/Apache-2.0)\\n[![Status](https://img.shields.io/badge/Status-Stable-green.svg)](https://github.com/cyanheads/perplexity-mcp-server/issues)\\n[![GitHub](https://img.shields.io/github/stars/cyanheads/perplexity-mcp-server?style=social)](https://github.com/cyanheads/perplexity-mcp-server)\\n\\nAn MCP server providing tools to interact with the [Perplexity AI API](https://docs.perplexity.ai/docs/getting-started), built using the [mcp-ts-template](https://github.com/cyanheads/mcp-ts-template). This server allows AI agents compatible with the [Model Context Protocol (MCP)](https://modelcontextprotocol.io/) to leverage Perplexity's search-augmented query capabilities. Includes a showThinking parameter to enable reasoning models to show its internal reasoning process.\\n\\n## Core Features\\n\\n- **Utilities**: Reusable components for logging, error handling, ID generation, rate limiting, and request context management.\\n- **Type Safety**: Strong typing with TypeScript.\\n- **Error Handling**: Robust error handling system.\\n- **Security**: Basic security features like input sanitization.\\n- **Perplexity Tool**: A ready-to-use tool for interacting with the Perplexity Search API.\\n\\n> **.clinerules**: This repository includes a [.clinerules](.clinerules) file that serves as a developer cheat sheet for LLM coding agents (like Cline) providing quick references for codebase patterns, file locations, and code snippets specific to this project.\\n\\n## Table of Contents\\n\\n- [Overview](#overview)\\n  - [What is Model Context Protocol?](#what-is-model-context-protocol)\\n  - [Architecture & Components](#architecture--components)\\n- [Features](#features)\\n  - [Core Utilities](#core-utilities)\\n  - [Type Safety](#type-safety)\\n  - [Error Handling](#error-handling)\\n  - [Security](#security)\\n  - [Perplexity Search Tool](#perplexity-search-tool)\\n- [Installation](#installation)\\n- [Configuration](#configuration)\\n- [Project Structure](#project-structure)\\n- [Tool Documentation](#tool-documentation)\\n  - [perplexity_search](#perplexity_search)\\n- [Development Guidelines](#development-guidelines)\\n  - [Adding a New Tool](#adding-a-new-tool)\\n  - [Adding a New Resource](#adding-a-new-resource)\\n- [License](#license)\\n\\n## Overview\\n\\n### What is Model Context Protocol?\\n\\nModel Context Protocol (MCP) is a framework that enables AI systems to interact with external tools and resources. It allows language models to:\\n\\n- Execute **tools** that perform actions and return results\\n- Access structured **resources** that provide information\\n- Create contextual workflows through standardized interfaces\\n\\nThis server allows AI systems to use the Perplexity API via MCP.\\n\\n### Architecture & Components\\n\\nThe server is based on the `mcp-ts-template` and follows its modular architecture:\\n\\n<details>\\n<summary>Click to expand architecture diagram</summary>\\n\\n```mermaid\\nflowchart TB\\n    subgraph API[\\\"API Layer\\\"]\\n        direction LR\\n        MCP[\\\"MCP Protocol\\\"]\\n        Val[\\\"Validation\\\"]\\n        San[\\\"Sanitization\\\"]\\n\\n        MCP --> Val --> San\\n    end\\n\\n    subgraph Core[\\\"Core Components\\\"]\\n        direction LR\\n        Config[\\\"Configuration\\\"]\\n        Logger[\\\"Logging System\\\"]\\n        Error[\\\"Error Handling\\\"]\\n        Server[\\\"MCP Server\\\"]\\n\\n        Config --> Server\\n        Logger --> Server\\n        Error --> Server\\n    end\\n\\n    subgraph Implementation[\\\"Implementation Layer\\\"]\\n        direction LR\\n        Tool[\\\"Tools (Perplexity)\\\"]\\n        Util[\\\"Utilities\\\"]\\n\\n        Tool --> Server\\n        Util --> Tool\\n    end\\n\\n    San --> Config\\n    San --> Server\\n\\n    classDef layer fill:#2d3748,stroke:#4299e1,stroke-width:3px,rx:5,color:#fff\\n    classDef component fill:#1a202c,stroke:#a0aec0,stroke-width:2px,rx:3,color:#fff\\n    class API,Core,Implementation layer\\n    class MCP,Val,San,Config,Logger,Error,Server,Tool,Util component\\n```\\n\\n</details>\\n\\nCore Components:\\n\\n- **Configuration System**: Environment-aware configuration with validation\\n- **Logging System**: Structured logging with sensitive data redaction\\n- **Error Handling**: Centralized error processing with consistent patterns\\n- **MCP Server**: Protocol implementation for tools\\n- **Validation Layer**: Input validation and sanitization using `validator` and `sanitize-html`.\\n- **Utilities**: Reusable utility functions for common operations\\n\\n## Features\\n\\n### Core Utilities\\n\\n- **Logging**: Configurable logging with file rotation and sensitive data redaction\\n- **Error Handling**: Pattern-based error classification and standardized reporting\\n- **ID Generation**: Secure unique identifier creation with prefix support\\n- **Rate Limiting**: Request throttling to prevent A\\n[...truncated for length...]\", \"tools\": [{\"name\": \"validator\", \"description\": \"and `sanitize-html`.\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"input\": {\"type\": \"string\", \"description\": \"Input parameter for validator\"}}, \"required\": [\"input\"]}, \"source\": \"readme\", \"access_level\": \"read\"}, {\"name\": \"PERPLEXITY_API_KEY\", \"description\": \"| API key for authentication with Perplexity        | (Required)        |\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"input\": {\"type\": \"string\", \"description\": \"Input parameter for PERPLEXITY_API_KEY\"}}, \"required\": [\"input\"]}, \"source\": \"readme\", \"access_level\": \"read\"}, {\"name\": \"PERPLEXITY_DEFAULT_MODEL\", \"description\": \"| Default model to use for Perplexity requests      | \\\"sonar-reasoning\\\" |\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"input\": {\"type\": \"string\", \"description\": \"Input parameter for PERPLEXITY_DEFAULT_MODEL\"}}, \"required\": [\"input\"]}, \"source\": \"readme\", \"access_level\": \"read\"}, {\"name\": \"PERPLEXITY_DEFAULT_SEARCH_CONTEXT\", \"description\": \"| Search context size ('low', 'medium', 'high')     | \\\"high\\\"            |\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"query\": {\"type\": \"string\", \"description\": \"Search query or term\"}, \"message\": {\"type\": \"string\", \"description\": \"Text content or message\"}}, \"required\": [\"query\", \"message\"]}, \"source\": \"readme\", \"access_level\": \"read\"}, {\"name\": \"LOG_LEVEL\", \"description\": \"| Logging level (\\\"debug\\\", \\\"info\\\", \\\"warn\\\", \\\"error\\\")  | \\\"info\\\"            |\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"input\": {\"type\": \"string\", \"description\": \"Input parameter for LOG_LEVEL\"}}, \"required\": [\"input\"]}, \"source\": \"readme\", \"access_level\": \"read\"}, {\"name\": \"NODE_ENV\", \"description\": \"| Runtime environment (\\\"development\\\", \\\"production\\\") | \\\"development\\\"     |\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"input\": {\"type\": \"string\", \"description\": \"Input parameter for NODE_ENV\"}}, \"required\": [\"input\"]}, \"source\": \"readme\", \"access_level\": \"execute\"}, {\"name\": \"YOUR_PERPLEXITY_API_KEY\", \"description\": \"with your key.\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"input\": {\"type\": \"string\", \"description\": \"Input parameter for YOUR_PERPLEXITY_API_KEY\"}}, \"required\": [\"input\"]}, \"source\": \"readme\", \"access_level\": \"read\"}, {\"name\": \"perplexity_search\", \"description\": \"tool performs search-augmented queries using the Perplexity API. It takes a natural language query, performs a web search using Perplexity's backend, and then uses an LLM to synthesize an answer based on the search results.\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"query\": {\"type\": \"string\", \"description\": \"Search query or term\"}}, \"required\": [\"query\"]}, \"source\": \"readme\", \"access_level\": \"read\"}, {\"name\": \"query\", \"description\": \"| string   | Yes      | The primary search query or question to be processed by Perplexity                                                |\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"query\": {\"type\": \"string\", \"description\": \"Search query or term\"}}, \"required\": [\"query\"]}, \"source\": \"readme\", \"access_level\": \"read\"}, {\"name\": \"return_related_questions\", \"description\": \"| boolean  | No       | When true, instructs the Perplexity model to suggest related questions alongside the main answer (Default: false) |\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"input\": {\"type\": \"string\", \"description\": \"Input parameter for return_related_questions\"}}, \"required\": [\"input\"]}, \"source\": \"readme\", \"access_level\": \"read\"}, {\"name\": \"search_recency_filter\", \"description\": \"| string   | No       | Filter search results by timeframe (e.g., 'day', 'week', 'month', 'year')                                         |\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"query\": {\"type\": \"string\", \"description\": \"Search query or term\"}}, \"required\": [\"query\"]}, \"source\": \"readme\", \"access_level\": \"read\"}, {\"name\": \"search_domain_filter\", \"description\": \"| string[] | No       | Limit search to specific domains (e.g., ['wikipedia.org'])                                                        |\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"query\": {\"type\": \"string\", \"description\": \"Search query or term\"}}, \"required\": [\"query\"]}, \"source\": \"readme\", \"access_level\": \"read\"}, {\"name\": \"showThinking\", \"description\": \"| boolean  | No       | Include the model's internal reasoning in the response (Default: false)                                           |\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"input\": {\"type\": \"string\", \"description\": \"Input parameter for showThinking\"}}, \"required\": [\"input\"]}, \"source\": \"readme\", \"access_level\": \"read\"}, {\"name\": \"ResourceTemplate\", \"description\": \", use `ErrorHandler.tryCatch` and `server.resource()`).\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"input\": {\"type\": \"string\", \"description\": \"Input parameter for ResourceTemplate\"}}, \"required\": [\"input\"]}, \"source\": \"readme\", \"access_level\": \"read\"}], \"tools_count\": 14, \"homepage\": \"\", \"url\": \"https://github.com/cyanheads/perplexity-mcp-server\", \"topics\": [\"llm-agent\", \"mcp\", \"mcp-server\", \"model-context-protocol\", \"perplexity-ai\", \"sag\", \"search-augmented-generation\"], \"data_sources\": [\"github\"]}", "target": "", "id": "cyanheads/perplexity-mcp-server", "metadata": {"stage": "finance_filter"}}
{"input": "ONLY RESPOND WITH JSON. NO EXPLANATIONS. NO MARKDOWN. NO TEXT OUTSIDE JSON.\n\nAnalyze the MCP server for financial relevance. Look for keywords: payment, banking, credit, loan, finance, money, currency, crypto, investment, trading, portfolio, market, exchange, wallet, account, budget, expense, income, tax, invoice, billing, accounting, insurance, compliance, KYC, AML.\n\nJSON FORMAT (NOTHING ELSE):\n{\n  \"server_name\": \"string\",\n  \"server_id\": \"string\", \n  \"is_finance_llm\": \"yes|no|unclear\",\n  \"confidence\": \"high|medium|low\",\n  \"threat_models\": [],\n  \"analysis_notes\": \"Brief reason\"\n}\n\nIf financial keywords found: is_finance_llm=\"yes\". If not: is_finance_llm=\"no\". If unclear: is_finance_llm=\"unclear\".\n\nRESPOND ONLY WITH JSON.\n\nMCP Server Data:\n{\"server_name\": \"scmcp\", \"server_id\": \"scmcphub/scmcp\", \"description\": \"An MCP server for scRNA-Seq analysis with natural language!\", \"readme\": \"# SCMCP\\n\\nAn MCP server for scRNA-Seq analysis  with natural language!\\n\\n## \\ud83e\\udea9 What can it do?\\n\\n- IO module like read and write scRNA-Seq data with natural language\\n- Preprocessing module,like filtering, quality control, normalization, scaling, highly-variable genes, PCA, Neighbors,...\\n- Tool module, like clustering, differential expression etc.\\n- Plotting module, like violin, heatmap, dotplot\\n- cell-cell communication analysis\\n- Pseudotime analysis\\n- enrichment analysis\\n\\n## \\u2753 Who is this for?\\n\\n- Anyone who wants to do scRNA-Seq analysis natural language!\\n- Agent developers who want to call scanpy's functions for their applications\\n\\n## \\ud83c\\udf10 Where to use it?\\n\\nYou can use scmcp in most AI clients, plugins, or agent frameworks that support the MCP:\\n\\n- AI clients, like Cherry Studio\\n- Plugins, like Cline\\n- Agent frameworks, like Agno \\n\\n\\n## \\ud83d\\udcda Documentation\\n\\nscmcphub's complete documentation is available at https://docs.scmcphub.org\\n\\n\\n## \\ud83c\\udfac Demo\\n\\nA demo showing scRNA-Seq cell cluster analysis in a AI client Cherry Studio using natural language based on scmcp\\n\\nhttps://github.com/user-attachments/assets/93a8fcd8-aa38-4875-a147-a5eeff22a559\\n\\n## \\ud83c\\udfce\\ufe0f Quickstart\\n\\n### Install\\n\\nInstall from PyPI\\n```\\npip install scmcp\\n```\\nyou can test it by running\\n```\\nscmcp run\\n```\\n\\n#### run scnapy-mcp locally\\nRefer to the following configuration in your MCP client:\\n\\ncheck path\\n```\\n$ which scmcp \\n/home/test/bin/scmcp\\n```\\n\\n> it has many tools , so it couldn't work if you model context is not large...More time, I recommend it is backend mcp server for scanpy-mcp, liana-mcp,cellrank-mcp, so they can use shared Anndata object.\\n\\n```\\n\\\"mcpServers\\\": {\\n  \\\"scmcp\\\": {\\n    \\\"command\\\": \\\"/home/test/bin/scmcp\\\",\\n    \\\"args\\\": [\\n      \\\"run\\\"\\n    ]\\n  }\\n}\\n```\\n\\n#### run scmcp remotely\\nRefer to the following configuration in your MCP client:\\n\\nrun it in your server\\n```\\nscmcp run --transport shttp --port 8000\\n```\\n\\nThen configure your MCP client in local AI client, like this:\\n```\\n\\n\\\"mcpServers\\\": {\\n  \\\"scmcp\\\": {\\n    \\\"url\\\": \\\"http://localhost:8000/mcp\\\"\\n  }\\n}\\n```\\n\\n## Intelligent Tool Selection (Experimental)\\n\\nSCMCP implements an intelligent tool selection system to optimize performance and reduce token usage. \\n\\n### How it Works\\n\\nThe intelligent tool selection system operates in two phases:\\n1. **Search_tool**: First identifies the most relevant tools for your analysis\\n2. **run_tool**: Then runs only the selected tools, reducing token consumption\\n\\n\\n### Usage\\n\\n1. Ensure you have the latest version of scmcp-shared installed:\\n```bash\\npip install --upgrade scmcp-shared\\n```\\n\\n2. Start the server with intelligent tool selection enabled:\\n```bash\\nscmcp run --transport shttp --port 8000 --tool-mode auto\\n```\\n\\n3. Configure your MCP client to connect to the server:\\n```json\\n{\\n  \\\"mcpServers\\\": {\\n    \\\"scmcp\\\": {\\n      \\\"url\\\": \\\"http://localhost:8000/mcp\\\"\\n    }\\n  }\\n}\\n```\\n\\n\\n## \\ud83e\\udd1d Contributing\\n\\nIf you have any questions, welcome to submit an issue, or contact me(hsh-me@outlook.com). Contributions to the code are also welcome!\\n\\n## Citing\\nIf you use scmcp in for your research, please consider citing  following works: \\n> Wolf, F., Angerer, P. & Theis, F. SCANPY: large-scale single-cell gene expression data analysis. Genome Biol 19, 15 (2018). https://doi.org/10.1186/s13059-017-1382-0\\n\\n> Dimitrov D., Sch\\u00e4fer P.S.L, Farr E., Rodriguez Mier P., Lobentanzer S., Badia-i-Mompel P., Dugourd A., Tanevski J., Ramirez Flores R.O. and Saez-Rodriguez J. LIANA+ provides an all-in-one framework for cell\\u2013cell communication inference. Nat Cell Biol (2024). https://doi.org/10.1038/s41556-024-01469-w\\n\\n> Badia-i-Mompel P., V\\u00e9lez Santiago J., Braunger J., Geiss C., Dimitrov D., M\\u00fcller-Dott S., Taus P., Dugourd A., Holland C.H., Ramirez Flores R.O. and Saez-Rodriguez J. 2022. decoupleR: ensemble of computational methods to infer biological activities from omics data. Bioinformatics Advances. https://doi.org/10.1093/bioadv/vbac016\\n\\n> Weiler, P., Lange, M., Klein, M. et al. CellRank 2: unified fate mapping in multiview single-cell data. Nat Methods 21, 1196\\u20131205 (2024). https://doi.org/10.1038/s41592-024-02303-9\\n\\n\", \"tools\": [], \"tools_count\": 0, \"homepage\": \"https://docs.scmcphub.org/\", \"url\": \"https://github.com/scmcphub/scmcp\", \"topics\": [\"agent\", \"ai\", \"llm\", \"mcp\", \"scrna-seq\"], \"data_sources\": [\"github\"]}", "target": "", "id": "scmcphub/scmcp", "metadata": {"stage": "finance_filter"}}
{"input": "ONLY RESPOND WITH JSON. NO EXPLANATIONS. NO MARKDOWN. NO TEXT OUTSIDE JSON.\n\nAnalyze the MCP server for financial relevance. Look for keywords: payment, banking, credit, loan, finance, money, currency, crypto, investment, trading, portfolio, market, exchange, wallet, account, budget, expense, income, tax, invoice, billing, accounting, insurance, compliance, KYC, AML.\n\nJSON FORMAT (NOTHING ELSE):\n{\n  \"server_name\": \"string\",\n  \"server_id\": \"string\", \n  \"is_finance_llm\": \"yes|no|unclear\",\n  \"confidence\": \"high|medium|low\",\n  \"threat_models\": [],\n  \"analysis_notes\": \"Brief reason\"\n}\n\nIf financial keywords found: is_finance_llm=\"yes\". If not: is_finance_llm=\"no\". If unclear: is_finance_llm=\"unclear\".\n\nRESPOND ONLY WITH JSON.\n\nMCP Server Data:\n{\"server_name\": \"mcp-link\", \"server_id\": \"aurafriday/mcp-link\", \"description\": \"Let AI agents like ChatGPT & Claude use real-world local/remote tools you approve via browser extension + optional MCP server\", \"readme\": \"# \\ud83d\\udd17 MCP Link \\u2014 Let AI Agents Use Your Tools\\n\\n**MCP Link** is a complete framework that enables AI agents to **interact with the real world** through a controlled, curated, safe and verified browser- and server-based toolchain.\\n\\nThis project enables:\\n\\n* \\ud83e\\udde0 **ChatGPT**, **Claude**, **Gemini**, **Perplexity**, **Grok**, and others to **discover and use tools** via an extension in your browser\\n* \\ud83d\\udd27 A flexible **Model Context Protocol (MCP)** server that safely executes local or remote tools\\n* \\ud83e\\udde9 A fully modular recipe + plugin system that supports AI integration, monetization, and control\\n\\n---\\n\\n## \\ud83d\\ude80 Quick Start\\n\\n1. **Install the MCP Link browser extension**\\n   *(Chrome Web Store link coming soon)*\\n\\n2. **Visit a supported AI site** like ChatGPT, Claude, or Perplexity\\n\\n3. **Let the AI suggest tools** \\u2014 the extension handles the rest\\n   (no configuration required unless you want local tools)\\n\\n> \\ud83d\\udee0\\ufe0f Want more power? After install, the extension will help you set up the optional MCP server for advanced local tool use.\\n\\n---\\n\\n## \\ud83e\\udde0 What Is MCP?\\n\\n**MCP** stands for **Model Context Protocol** \\u2014 a simple runtime system that allows AI agents to:\\n\\n* Discover user-allowed tools provided to the AI by the extension based on browser site recipes\\n* Call tools using structured markup; e.g. (`<antml:function_calls>`)\\n* Route tool execution to a local or remote server\\n* Receive formatted responses back into their current conversation\\n\\nThis gives AI models plugin-like powers **without cloud dependencies**, **without vendor lock-in**, and with **user-side control**.\\n\\n---\\n\\n## \\ud83d\\udd10 Designed for Enterprise-Grade Trust\\n\\nMCP Link is built for safe, auditable real-world AI action.\\n\\n* \\ud83e\\udde0 **Agents can only see tools you\\u2019ve approved**\\n* \\ud83d\\uded1 **AIs cannot call any tool unless you\\u2019ve explicitly enabled it**\\n* \\ud83e\\uddee **Every call can prompt for user approval, unless you override it**\\n* \\ud83e\\uddf1 **Supports sandboxing via Docker for isolated tool environments**\\n* \\ud83d\\udcdc **Logs every tool request, tool response, and agent call**\\n\\nWhether you\\u2019re letting ChatGPT rename a folder, wanting Gemini to book you a hotel, or asking Claude to run semantic SQL queries, MCP Link ensures you stay in control \\u2014 every step of the way.\\n\\n---\\n\\n## \\ud83e\\uddf0 What This Repo Contains\\n\\nThis repo isn't just an extension \\u2014 it's an entire AI-tool ecosystem:\\n\\n| Folder            | Purpose                                                          |\\n| ----------------- | ---------------------------------------------------------------- |\\n| `extension/`      | Lightweight browser extension for Chrome, Firefox, Safari, etc.  |\\n| `remote/recipes/` | Enhancement recipes for popular AI sites (ChatGPT, Claude, etc.) |\\n| `server/`         | MCP SSE backend server (Python 3.9+) for tool execution          |\\n| `store/`          | Licensing, gating, and optional payment/subscription logic       |\\n| `toolspecs/`      | Shared schemas and validation logic for tools + manifests        |\\n\\n---\\n\\n## \\u2699\\ufe0f How It Works\\n\\nMCP Link activates enhancement recipes in popular AI websites like:\\n\\n* [ChatGPT.com](https://chatgpt.com)\\n* [claude.ai](https://claude.ai)\\n* [gemini.google.com/app](https://gemini.google.com/app)\\n* [perplexity.ai](https://www.perplexity.ai)\\n* [x.com/i/grok](https://x.com/i/grok)\\n\\nThese recipes tell the AI how to discover and use the tools you approve it to use via your browser.\\n\\n---\\n\\n## \\ud83e\\udde9 What Tools Can Be Called?\\n\\nMCP Link enables AI agents to call both **remote tools** (hosted online) and **local tools** (run securely on your own machine or LAN).\\n\\nTools are activated using structured markup emitted by supported AI models and interpreted by the extension \\u2014 but **only for tools the user has explicitly enabled**.\\n\\n---\\n\\n### \\ud83e\\uddcd\\u200d\\u2642\\ufe0f User-Controlled Tool Access & Security\\n\\nMCP Link gives **complete tool-level control to the user**.\\n\\nEvery tool goes through a two-step permissions process:\\n\\n| Control Layer             | Description                                                                                                                                                                                                                                                                                                             |\\n| ------------------------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\\n| \\ud83e\\udde9 **Tool Visibility**    | Users can enable or disable each tool via checkboxes in the extension UI. Only enabled tools are advertised to AI agents. Disabled tools are entirely invisible.                                                                                                                                                        |\\n| \\u2705 **Tool Usage Approval** | For enabled tools, the user can choose one of three runtime access policies:<br> - **Ask every time*\\n[...truncated for length...]\", \"tools\": [{\"name\": \"geolocation\", \"description\": \"| Reveals your location using browser GPS or IP  | \\u2705 Free    |\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"input\": {\"type\": \"string\", \"description\": \"Input parameter for geolocation\"}}, \"required\": [\"input\"]}, \"source\": \"readme\", \"access_level\": \"read\"}, {\"name\": \"weather\", \"description\": \"| Fetches local weather info using your location | \\u2705 Free    |\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"input\": {\"type\": \"string\", \"description\": \"Input parameter for weather\"}}, \"required\": [\"input\"]}, \"source\": \"readme\", \"access_level\": \"read\"}, {\"name\": \"adaptive_thinking\", \"description\": \"| Helps agents reflect, revise, and plan actions | \\u2705 Free    |\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"input\": {\"type\": \"string\", \"description\": \"Input parameter for adaptive_thinking\"}}, \"required\": [\"input\"]}, \"source\": \"readme\", \"access_level\": \"read\"}, {\"name\": \"cards\", \"description\": \"| Draws random cards for agent decision-making                 | \\u2705 Free       |\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"input\": {\"type\": \"string\", \"description\": \"Input parameter for cards\"}}, \"required\": [\"input\"]}, \"source\": \"readme\", \"access_level\": \"read\"}, {\"name\": \"sqlite\", \"description\": \"| Runs semantic and raw SQL queries on your data               | \\u2705 Free       |\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"input\": {\"type\": \"string\", \"description\": \"Input parameter for sqlite\"}}, \"required\": [\"input\"]}, \"source\": \"readme\", \"access_level\": \"execute\"}, {\"name\": \"tts\", \"description\": \"| Speaks text using your system's speakers                     | \\u2705 Free       |\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"message\": {\"type\": \"string\", \"description\": \"Text content or message\"}}, \"required\": [\"message\"]}, \"source\": \"readme\", \"access_level\": \"read\"}, {\"name\": \"stt\", \"description\": \"| Transcribes audio from your microphone                       | \\u2705 Free       |\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"input\": {\"type\": \"string\", \"description\": \"Input parameter for stt\"}}, \"required\": [\"input\"]}, \"source\": \"readme\", \"access_level\": \"read\"}, {\"name\": \"whatsapp\", \"description\": \"| Sends messages via your personal WhatsApp                    | \\ud83d\\udd10 Licensed  |\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"message\": {\"type\": \"string\", \"description\": \"Text content or message\"}}, \"required\": [\"message\"]}, \"source\": \"readme\", \"access_level\": \"execute\"}, {\"name\": \"openrouter\", \"description\": \"| Proxies multiple AI models via user API keys                 | \\u2705 Configured |\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"input\": {\"type\": \"string\", \"description\": \"Input parameter for openrouter\"}}, \"required\": [\"input\"]}, \"source\": \"readme\", \"access_level\": \"read\"}, {\"name\": \"ai_chat\", \"description\": \"| Enables agent-to-agent chat coordination                     | \\ud83d\\udd10 Licensed  |\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"input\": {\"type\": \"string\", \"description\": \"Input parameter for ai_chat\"}}, \"required\": [\"input\"]}, \"source\": \"readme\", \"access_level\": \"read\"}, {\"name\": \"docker\", \"description\": \"| **Isolates tools and actions in a secure container sandbox** | \\u2705 Critical   |\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"input\": {\"type\": \"string\", \"description\": \"Input parameter for docker\"}}, \"required\": [\"input\"]}, \"source\": \"readme\", \"access_level\": \"read\"}, {\"name\": \"LICENSE\", \"description\": \"explains how to use this repo safely\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"input\": {\"type\": \"string\", \"description\": \"Input parameter for LICENSE\"}}, \"required\": [\"input\"]}, \"source\": \"readme\", \"access_level\": \"read\"}], \"tools_count\": 12, \"homepage\": \"https://mcp.aurafriday.com/sse\", \"url\": \"https://github.com/AuraFriday/mcp-link\", \"topics\": [\"agent-tools\", \"ai-agent\", \"ai-automation\", \"ai-commerce\", \"ai-integration\", \"ai-plugins\", \"ai-toolbox\", \"browser-extension\", \"chrome-extension\", \"docker-sandbox\", \"firefox-extension\", \"mcp\", \"mcp-server\", \"mcp-store\", \"model-context-protocol\", \"safari-extension\", \"secure-ai\", \"semantic-search\", \"sse\", \"sse-server\"], \"data_sources\": [\"github\"]}", "target": "", "id": "aurafriday/mcp-link", "metadata": {"stage": "finance_filter"}}
{"input": "ONLY RESPOND WITH JSON. NO EXPLANATIONS. NO MARKDOWN. NO TEXT OUTSIDE JSON.\n\nAnalyze the MCP server for financial relevance. Look for keywords: payment, banking, credit, loan, finance, money, currency, crypto, investment, trading, portfolio, market, exchange, wallet, account, budget, expense, income, tax, invoice, billing, accounting, insurance, compliance, KYC, AML.\n\nJSON FORMAT (NOTHING ELSE):\n{\n  \"server_name\": \"string\",\n  \"server_id\": \"string\", \n  \"is_finance_llm\": \"yes|no|unclear\",\n  \"confidence\": \"high|medium|low\",\n  \"threat_models\": [],\n  \"analysis_notes\": \"Brief reason\"\n}\n\nIf financial keywords found: is_finance_llm=\"yes\". If not: is_finance_llm=\"no\". If unclear: is_finance_llm=\"unclear\".\n\nRESPOND ONLY WITH JSON.\n\nMCP Server Data:\n{\"server_name\": \"drift-detector\", \"server_id\": \"saranshhalwai/drift-detector\", \"description\": \"A proof-of-concept showing the use of a meta-agent to monitor drift in an LLM, with the use of an MCP server. \", \"readme\": \"---\\ntitle: Drift Detector\\nemoji: \\ud83d\\udcda\\ncolorFrom: blue\\ncolorTo: red\\nsdk: gradio\\nsdk_version: 5.33.0\\napp_file: app.py\\npinned: false\\nlicense: mit\\ntags: \\n- mcp-server-track\\n- agent-demo-track\\n---\\n\\nThis was made with the combined efforts of Saransh Halwai(HF username: [Sars6](https://huggingface.co/Sars6)), Harsh Bhati(HF username: [HarshBhati](https://huggingface.co/HarshBhati)), and Anurag Prasad(HF username: [LegendXInfinity](https://huggingface.co/LegendXInfinity))\\nGitHub repo: [Drift Detector](https://github.com/saranshhalwai/drift-detector)\\n\\n# Drift Detector\\nDrift Detector is an MCP server, designed to detect drift in LLM performance over time by using the power of the **sampling** functionality of MCP. \\nThis implementation is intended as a **proof of concept** and is **NOT intended** for production use without significant changes.\\n\\n## The Idea\\n\\nThe drift detector is a server that can be connected to any LLM client that supports the MCP sampling functionality. \\nIt allows you to monitor the performance of your LLM models over time, detecting any drift in their behavior.\\nThis is particularly useful for applications where the model's performance may change due to various factors, such as changes in the data distribution, model updates, or other external influences.\\n\\n## How to run\\n\\nTo run the Drift Detector, you need to have Python installed on your machine. Follow these steps:\\n\\n1. Clone the repository:\\n   ```bash\\n   git clone https://github.com/saranshhalwai/drift-detector\\n    cd drift-detector\\n    ```\\n2. Install the required dependencies:\\n    ```bash\\n    pip install -r requirements.txt\\n    ```\\n3. Start the server:\\n    ```bash\\n   gradio app.py\\n    ```\\n4. Open your web browser and navigate to `http://localhost:7860` to access the Drift Detector interface.\\n\\n## Interface\\n\\nThe interface consists of the following components:\\n- **Model Selection** - A panel allowing you to:\\n  - Select models from a dropdown list\\n  - Search for models by name or description\\n  - Create new models with custom system prompts\\n  - Enhance prompts with AI assistance\\n\\n- **Model Operations** - A tabbed interface with:\\n  - **Chatbot** - Interact with the selected model through a conversational interface\\n  - **Drift Analysis** - Analyze and visualize model drift over time, including:\\n    - Calculate new drift scores for the selected model\\n    - View historical drift data in JSON format\\n    - Visualize drift trends through interactive charts\\n\\nThe drift detection functionality allows you to track changes in model performance over time, which is essential for monitoring and maintaining model quality.\\n\\n## Under the Hood\\n\\nOur GitHub repo consists of two main components:\\n\\n- **Drift Detector Server**  \\n    A low-level MCP server that detects drift in LLM performance of the connected client.\\n- **Target Client**\\n    A client implemented using the fast-agent library, which connects to the Drift Detector server and demonstrates it's functionality.\\n\\nThe gradio interface in [app.py](app.py) is an example dashboard which allows users to interact with the Drift Detector server and visualize drift data.\\n\\n### Database Integration\\n\\nThe system uses SQLite (by default) to store:\\n- Model information (name, capabilities, creation date)\\n- Drift history (date and score for each drift calculation)\\n- Diagnostic data (baseline and current questions/answers)\\n\\nThis enables persistent tracking of model performance over time, allowing for:\\n- Historical trend analysis\\n- Comparison between different models\\n- Early detection of performance degradation\\n\\n### Drift Detector Server\\n\\nThe Drift Detector server is implemented using the MCP python SDK.\\nIt exposes the following tools:\\n\\n1. **run_initial_diagnostics**\\n   - **Purpose**: Establishes a baseline for model behavior using adaptive sampling techniques\\n   - **Parameters**:\\n     - `model`: The name of the model to run diagnostics on\\n     - `model_capabilities`: Full description of the model's capabilities and special features\\n   - **Sampling Process**:\\n     - First generates a tailored questionnaire based on model-specific capabilities\\n     - Collects responses by sampling the target model with controlled parameters (temperature=0.7)\\n     - Each question is processed individually to ensure proper context isolation\\n     - Baseline samples are stored as paired question-answer JSON records for future comparison\\n   - **Output**: Confirmation message indicating successful baseline creation\\n\\n2. **check_drift**\\n   - **Purpose**: Measures potential drift by comparative sampling against the baseline\\n   - **Parameters**:\\n     - `model`: The name of the model to check for drift\\n   - **Sampling Process**:\\n     - Retrieves the original questions from the baseline\\n     - Re-samples the model with identical questions using the same sampling parameters\\n     - Maintains consistent context conditions to ensure fair comparison\\n     - Uses differential analysis to compare semantic and functional differences between sample sets\\n   - **Drift Evaluation*\\n[...truncated for length...]\", \"tools\": [{\"name\": \"model\", \"description\": \"The name of the model to run diagnostics on\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"input\": {\"type\": \"string\", \"description\": \"Input parameter for model\"}}, \"required\": [\"input\"]}, \"source\": \"readme\", \"access_level\": \"execute\"}, {\"name\": \"model_capabilities\", \"description\": \"Full description of the model's capabilities and special features\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"input\": {\"type\": \"string\", \"description\": \"Input parameter for model_capabilities\"}}, \"required\": [\"input\"]}, \"source\": \"readme\", \"access_level\": \"read\"}, {\"name\": \"run_initial_diagnostics\", \"description\": \"tool.\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"input\": {\"type\": \"string\", \"description\": \"Input parameter for run_initial_diagnostics\"}}, \"required\": [\"input\"]}, \"source\": \"readme\", \"access_level\": \"execute\"}, {\"name\": \"check_drift\", \"description\": \"tool to measure potential drift in the model's performance.\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"input\": {\"type\": \"string\", \"description\": \"Input parameter for check_drift\"}}, \"required\": [\"input\"]}, \"source\": \"readme\", \"access_level\": \"read\"}], \"tools_count\": 4, \"homepage\": \"https://huggingface.co/spaces/Agents-MCP-Hackathon/drift-detector\", \"url\": \"https://github.com/saranshhalwai/drift-detector\", \"topics\": [], \"data_sources\": [\"github\"]}", "target": "", "id": "saranshhalwai/drift-detector", "metadata": {"stage": "finance_filter"}}
{"input": "ONLY RESPOND WITH JSON. NO EXPLANATIONS. NO MARKDOWN. NO TEXT OUTSIDE JSON.\n\nAnalyze the MCP server for financial relevance. Look for keywords: payment, banking, credit, loan, finance, money, currency, crypto, investment, trading, portfolio, market, exchange, wallet, account, budget, expense, income, tax, invoice, billing, accounting, insurance, compliance, KYC, AML.\n\nJSON FORMAT (NOTHING ELSE):\n{\n  \"server_name\": \"string\",\n  \"server_id\": \"string\", \n  \"is_finance_llm\": \"yes|no|unclear\",\n  \"confidence\": \"high|medium|low\",\n  \"threat_models\": [],\n  \"analysis_notes\": \"Brief reason\"\n}\n\nIf financial keywords found: is_finance_llm=\"yes\". If not: is_finance_llm=\"no\". If unclear: is_finance_llm=\"unclear\".\n\nRESPOND ONLY WITH JSON.\n\nMCP Server Data:\n{\"server_name\": \"mcp-postman\", \"server_id\": \"shannonlal/mcp-postman\", \"description\": \"MCP server for running Postman Collections locally via Newman. Allows for simple execution of Postman Server and returns the results of whether the collection passed all the tests.\", \"readme\": \"# Postman MCP Server\\n[![smithery badge](https://smithery.ai/badge/mcp-postman)](https://smithery.ai/server/mcp-postman)\\n\\nAn MCP (Model Context Protocol) server that enables running Postman collections using Newman. This server allows LLMs to execute API tests and get detailed results through a standardized interface.\\n\\n[![MCP Postman Server Demo](https://img.youtube.com/vi/d1WgTqwMsog/0.jpg)](https://youtu.be/d1WgTqwMsog)\\n\\n<a href=\\\"https://glama.ai/mcp/servers/qfx34b2s2v\\\"><img width=\\\"380\\\" height=\\\"200\\\" src=\\\"https://glama.ai/mcp/servers/qfx34b2s2v/badge\\\" alt=\\\"Postman Server MCP server\\\" /></a>\\n\\n## Features\\n\\n- Run Postman collections using Newman\\n- Support for environment files\\n- Support for global variables\\n- Detailed test results including:\\n  - Overall success/failure status\\n  - Test summary (total, passed, failed)\\n  - Detailed failure information\\n  - Execution timings\\n\\n## Installation\\n\\n### Installing via Smithery\\n\\nTo install Postman Runner for Claude Desktop automatically via [Smithery](https://smithery.ai/server/mcp-postman):\\n\\n```bash\\nnpx -y @smithery/cli install mcp-postman --client claude\\n```\\n\\n### Manual Installation\\n```bash\\n# Clone the repository\\ngit clone <repository-url>\\ncd mcp-postman\\n\\n# Install dependencies\\npnpm install\\n\\n# Build the project\\npnpm build\\n```\\n\\n## Usage\\n\\n### Configuration\\n\\nAdd the server to your Claude desktop configuration file at `~/Library/Application Support/Claude/claude_desktop_config.json`:\\n\\n```json\\n{\\n  \\\"mcpServers\\\": {\\n    \\\"postman-runner\\\": {\\n      \\\"command\\\": \\\"node\\\",\\n      \\\"args\\\": [\\\"/absolute/path/to/mcp-postman/build/index.js\\\"]\\n    }\\n  }\\n}\\n```\\n\\n### Available Tools\\n\\n#### run-collection\\n\\nRuns a Postman collection and returns the test results.\\n\\n**Parameters:**\\n\\n- `collection` (required): Path or URL to the Postman collection\\n- `environment` (optional): Path or URL to environment file\\n- `globals` (optional): Path or URL to globals file\\n- `iterationCount` (optional): Number of iterations to run\\n\\n**Example Response:**\\n\\n```json\\n{\\n  \\\"success\\\": true,\\n  \\\"summary\\\": {\\n    \\\"total\\\": 5,\\n    \\\"failed\\\": 0,\\n    \\\"passed\\\": 5\\n  },\\n  \\\"failures\\\": [],\\n  \\\"timings\\\": {\\n    \\\"started\\\": \\\"2024-03-14T10:00:00.000Z\\\",\\n    \\\"completed\\\": \\\"2024-03-14T10:00:01.000Z\\\",\\n    \\\"duration\\\": 1000\\n  }\\n}\\n```\\n\\n### Example Usage in Claude\\n\\nYou can use the server in Claude by asking it to run a Postman collection:\\n\\n\\\"Run the Postman collection at /path/to/collection.json and tell me if all tests passed\\\"\\n\\nClaude will:\\n\\n1. Use the run-collection tool\\n2. Analyze the test results\\n3. Provide a human-friendly summary of the execution\\n\\n## Development\\n\\n### Project Structure\\n\\n```\\nsrc/\\n  \\u251c\\u2500\\u2500 index.ts           # Entry point\\n  \\u251c\\u2500\\u2500 server/\\n  \\u2502   \\u251c\\u2500\\u2500 server.ts     # MCP Server implementation\\n  \\u2502   \\u2514\\u2500\\u2500 types.ts      # Type definitions\\n  \\u2514\\u2500\\u2500 newman/\\n      \\u2514\\u2500\\u2500 runner.ts     # Newman runner implementation\\ntest/\\n  \\u251c\\u2500\\u2500 server.test.ts    # Server tests\\n  \\u251c\\u2500\\u2500 newman-runner.test.ts  # Runner tests\\n  \\u2514\\u2500\\u2500 fixtures/         # Test fixtures\\n      \\u2514\\u2500\\u2500 sample-collection.json\\n```\\n\\n### Running Tests\\n\\n```bash\\n# Run tests\\npnpm test\\n\\n# Run tests with coverage\\npnpm test:coverage\\n```\\n\\n### Building\\n\\n```bash\\n# Build the project\\npnpm build\\n\\n# Clean build artifacts\\npnpm clean\\n```\\n\\n## Contributing\\n\\n1. Fork the repository\\n2. Create your feature branch (`git checkout -b feature/amazing-feature`)\\n3. Commit your changes (`git commit -m 'Add some amazing feature'`)\\n4. Push to the branch (`git push origin feature/amazing-feature`)\\n5. Open a Pull Request\\n\\n## License\\n\\nISC\\n\", \"tools\": [{\"name\": \"collection\", \"description\": \"(required): Path or URL to the Postman collection\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"file_path\": {\"type\": \"string\", \"description\": \"File path or file to process\"}, \"url\": {\"type\": \"string\", \"description\": \"URL or link to process\"}}, \"required\": [\"file_path\", \"url\"]}, \"source\": \"readme\", \"access_level\": \"read\"}, {\"name\": \"environment\", \"description\": \"(optional): Path or URL to environment file\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"file_path\": {\"type\": \"string\", \"description\": \"File path or file to process\"}, \"url\": {\"type\": \"string\", \"description\": \"URL or link to process\"}}, \"required\": [\"file_path\", \"url\"]}, \"source\": \"readme\", \"access_level\": \"read\"}, {\"name\": \"globals\", \"description\": \"(optional): Path or URL to globals file\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"file_path\": {\"type\": \"string\", \"description\": \"File path or file to process\"}, \"url\": {\"type\": \"string\", \"description\": \"URL or link to process\"}}, \"required\": [\"file_path\", \"url\"]}, \"source\": \"readme\", \"access_level\": \"read\"}, {\"name\": \"iterationCount\", \"description\": \"(optional): Number of iterations to run\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"input\": {\"type\": \"string\", \"description\": \"Input parameter for iterationCount\"}}, \"required\": [\"input\"]}, \"source\": \"readme\", \"access_level\": \"execute\"}], \"tools_count\": 4, \"homepage\": \"\", \"url\": \"https://github.com/shannonlal/mcp-postman\", \"topics\": [], \"data_sources\": [\"github\", \"official\"]}", "target": "", "id": "shannonlal/mcp-postman", "metadata": {"stage": "finance_filter"}}
{"input": "ONLY RESPOND WITH JSON. NO EXPLANATIONS. NO MARKDOWN. NO TEXT OUTSIDE JSON.\n\nAnalyze the MCP server for financial relevance. Look for keywords: payment, banking, credit, loan, finance, money, currency, crypto, investment, trading, portfolio, market, exchange, wallet, account, budget, expense, income, tax, invoice, billing, accounting, insurance, compliance, KYC, AML.\n\nJSON FORMAT (NOTHING ELSE):\n{\n  \"server_name\": \"string\",\n  \"server_id\": \"string\", \n  \"is_finance_llm\": \"yes|no|unclear\",\n  \"confidence\": \"high|medium|low\",\n  \"threat_models\": [],\n  \"analysis_notes\": \"Brief reason\"\n}\n\nIf financial keywords found: is_finance_llm=\"yes\". If not: is_finance_llm=\"no\". If unclear: is_finance_llm=\"unclear\".\n\nRESPOND ONLY WITH JSON.\n\nMCP Server Data:\n{\"server_name\": \"my-apple-remembers\", \"server_id\": \"honeybluesky/my-apple-remembers\", \"description\": \"A lightweight MCP server that integrates with Apple Notes to create a personal memory system for AI. Easily recall and save information from your Mac using simple AppleScript commands. Compatible with all macOS versions with minimal setup requirements.\", \"readme\": \"# MCP Server - My Apple Remembers\\n**A simple MCP server that recalls and saves memories from and to Apple Notes.**\\n\\n[![Docker Pulls](https://img.shields.io/docker/pulls/buryhuang/mcp-my-apple-remembers)](https://hub.docker.com/r/buryhuang/mcp-my-apple-remembers)\\n[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)\\n\\n<img width=\\\"600\\\" alt=\\\"image\\\" src=\\\"https://github.com/user-attachments/assets/9bd5bc1c-02fe-4e71-88c4-46b3e9438ac0\\\" />\\n\\n\\n## Features\\n\\n* **Memory Recall**: Access notes, calendar events, messages, files and other information from your Mac\\n* **Memory Persistence**: Save important information to Apple Notes for future reference\\n* **Minimal Setup**: Just enable Remote Login on the target Mac\\n* **Universal Compatibility**: Works with all macOS versions\\n\\n## Control in your hand\\nYou can use prompt to instruct how you want your memory to be save. For example:\\n```\\nYou should always use Folder \\\"baryhuang\\\" on recall and save memory.\\n```\\n\\n## Installation\\n- [Enable SSH on macOS](https://support.apple.com/guide/mac-help/allow-a-remote-computer-to-access-your-mac-mchlp1066/mac)\\n- [Install Docker Desktop for local Mac](https://docs.docker.com/desktop/setup/install/mac-install/)\\n- [Add this MCP server to Claude Desktop](https://modelcontextprotocol.io/quickstart/user)\\n\\nYou can configure Claude Desktop to use the Docker image by adding the following to your Claude configuration:\\n```json\\n{\\n  \\\"mcpServers\\\": {\\n    \\\"my-apple-remembers\\\": {\\n      \\\"command\\\": \\\"docker\\\",\\n      \\\"args\\\": [\\n        \\\"run\\\",\\n        \\\"-i\\\",\\n        \\\"-e\\\",\\n        \\\"MACOS_USERNAME=your_macos_username\\\",\\n        \\\"-e\\\",\\n        \\\"MACOS_PASSWORD=your_macos_password\\\",\\n        \\\"-e\\\",\\n        \\\"MACOS_HOST=localhost\\\",\\n        \\\"--rm\\\",\\n        \\\"buryhuang/mcp-my-apple-remembers:latest\\\"\\n      ]\\n    }\\n  }\\n}\\n```\\n\\n## Developer Instructions\\n### Clone the repo\\n```bash\\n# Clone the repository\\ngit clone https://github.com/baryhuang/mcp-my-apple-remembers.git\\ncd mcp-my-apple-remembers\\n```\\n\\n### Building the Docker Image\\n\\n```bash\\n# Build the Docker image\\ndocker build -t mcp-my-apple-remembers .\\n```\\n\\n### Publishing Multi-Platform Docker Images\\n\\n```bash\\n# Set up Docker buildx for multi-platform builds\\ndocker buildx create --use\\n\\n# Build and push the multi-platform image\\ndocker buildx build --platform linux/amd64,linux/arm64 -t buryhuang/mcp-my-apple-remembers:latest --push .\\n```\\n\\n### Tools Specifications\\n\\n#### my_apple_recall_memory\\nRun AppleScript commands on a remote macOS system to recall memories. This tool helps access Apple Notes, Calendar events, iMessages, chat history, files, and other information on your Mac.\\n\\n#### my_apple_save_memory\\nRun AppleScript commands on a remote macOS system to save important information. This tool allows AI to persist relevant information to Apple Notes for future reference. \\n\\nAll tools require macOS SSH access, with host and password.\\n\\n## Security Note\\n\\nAlways use secure, authenticated connections when accessing remote macOS machines. This tool should only be used with servers you trust and have permission to access.\\n\\n## License\\n\\nSee the LICENSE file for details. \\n\", \"tools\": [], \"tools_count\": 0, \"homepage\": \"\", \"url\": \"https://github.com/honeybluesky/my-apple-remembers\", \"topics\": [\"agent-memory\", \"agentic-ai\", \"macos\", \"mcp-server\"], \"data_sources\": [\"github\"]}", "target": "", "id": "honeybluesky/my-apple-remembers", "metadata": {"stage": "finance_filter"}}
{"input": "ONLY RESPOND WITH JSON. NO EXPLANATIONS. NO MARKDOWN. NO TEXT OUTSIDE JSON.\n\nAnalyze the MCP server for financial relevance. Look for keywords: payment, banking, credit, loan, finance, money, currency, crypto, investment, trading, portfolio, market, exchange, wallet, account, budget, expense, income, tax, invoice, billing, accounting, insurance, compliance, KYC, AML.\n\nJSON FORMAT (NOTHING ELSE):\n{\n  \"server_name\": \"string\",\n  \"server_id\": \"string\", \n  \"is_finance_llm\": \"yes|no|unclear\",\n  \"confidence\": \"high|medium|low\",\n  \"threat_models\": [],\n  \"analysis_notes\": \"Brief reason\"\n}\n\nIf financial keywords found: is_finance_llm=\"yes\". If not: is_finance_llm=\"no\". If unclear: is_finance_llm=\"unclear\".\n\nRESPOND ONLY WITH JSON.\n\nMCP Server Data:\n{\"server_name\": \"HuggingMCP\", \"server_id\": \"procreations-official/huggingmcp\", \"description\": \"Model Context Protocol (MCP) server for HuggingFace integration - lets Claude create, manage, and interact with HuggingFace spaces, models, datasets, and collections\", \"readme\": \"# HuggingMCP - Enhanced Hugging Face MCP Server\\n\\nA comprehensive and optimized Model Context Protocol (MCP) server for Hugging Face Hub operations, featuring 10 consolidated commands, enhanced debugging, and robust error handling.\\n\\n## \\ud83d\\ude80 Features\\n\\n- **Optimized Command Structure**: Consolidated from 23+ commands to 10 main commands\\n- **Enhanced Debugging**: Comprehensive stderr output and logging for troubleshooting\\n- **Robust Error Handling**: Safe execution wrappers and detailed error reporting\\n- **Batch Operations**: Execute multiple operations efficiently\\n- **Advanced Search**: Cross-content search with popularity scoring\\n- **File Operations**: Read, write, edit, and delete files with chunked reading support\\n- **Repository Management**: Create, delete, and manage repositories with creator tracking\\n- **Pull Request Support**: Create and manage PRs with file changes\\n- **Collection Management**: Create and manage Hugging Face collections\\n- **Comprehensive Diagnostics**: System health checks and connectivity testing\\n\\n## \\ud83d\\udccb Prerequisites\\n\\n- Python 3.8+\\n- Required packages:\\n  ```bash\\n  pip install mcp huggingface_hub\\n  ```\\n- Hugging Face token (set as `HF_TOKEN` environment variable)\\n\\n## \\u2699\\ufe0f Configuration\\n\\nAdd to your Claude Desktop configuration file at:\\n`/Users/[username]/Library/Application Support/Claude/claude_desktop_config.json`\\n\\n```json\\n{\\n  \\\"mcpServers\\\": {\\n    \\\"huggingmcp\\\": {\\n      \\\"command\\\": \\\"python3\\\",\\n      \\\"args\\\": [\\\"/Users/sshpro/Documents/hugmcp.py\\\"],\\n      \\\"env\\\": {\\n        \\\"HF_TOKEN\\\": \\\"your_hugging_face_token_here\\\",\\n        \\\"HF_ADMIN_MODE\\\": \\\"true\\\",\\n        \\\"HF_READ_ONLY\\\": \\\"false\\\",\\n        \\\"HF_WRITE_ONLY\\\": \\\"false\\\",\\n        \\\"HF_MAX_FILE_SIZE\\\": \\\"100000000\\\"\\n      }\\n    }\\n  }\\n}\\n```\\n\\n### Environment Variables\\n\\n- `HF_TOKEN`: Your Hugging Face API token (required for write operations)\\n- `HF_ADMIN_MODE`: Enable admin operations like repository deletion (default: false)\\n- `HF_READ_ONLY`: Restrict to read-only operations (default: false)\\n- `HF_MAX_FILE_SIZE`: Maximum file size for operations (default: 100MB)\\n\\n## \\ud83d\\udee0\\ufe0f Available Commands\\n\\n### 1. `hf_system_info()`\\nGet system information, configuration, and test connectivity.\\n```python\\n# Returns server status, configuration, user info, and capabilities\\n```\\n\\n### 2. `hf_repository_manager(action, repo_id, repo_type=\\\"model\\\", **kwargs)`\\nComprehensive repository management.\\n\\n**Actions:**\\n- `create`: Create new repository\\n  - `private`: Make repository private (default: False)\\n  - `description`: Repository description\\n  - `space_sdk`: For Spaces - \\\"gradio\\\", \\\"streamlit\\\", \\\"docker\\\", \\\"static\\\"\\n  - `creator`: Repository creator (defaults to authenticated user)\\n- `delete`: Delete repository (requires admin mode)\\n- `info`: Get repository information\\n- `list_files`: List all files in repository\\n\\n**Examples:**\\n```python\\n# Create a public model repository\\nhf_repository_manager(\\\"create\\\", \\\"my-awesome-model\\\", \\\"model\\\", \\n                     description=\\\"My awesome AI model\\\")\\n\\n# Create a private Gradio space\\nhf_repository_manager(\\\"create\\\", \\\"my-space\\\", \\\"space\\\", \\n                     private=True, space_sdk=\\\"gradio\\\")\\n\\n# Get repository info\\nhf_repository_manager(\\\"info\\\", \\\"microsoft/DialoGPT-medium\\\")\\n\\n# List files in repository\\nhf_repository_manager(\\\"list_files\\\", \\\"gpt2\\\")\\n```\\n\\n### 3. `hf_file_operations(action, repo_id, filename, repo_type=\\\"model\\\", **kwargs)`\\nComprehensive file operations.\\n\\n**Actions:**\\n- `read`: Read file content\\n  - `max_size`: Maximum characters to read (default: 500,000)\\n  - `chunk_size`: Enable chunked reading\\n  - `chunk_number`: Chunk number to read (for chunked reading)\\n- `write`: Write/upload file content\\n  - `content`: File content to write\\n  - `commit_message`: Commit message\\n- `edit`: Edit file by replacing text\\n  - `old_text`: Text to replace\\n  - `new_text`: Replacement text\\n  - `commit_message`: Commit message\\n- `delete`: Delete file from repository\\n\\n**Examples:**\\n```python\\n# Read a file (truncated to 1000 chars)\\nhf_file_operations(\\\"read\\\", \\\"gpt2\\\", \\\"README.md\\\", max_size=1000)\\n\\n# Read file in chunks\\nhf_file_operations(\\\"read\\\", \\\"gpt2\\\", \\\"config.json\\\", chunk_size=1000, chunk_number=0)\\n\\n# Write a new file\\nhf_file_operations(\\\"write\\\", \\\"my-repo\\\", \\\"new_file.txt\\\", \\n                  content=\\\"Hello World!\\\", \\n                  commit_message=\\\"Add new file\\\")\\n\\n# Edit existing file\\nhf_file_operations(\\\"edit\\\", \\\"my-repo\\\", \\\"README.md\\\",\\n                  old_text=\\\"# Old Title\\\",\\n                  new_text=\\\"# New Title\\\",\\n                  commit_message=\\\"Update title\\\")\\n```\\n\\n### 4. `hf_search_hub(content_type, query=None, author=None, filter_tag=None, limit=20)`\\nSearch Hugging Face Hub for models, datasets, or spaces.\\n\\n**Examples:**\\n```python\\n# Search for transformer models\\nhf_search_hub(\\\"models\\\", query=\\\"transformer\\\", limit=10)\\n\\n# Search for datasets by specific author\\nhf_search_hub(\\\"datasets\\\", author=\\\"huggingface\\\", limit=5)\\n\\n# Search for Gradio spaces\\nhf_search_hub(\\\"spaces\\\", filter_tag=\\\"gradio\\\")\\n```\\n\\n### 5. `hf_collections(action, **kwargs)`\\nManage Hugging Face Collections.\\n\\n**Actions:*\\n[...truncated for length...]\", \"tools\": [{\"name\": \"HF_TOKEN\", \"description\": \"environment variable)\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"input\": {\"type\": \"string\", \"description\": \"Input parameter for HF_TOKEN\"}}, \"required\": [\"input\"]}, \"source\": \"readme\", \"access_level\": \"read\"}, {\"name\": \"HF_ADMIN_MODE\", \"description\": \"Enable admin operations like repository deletion (default: false)\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"input\": {\"type\": \"string\", \"description\": \"Input parameter for HF_ADMIN_MODE\"}}, \"required\": [\"input\"]}, \"source\": \"readme\", \"access_level\": \"read\"}, {\"name\": \"HF_READ_ONLY\", \"description\": \"Restrict to read-only operations (default: false)\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"input\": {\"type\": \"string\", \"description\": \"Input parameter for HF_READ_ONLY\"}}, \"required\": [\"input\"]}, \"source\": \"readme\", \"access_level\": \"read\"}, {\"name\": \"HF_MAX_FILE_SIZE\", \"description\": \"Maximum file size for operations (default: 100MB)\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"file_path\": {\"type\": \"string\", \"description\": \"File path or file to process\"}}, \"required\": [\"file_path\"]}, \"source\": \"readme\", \"access_level\": \"read\"}, {\"name\": \"create\", \"description\": \"Create new repository\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"input\": {\"type\": \"string\", \"description\": \"Input parameter for create\"}}, \"required\": [\"input\"]}, \"source\": \"readme\", \"access_level\": \"write\"}, {\"name\": \"private\", \"description\": \"Make repository private (default: False)\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"input\": {\"type\": \"string\", \"description\": \"Input parameter for private\"}}, \"required\": [\"input\"]}, \"source\": \"readme\", \"access_level\": \"write\"}, {\"name\": \"description\", \"description\": \"Repository description\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"input\": {\"type\": \"string\", \"description\": \"Input parameter for description\"}}, \"required\": [\"input\"]}, \"source\": \"readme\", \"access_level\": \"read\"}, {\"name\": \"space_sdk\", \"description\": \"For Spaces - \\\"gradio\\\", \\\"streamlit\\\", \\\"docker\\\", \\\"static\\\"\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"input\": {\"type\": \"string\", \"description\": \"Input parameter for space_sdk\"}}, \"required\": [\"input\"]}, \"source\": \"readme\", \"access_level\": \"read\"}, {\"name\": \"creator\", \"description\": \"Repository creator (defaults to authenticated user)\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"input\": {\"type\": \"string\", \"description\": \"Input parameter for creator\"}}, \"required\": [\"input\"]}, \"source\": \"readme\", \"access_level\": \"read\"}, {\"name\": \"delete\", \"description\": \"Delete repository (requires admin mode)\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"input\": {\"type\": \"string\", \"description\": \"Input parameter for delete\"}}, \"required\": [\"input\"]}, \"source\": \"readme\", \"access_level\": \"execute\"}, {\"name\": \"info\", \"description\": \"Get repository information\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"input\": {\"type\": \"string\", \"description\": \"Input parameter for info\"}}, \"required\": [\"input\"]}, \"source\": \"readme\", \"access_level\": \"read\"}, {\"name\": \"list_files\", \"description\": \"List all files in repository\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"file_path\": {\"type\": \"string\", \"description\": \"File path or file to process\"}}, \"required\": [\"file_path\"]}, \"source\": \"readme\", \"access_level\": \"read\"}, {\"name\": \"read\", \"description\": \"Read file content\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"file_path\": {\"type\": \"string\", \"description\": \"File path or file to process\"}, \"message\": {\"type\": \"string\", \"description\": \"Text content or message\"}}, \"required\": [\"file_path\", \"message\"]}, \"source\": \"readme\", \"access_level\": \"read\"}, {\"name\": \"max_size\", \"description\": \"Maximum characters to read (default: 500,000)\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"input\": {\"type\": \"string\", \"description\": \"Input parameter for max_size\"}}, \"required\": [\"input\"]}, \"source\": \"readme\", \"access_level\": \"read\"}, {\"name\": \"chunk_size\", \"description\": \"Enable chunked reading\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"input\": {\"type\": \"string\", \"description\": \"Input parameter for chunk_size\"}}, \"required\": [\"input\"]}, \"source\": \"readme\", \"access_level\": \"read\"}, {\"name\": \"chunk_number\", \"description\": \"Chunk number to read (for chunked reading)\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"input\": {\"type\": \"string\", \"description\": \"Input parameter for chunk_number\"}}, \"required\": [\"input\"]}, \"source\": \"readme\", \"access_level\": \"read\"}, {\"name\": \"write\", \"description\": \"Write/upload file content\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"file_path\": {\"type\": \"string\", \"description\": \"File path or file to process\"}, \"message\": {\"type\": \"string\", \"description\": \"Text content or message\"}}, \"required\": [\"file_path\", \"message\"]}, \"source\": \"readme\", \"access_level\": \"write\"}, {\"name\": \"content\", \"description\": \"File content to write\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"file_path\": {\"type\": \"string\", \"description\": \"File path or file to process\"}, \"message\": {\"type\": \"string\", \"description\": \"Text content or message\"}}, \"required\": [\"file_path\", \"message\"]}, \"source\": \"readme\", \"access_level\": \"write\"}, {\"name\": \"commit_message\", \"description\": \"Commit message\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"message\": {\"type\": \"string\", \"description\": \"Text content or message\"}}, \"required\": [\"message\"]}, \"source\": \"readme\", \"access_level\": \"read\"}, {\"name\": \"edit\", \"description\": \"Edit file by replacing text\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"file_path\": {\"type\": \"string\", \"description\": \"File path or file to process\"}, \"message\": {\"type\": \"string\", \"description\": \"Text content or message\"}}, \"required\": [\"file_path\", \"message\"]}, \"source\": \"readme\", \"access_level\": \"write\"}, {\"name\": \"old_text\", \"description\": \"Text to replace\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"message\": {\"type\": \"string\", \"description\": \"Text content or message\"}}, \"required\": [\"message\"]}, \"source\": \"readme\", \"access_level\": \"read\"}, {\"name\": \"new_text\", \"description\": \"Replacement text\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"message\": {\"type\": \"string\", \"description\": \"Text content or message\"}}, \"required\": [\"message\"]}, \"source\": \"readme\", \"access_level\": \"read\"}, {\"name\": \"title\", \"description\": \"Collection title (required)\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"input\": {\"type\": \"string\", \"description\": \"Input parameter for title\"}}, \"required\": [\"input\"]}, \"source\": \"readme\", \"access_level\": \"read\"}, {\"name\": \"namespace\", \"description\": \"Collection namespace (defaults to user)\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"input\": {\"type\": \"string\", \"description\": \"Input parameter for namespace\"}}, \"required\": [\"input\"]}, \"source\": \"readme\", \"access_level\": \"read\"}, {\"name\": \"add_item\", \"description\": \"Add item to collection\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"input\": {\"type\": \"string\", \"description\": \"Input parameter for add_item\"}}, \"required\": [\"input\"]}, \"source\": \"readme\", \"access_level\": \"write\"}, {\"name\": \"collection_slug\", \"description\": \"Collection identifier\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"input\": {\"type\": \"string\", \"description\": \"Input parameter for collection_slug\"}}, \"required\": [\"input\"]}, \"source\": \"readme\", \"access_level\": \"read\"}, {\"name\": \"item_id\", \"description\": \"Item to add (repo ID)\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"input\": {\"type\": \"string\", \"description\": \"Input parameter for item_id\"}}, \"required\": [\"input\"]}, \"source\": \"readme\", \"access_level\": \"write\"}, {\"name\": \"item_type\", \"description\": \"Type of item (\\\"model\\\", \\\"dataset\\\", \\\"space\\\")\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"input\": {\"type\": \"string\", \"description\": \"Input parameter for item_type\"}}, \"required\": [\"input\"]}, \"source\": \"readme\", \"access_level\": \"write\"}, {\"name\": \"note\", \"description\": \"Optional note about the item\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"input\": {\"type\": \"string\", \"description\": \"Input parameter for note\"}}, \"required\": [\"input\"]}, \"source\": \"readme\", \"access_level\": \"read\"}, {\"name\": \"list\", \"description\": \"List PRs\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"input\": {\"type\": \"string\", \"description\": \"Input parameter for list\"}}, \"required\": [\"input\"]}, \"source\": \"readme\", \"access_level\": \"read\"}, {\"name\": \"status\", \"description\": \"Filter by status (\\\"open\\\", \\\"closed\\\", \\\"all\\\")\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"input\": {\"type\": \"string\", \"description\": \"Input parameter for status\"}}, \"required\": [\"input\"]}, \"source\": \"readme\", \"access_level\": \"read\"}, {\"name\": \"author\", \"description\": \"Filter by author\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"input\": {\"type\": \"string\", \"description\": \"Input parameter for author\"}}, \"required\": [\"input\"]}, \"source\": \"readme\", \"access_level\": \"read\"}, {\"name\": \"details\", \"description\": \"Get PR details\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"input\": {\"type\": \"string\", \"description\": \"Input parameter for details\"}}, \"required\": [\"input\"]}, \"source\": \"readme\", \"access_level\": \"read\"}, {\"name\": \"pr_number\", \"description\": \"PR number to get details for\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"input\": {\"type\": \"string\", \"description\": \"Input parameter for pr_number\"}}, \"required\": [\"input\"]}, \"source\": \"readme\", \"access_level\": \"read\"}, {\"name\": \"create_with_files\", \"description\": \"Create PR with file changes\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"file_path\": {\"type\": \"string\", \"description\": \"File path or file to process\"}}, \"required\": [\"file_path\"]}, \"source\": \"readme\", \"access_level\": \"write\"}, {\"name\": \"files\", \"description\": \"List of {path, content} dictionaries\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"file_path\": {\"type\": \"string\", \"description\": \"File path or file to process\"}, \"message\": {\"type\": \"string\", \"description\": \"Text content or message\"}}, \"required\": [\"file_path\", \"message\"]}, \"source\": \"readme\", \"access_level\": \"read\"}, {\"name\": \"pr_title\", \"description\": \"PR title\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"input\": {\"type\": \"string\", \"description\": \"Input parameter for pr_title\"}}, \"required\": [\"input\"]}, \"source\": \"readme\", \"access_level\": \"read\"}, {\"name\": \"pr_description\", \"description\": \"PR description\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"input\": {\"type\": \"string\", \"description\": \"Input parameter for pr_description\"}}, \"required\": [\"input\"]}, \"source\": \"readme\", \"access_level\": \"read\"}, {\"name\": \"single_file\", \"description\": \"Upload one file\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"file_path\": {\"type\": \"string\", \"description\": \"File path or file to process\"}}, \"required\": [\"file_path\"]}, \"source\": \"readme\", \"access_level\": \"read\"}, {\"name\": \"file_path\", \"description\": \"Path in repository\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"file_path\": {\"type\": \"string\", \"description\": \"File path or file to process\"}}, \"required\": [\"file_path\"]}, \"source\": \"readme\", \"access_level\": \"read\"}, {\"name\": \"multiple_files\", \"description\": \"Upload multiple files\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"file_path\": {\"type\": \"string\", \"description\": \"File path or file to process\"}}, \"required\": [\"file_path\"]}, \"source\": \"readme\", \"access_level\": \"read\"}, {\"name\": \"with_pr\", \"description\": \"Upload file(s) and create PR\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"file_path\": {\"type\": \"string\", \"description\": \"File path or file to process\"}}, \"required\": [\"file_path\"]}, \"source\": \"readme\", \"access_level\": \"write\"}, {\"name\": \"search\", \"description\": \"Batch search operations\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"query\": {\"type\": \"string\", \"description\": \"Search query or term\"}}, \"required\": [\"query\"]}, \"source\": \"readme\", \"access_level\": \"read\"}], \"tools_count\": 43, \"homepage\": \"\", \"url\": \"https://github.com/ProCreations-Official/HuggingMCP\", \"topics\": [], \"data_sources\": [\"github\"]}", "target": "", "id": "procreations-official/huggingmcp", "metadata": {"stage": "finance_filter"}}
{"input": "ONLY RESPOND WITH JSON. NO EXPLANATIONS. NO MARKDOWN. NO TEXT OUTSIDE JSON.\n\nAnalyze the MCP server for financial relevance. Look for keywords: payment, banking, credit, loan, finance, money, currency, crypto, investment, trading, portfolio, market, exchange, wallet, account, budget, expense, income, tax, invoice, billing, accounting, insurance, compliance, KYC, AML.\n\nJSON FORMAT (NOTHING ELSE):\n{\n  \"server_name\": \"string\",\n  \"server_id\": \"string\", \n  \"is_finance_llm\": \"yes|no|unclear\",\n  \"confidence\": \"high|medium|low\",\n  \"threat_models\": [],\n  \"analysis_notes\": \"Brief reason\"\n}\n\nIf financial keywords found: is_finance_llm=\"yes\". If not: is_finance_llm=\"no\". If unclear: is_finance_llm=\"unclear\".\n\nRESPOND ONLY WITH JSON.\n\nMCP Server Data:\n{\"server_name\": \"Volatility-MCP-Server\", \"server_id\": \"omghozlan/volatility-mcp-server\", \"description\": \" MCP (Model Context Protocol) interface for Volatility 3, providing memory forensics capabilities through LLM-based tools. Query, analyze, and automate Volatility 3 plugins using natural language via API or agent-based workflows\", \"readme\": \"# \\u2744\\ufe0f Volatility MCP Server\\n\\n[![Python](https://img.shields.io/badge/Python-3.11-blue.svg)](https://www.python.org/downloads/release/python-3110/)\\n[![Volatility 3](https://img.shields.io/badge/Volatility-3.x-success)](https://github.com/volatilityfoundation/volatility3)\\n[![Docker (Not) Ready](https://img.shields.io/badge/Docker-Ready-green)](https://hub.docker.com/)\\n[![FastMCP](https://img.shields.io/badge/FastMCP-Server-red.svg)](https://github.com/Textualize/fastmcp)\\n\\n---\\n\\n## \\ud83d\\udccc Overview\\n\\nThe Volatility MCP Server is a powerful memory forensics automation toolkit powered by **Volatility 3**. It provides a modular, extensible interface for running Volatility plugins across Windows, Linux, and macOS memory dumps.\\n\\nIt makes memory analysis faster and more accessible via:\\n\\n\\u2705 Plugin automation  \\n\\u2705 Cross-platform support (Windows, Linux, macOS)  \\n\\u2705 Modular plugin architecture  \\n\\u2705 Rich logging with beautiful formatting  \\n\\u2705 Easy plugin registration and management  \\n\\n---\\n\\n## \\ud83d\\udca1 Key Features\\n\\n- \\ud83d\\udd0d Powered by **Volatility 3**\\n- \\ud83e\\udde0 Supports Windows, Linux, and macOS plugins\\n- \\u2699\\ufe0f Asynchronous plugin execution\\n- \\ud83d\\udce4 JSON output format\\n- \\ud83d\\udcca Built-in error handling and validation\\n- \\ud83d\\udc68\\u200d\\ud83d\\udcbb FastMCP server interface\\n- \\ud83d\\udc33 Docker-ready environment\\n\\n---\\n\\n## \\ud83d\\udce6 Requirements\\n\\n```bash\\npython 3.11+\\npip install -r requirements.txt\\n```\\n\\n**requirements.txt:**\\n```\\nfastmcp\\nrich\\npython-dotenv\\n```\\n\\n---\\n\\n## \\ud83d\\udcc1 Project Structure\\n\\n```\\nVolatility-MCP-Server/\\n\\u251c\\u2500\\u2500 volatility_mcp_server.py    # Main server implementation\\n\\u251c\\u2500\\u2500 plugins/                    # Plugin modules\\n\\u2502   \\u251c\\u2500\\u2500 base_plugin.py         # Base plugin class\\n\\u2502   \\u251c\\u2500\\u2500 plugin_factory.py      # Plugin registration\\n\\u2502   \\u251c\\u2500\\u2500 windows/               # Windows plugins\\n\\u2502   \\u251c\\u2500\\u2500 linux/                 # Linux plugins\\n\\u2502   \\u251c\\u2500\\u2500 mac/                   # macOS plugins\\n\\u2502   \\u2514\\u2500\\u2500 common/                # Common plugins\\n\\u251c\\u2500\\u2500 requirements.txt           # Dependencies\\n\\u2514\\u2500\\u2500 README.md                 # This file\\n```\\n\\n---\\n\\n## \\ud83d\\udda5\\ufe0f Usage\\n\\n### \\ud83d\\udd27 Local Connection\\n#### Using `stdio`\\nCreate a `.cursor/mcp.json` file with:\\n\\n```json\\n{\\n  \\\"mcpServers\\\": {\\n    \\\"Volatility3\\\": {\\n      \\\"command\\\": \\\"fastmcp\\\",\\n      \\\"args\\\": [\\\"run\\\", \\\"path/to/volatility_mcp_server.py:mcp\\\", \\\"--transport\\\", \\\"stdio\\\"]\\n    }\\n  }\\n}\\n```\\n#### Using `sse`\\nRun the server using\\n```pwsh\\nfastmcp run volatility_mcp_server.py:mcp --transport sse\\n```\\nFor Claude desktop\\n```json\\n{\\n    \\\"mcpServers\\\": {\\n      \\\"volatility3\\\": {\\n        \\\"command\\\": \\\"npx\\\",\\n        \\\"args\\\": [\\\"mcp-remote\\\", \\\"http://localhost:8000/sse\\\"]\\n      }\\n    }\\n  }\\n```\\nFor Cursor\\n```json\\n{\\n  \\\"mcpServers\\\": {\\n    \\\"Volatility3\\\": {\\n      \\\"url\\\": \\\"http://localhost:8000/sse\\\"\\n    }\\n  }\\n}\\n```\\n\\n### \\ud83d\\udcca Available Plugins\\n\\n#### Windows Plugins\\n- Process: `PsList`, `PsTree`, `PsScan`\\n- Memory: `Malfind`, `MemMap`\\n- Network: `NetScan`\\n- Registry: `RegistryHiveList`, `RegistryPrintKey`\\n- System: `SvcScan`, `CmdLine`, `DllList`, `Handles`, `FileScan`\\n- Disk: `ADS`, `MFTScan`, `ResidentData`\\n\\n#### Linux Plugins\\n- Process: `PsList`, `PsTree`, `PsScan`, `PsAux`, `PsCallStack`\\n- System: `Bash`, `Boottime`, `Capabilities`\\n- Network: `IpAddr`, `IpLink`, `Netfilter`\\n- Memory: `Malfind`, `ModuleExtract`\\n- File System: `Files`, `InodePages`, `RecoverFs`\\n\\n#### macOS Plugins\\n- Process: `PsList`, `PsTree`, `Psaux`\\n- System: `Bash`, `Dmesg`, `Lsmod`\\n- Network: `Ifconfig`, `Netstat`\\n- Security: `Check_syscall`, `Check_sysctl`, `Check_trap_table`\\n\\n#### Common Plugins\\n- Framework: `Banners`, `ConfigWriter`, `FrameworkInfo`, `IsfInfo`, `LayerWriter`\\n- Scan: `RegExScan`, `YaraScan`, `Vmscan`\\n- Timeline: `Timeliner`\\n\\n---\\n\\n## \\ud83d\\udc33 Docker Usage (No idea what I wanted to do here but might be useful in the future)\\n\\n### \\u2699\\ufe0f 1. Build the Docker Image\\n\\nFrom the root directory:\\n\\n```bash\\ndocker build -t volatility-mcp .\\n```\\n\\n### \\u25b6\\ufe0f 2. Run the Server\\n\\n```bash\\ndocker run --rm -it \\\\\\n  -v $(pwd)/memdumps:/memdumps \\\\\\n  -v $(pwd)/output:/output \\\\\\n  volatility-mcp\\n```\\n\\n---\\n\\n## \\ud83d\\udd27 Developer/Contributor Guide\\n\\n### \\ud83e\\uddf1 Setup Virtual Environment\\n\\n```bash\\npython3 -m venv venv\\nsource venv/bin/activate\\npip install -r requirements.txt\\n```\\n\\n### \\ud83e\\uddea Run Locally\\n\\n```bash\\npython volatility_mcp_server.py\\n```\\n\\n---\\n\\n## \\u270d\\ufe0f Customization Tips\\n\\n- \\ud83d\\udcc0 Want to add a new plugin? Extend `BasePlugin` and register it in `plugin_factory.py`\\n- \\ud83e\\udde9 Want to add a new OS? Create a new plugin directory and implement the plugins\\n- \\ud83d\\udcda Want to add new features? The modular architecture makes it easy to extend\\n\\n---\\n\\n## \\ud83d\\ude4b FAQ\\n\\n> \\ud83d\\udfe0 **Does this support Volatility 2.x?**  \\n\\ud83d\\udd3b No. This server supports **Volatility 3 only** for modern plugin support.\\n\\n> \\ud83d\\udd35 **Can I add custom plugins?**  \\n\\u2705 Yes! Just extend the `BasePlugin` class and register it in the factory.\\n\\n> \\ud83d\\udd34 **Why use FastMCP?**  \\nIt provides a clean, efficient interface for running Volatility plugins with proper error handling and async support.\\n\\n---\\n\\n## \\ud83d\\udcdc License\\n\\nMIT \\u00a9\\ufe0f 2025\\n\\n---\\n\\n## \\ud83c\\udf10 More Tools?\\n\\nYou may also like:\\n- [Volatility Foundation](https://www.volatilityfoundation.org/)\\n- [FastMCP Documentation](https://github.com/Textualize/fastmcp)\\n- [Python-dotenv](https:/\\n[...truncated for length...]\", \"tools\": [{\"name\": \"stdio\", \"description\": \"Create a `.cursor/mcp.json` file with:\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"file_path\": {\"type\": \"string\", \"description\": \"File path or file to process\"}}, \"required\": [\"file_path\"]}, \"source\": \"readme\", \"access_level\": \"write\"}, {\"name\": \"sse\", \"description\": \"Run the server using\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"input\": {\"type\": \"string\", \"description\": \"Input parameter for sse\"}}, \"required\": [\"input\"]}, \"source\": \"readme\", \"access_level\": \"execute\"}, {\"name\": \"PsList\", \"description\": \", `PsTree`, `PsScan`\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"input\": {\"type\": \"string\", \"description\": \"Input parameter for PsList\"}}, \"required\": [\"input\"]}, \"source\": \"readme\", \"access_level\": \"read\"}, {\"name\": \"Malfind\", \"description\": \", `MemMap`\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"query\": {\"type\": \"string\", \"description\": \"Search query or term\"}}, \"required\": [\"query\"]}, \"source\": \"readme\", \"access_level\": \"read\"}, {\"name\": \"NetScan\", \"description\": \"- Registry: `RegistryHiveList`, `RegistryPrintKey`\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"input\": {\"type\": \"string\", \"description\": \"Input parameter for NetScan\"}}, \"required\": [\"input\"]}, \"source\": \"readme\", \"access_level\": \"read\"}, {\"name\": \"SvcScan\", \"description\": \", `CmdLine`, `DllList`, `Handles`, `FileScan`\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"file_path\": {\"type\": \"string\", \"description\": \"File path or file to process\"}}, \"required\": [\"file_path\"]}, \"source\": \"readme\", \"access_level\": \"read\"}, {\"name\": \"ADS\", \"description\": \", `MFTScan`, `ResidentData`\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"input\": {\"type\": \"string\", \"description\": \"Input parameter for ADS\"}}, \"required\": [\"input\"]}, \"source\": \"readme\", \"access_level\": \"read\"}, {\"name\": \"Bash\", \"description\": \", `Boottime`, `Capabilities`\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"input\": {\"type\": \"string\", \"description\": \"Input parameter for Bash\"}}, \"required\": [\"input\"]}, \"source\": \"readme\", \"access_level\": \"read\"}, {\"name\": \"IpAddr\", \"description\": \", `IpLink`, `Netfilter`\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"url\": {\"type\": \"string\", \"description\": \"URL or link to process\"}}, \"required\": [\"url\"]}, \"source\": \"readme\", \"access_level\": \"write\"}, {\"name\": \"Files\", \"description\": \", `InodePages`, `RecoverFs`\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"file_path\": {\"type\": \"string\", \"description\": \"File path or file to process\"}}, \"required\": [\"file_path\"]}, \"source\": \"readme\", \"access_level\": \"read\"}, {\"name\": \"Ifconfig\", \"description\": \", `Netstat`\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"input\": {\"type\": \"string\", \"description\": \"Input parameter for Ifconfig\"}}, \"required\": [\"input\"]}, \"source\": \"readme\", \"access_level\": \"read\"}, {\"name\": \"Check_syscall\", \"description\": \", `Check_sysctl`, `Check_trap_table`\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"input\": {\"type\": \"string\", \"description\": \"Input parameter for Check_syscall\"}}, \"required\": [\"input\"]}, \"source\": \"readme\", \"access_level\": \"read\"}, {\"name\": \"Banners\", \"description\": \", `ConfigWriter`, `FrameworkInfo`, `IsfInfo`, `LayerWriter`\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"input\": {\"type\": \"string\", \"description\": \"Input parameter for Banners\"}}, \"required\": [\"input\"]}, \"source\": \"readme\", \"access_level\": \"write\"}, {\"name\": \"RegExScan\", \"description\": \", `YaraScan`, `Vmscan`\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"input\": {\"type\": \"string\", \"description\": \"Input parameter for RegExScan\"}}, \"required\": [\"input\"]}, \"source\": \"readme\", \"access_level\": \"read\"}, {\"name\": \"Timeliner\", \"description\": \"---\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"input\": {\"type\": \"string\", \"description\": \"Input parameter for Timeliner\"}}, \"required\": [\"input\"]}, \"source\": \"readme\", \"access_level\": \"read\"}, {\"name\": \"BasePlugin\", \"description\": \"and register it in `plugin_factory.py`\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"input\": {\"type\": \"string\", \"description\": \"Input parameter for BasePlugin\"}}, \"required\": [\"input\"]}, \"source\": \"readme\", \"access_level\": \"read\"}], \"tools_count\": 16, \"homepage\": \"\", \"url\": \"https://github.com/OMGhozlan/Volatility-MCP-Server\", \"topics\": [\"agentic-ai\", \"fastmcp\", \"mcp-server\", \"mcp-tools\", \"memory-forensics\", \"python3\", \"volatility\", \"volatility-framework\", \"volatility3\"], \"data_sources\": [\"github\"]}", "target": "", "id": "omghozlan/volatility-mcp-server", "metadata": {"stage": "finance_filter"}}
{"input": "ONLY RESPOND WITH JSON. NO EXPLANATIONS. NO MARKDOWN. NO TEXT OUTSIDE JSON.\n\nAnalyze the MCP server for financial relevance. Look for keywords: payment, banking, credit, loan, finance, money, currency, crypto, investment, trading, portfolio, market, exchange, wallet, account, budget, expense, income, tax, invoice, billing, accounting, insurance, compliance, KYC, AML.\n\nJSON FORMAT (NOTHING ELSE):\n{\n  \"server_name\": \"string\",\n  \"server_id\": \"string\", \n  \"is_finance_llm\": \"yes|no|unclear\",\n  \"confidence\": \"high|medium|low\",\n  \"threat_models\": [],\n  \"analysis_notes\": \"Brief reason\"\n}\n\nIf financial keywords found: is_finance_llm=\"yes\". If not: is_finance_llm=\"no\". If unclear: is_finance_llm=\"unclear\".\n\nRESPOND ONLY WITH JSON.\n\nMCP Server Data:\n{\"server_name\": \"A2A-MCP-Server\", \"server_id\": \"gongrzhe/a2a-mcp-server\", \"description\": \"An MCP server that bridges the Model Context Protocol (MCP) with the Agent-to-Agent (A2A) protocol, enabling MCP-compatible AI assistants (like Claude) to seamlessly interact with A2A agents.\", \"readme\": \"# A2A MCP Server\\n\\n[![License](https://img.shields.io/badge/License-Apache_2.0-blue.svg)](https://opensource.org/licenses/Apache-2.0)\\n![](https://badge.mcpx.dev?type=server 'MCP Server')\\n[![smithery badge](https://smithery.ai/badge/@GongRzhe/A2A-MCP-Server)](https://smithery.ai/server/@GongRzhe/A2A-MCP-Server)\\n\\nA mcp server that bridges the Model Context Protocol (MCP) with the Agent-to-Agent (A2A) protocol, enabling MCP-compatible AI assistants (like Claude) to seamlessly interact with A2A agents.\\n\\n## Overview\\n\\nThis project serves as an integration layer between two cutting-edge AI agent protocols:\\n\\n- **Model Context Protocol (MCP)**: Developed by Anthropic, MCP allows AI assistants to connect to external tools and data sources. It standardizes how AI applications and large language models connect to external resources in a secure, composable way.\\n\\n- **Agent-to-Agent Protocol (A2A)**: Developed by Google, A2A enables communication and interoperability between different AI agents through a standardized JSON-RPC interface.\\n\\nBy bridging these protocols, this server allows MCP clients (like Claude) to discover, register, communicate with, and manage tasks on A2A agents through a unified interface.\\n\\n### Demo\\n\\n#### 1, Run The Currency Agent in A2A Sample\\n\\n![agent](public/agent.png)\\n\\n`also support cloud deployed Agent`\\n\\n![cloudAgent](https://github.com/user-attachments/assets/481cbf01-95a0-4b0a-9ac5-898aef66a944)\\n\\n\\n#### 2, Use Claude to Register the Currency Agent \\n\\n![register](public/register.png)\\n\\n#### 3, Use Claude to Send a task to the Currency Agent and get the result \\n\\n![task](public/task.png)\\n\\n## Features\\n\\n- **Agent Management**\\n  - Register A2A agents with the bridge server\\n  - List all registered agents\\n  - Unregister agents when no longer needed\\n\\n- **Communication**\\n  - Send messages to A2A agents and receive responses\\n  - Stream responses from A2A agents in real-time\\n\\n- **Task Management**\\n  - Track which A2A agent handles which task\\n  - Retrieve task results using task IDs\\n  - Cancel running tasks\\n\\n- **Transport Support**\\n  - Multiple transport types: stdio, streamable-http, SSE\\n  - Configure transport type using MCP_TRANSPORT environment variable\\n\\n## Installation\\n\\n### Installing via Smithery\\n\\nTo install A2A Bridge Server for Claude Desktop automatically via [Smithery](https://smithery.ai/server/@GongRzhe/A2A-MCP-Server):\\n\\n```bash\\nnpx -y @smithery/cli install @GongRzhe/A2A-MCP-Server --client claude\\n```\\n\\n### Option 1: Install from PyPI\\n\\n```bash\\npip install a2a-mcp-server\\n```\\n\\n### Option 2: Local Installation\\n\\n1. Clone the repository:\\n   ```bash\\n   git clone https://github.com/GongRzhe/A2A-MCP-Server.git\\n   cd A2A-MCP-Server\\n   ```\\n\\n2. Set up a virtual environment:\\n   ```bash\\n   python -m venv .venv\\n   source .venv/bin/activate  # On Windows: .venv\\\\Scripts\\\\activate\\n   ```\\n\\n3. Install dependencies:\\n   ```bash\\n   pip install -r requirements.txt\\n   ```\\n\\n## Configuration\\n\\n### Environment Variables\\n\\nConfigure how the MCP server runs using these environment variables:\\n\\n```bash\\n# Transport type: stdio, streamable-http, or sse\\nexport MCP_TRANSPORT=\\\"streamable-http\\\"\\n\\n# Host for the MCP server\\nexport MCP_HOST=\\\"0.0.0.0\\\"\\n\\n# Port for the MCP server (when using HTTP transports)\\nexport MCP_PORT=\\\"8000\\\"\\n\\n# Path for the MCP server endpoint (when using HTTP transports)\\nexport MCP_PATH=\\\"/mcp\\\"\\n\\n# Path for SSE endpoint (when using SSE transport)\\nexport MCP_SSE_PATH=\\\"/sse\\\"\\n\\n# Enable debug logging\\nexport MCP_DEBUG=\\\"true\\\"\\n```\\n\\n### Transport Types\\n\\nThe A2A MCP Server supports multiple transport types:\\n\\n1. **stdio** (default): Uses standard input/output for communication\\n   - Ideal for command-line usage and testing\\n   - No HTTP server is started\\n   - Required for Claude Desktop\\n\\n2. **streamable-http** (recommended for web clients): HTTP transport with streaming support\\n   - Recommended for production deployments\\n   - Starts an HTTP server to handle MCP requests\\n   - Enables streaming of large responses\\n\\n3. **sse**: Server-Sent Events transport\\n   - Provides real-time event streaming\\n   - Useful for real-time updates\\n\\nTo specify the transport type:\\n\\n```bash\\n# Using environment variable\\nexport MCP_TRANSPORT=\\\"streamable-http\\\"\\nuvx a2a-mcp-server\\n\\n# Or directly in the command\\nMCP_TRANSPORT=streamable-http uvx a2a-mcp-server\\n```\\n\\n## Running the Server\\n\\n### From Command Line\\n\\n```bash\\n# Using default settings (stdio transport)\\nuvx a2a-mcp-server\\n\\n# Using HTTP transport on specific host and port\\nMCP_TRANSPORT=streamable-http MCP_HOST=127.0.0.1 MCP_PORT=8080 uvx a2a-mcp-server\\n```\\n\\n## Configuring in Claude Desktop\\n\\nClaude Desktop allows you to configure MCP servers in the `claude_desktop_config.json` file. This file is typically located at:\\n\\n- **Windows**: `%APPDATA%\\\\Claude\\\\claude_desktop_config.json`\\n- **macOS**: `~/Library/Application Support/Claude/claude_desktop_config.json`\\n- **Linux**: `~/.config/Claude/claude_desktop_config.json`\\n\\n### Method 1: PyPI Installation (Recommended)\\n\\nAdd the following to the `mcpServers` section of your `\\n[...truncated for length...]\", \"tools\": [{\"name\": \"mcpServers\", \"description\": \"section of your `claude_desktop_config.json`:\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"input\": {\"type\": \"string\", \"description\": \"Input parameter for mcpServers\"}}, \"required\": [\"input\"]}, \"source\": \"readme\", \"access_level\": \"read\"}, {\"name\": \"task_id\", \"description\": \"2. Maps this ID to the agent's URL in the `task_agent_mapping` dictionary\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"url\": {\"type\": \"string\", \"description\": \"URL or link to process\"}}, \"required\": [\"url\"]}, \"source\": \"readme\", \"access_level\": \"read\"}, {\"name\": \"list_agents\", \"description\": \")\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"input\": {\"type\": \"string\", \"description\": \"Input parameter for list_agents\"}}, \"required\": [\"input\"]}, \"source\": \"readme\", \"access_level\": \"read\"}, {\"name\": \"MCP_TRANSPORT\", \"description\": \"is set to `\\\"stdio\\\"` in the `env` section\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"input\": {\"type\": \"string\", \"description\": \"Input parameter for MCP_TRANSPORT\"}}, \"required\": [\"input\"]}, \"source\": \"readme\", \"access_level\": \"write\"}, {\"name\": \"A2AServerTaskManager\", \"description\": \"class that extends `InMemoryTaskManager`. You can customize its behavior by modifying this class.\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"input\": {\"type\": \"string\", \"description\": \"Input parameter for A2AServerTaskManager\"}}, \"required\": [\"input\"]}, \"source\": \"readme\", \"access_level\": \"write\"}], \"tools_count\": 5, \"homepage\": \"\", \"url\": \"https://github.com/GongRzhe/A2A-MCP-Server\", \"topics\": [], \"data_sources\": [\"github\", \"official\"]}", "target": "", "id": "gongrzhe/a2a-mcp-server", "metadata": {"stage": "finance_filter"}}
{"input": "ONLY RESPOND WITH JSON. NO EXPLANATIONS. NO MARKDOWN. NO TEXT OUTSIDE JSON.\n\nAnalyze the MCP server for financial relevance. Look for keywords: payment, banking, credit, loan, finance, money, currency, crypto, investment, trading, portfolio, market, exchange, wallet, account, budget, expense, income, tax, invoice, billing, accounting, insurance, compliance, KYC, AML.\n\nJSON FORMAT (NOTHING ELSE):\n{\n  \"server_name\": \"string\",\n  \"server_id\": \"string\", \n  \"is_finance_llm\": \"yes|no|unclear\",\n  \"confidence\": \"high|medium|low\",\n  \"threat_models\": [],\n  \"analysis_notes\": \"Brief reason\"\n}\n\nIf financial keywords found: is_finance_llm=\"yes\". If not: is_finance_llm=\"no\". If unclear: is_finance_llm=\"unclear\".\n\nRESPOND ONLY WITH JSON.\n\nMCP Server Data:\n{\"server_name\": \"task-manager-mcp\", \"server_id\": \"mryanmyn/task-manager-mcp\", \"description\": \"A simple UI and MCP server for task + project plan management \", \"readme\": \"# Terminal Task Tracker\\n\\nA terminal-based task tracking application with a three-pane layout for managing tasks and project plans.\\n\\n # Image\\n\\n![Terminal Task Tracker](https://github.com/MrYanMYN/task-manager-mcp/blob/master/img.png?raw=true)\\n\\n## Features\\n\\n- Three-pane terminal UI:\\n  - Task list (top left)\\n  - Task details (top right)\\n  - Project plan (bottom, full width)\\n- Task management:\\n  - Create, view, edit, and delete tasks\\n  - Set priorities and status\\n  - Add detailed descriptions\\n- Project plan management:\\n  - Define high-level project steps\\n  - Track step completion\\n  - Reorder steps\\n- Complete API for programmatic access\\n- Command-line interface for scripting\\n- Data persistence\\n\\n## Installation\\n\\n```bash\\n# Clone the repository\\ngit clone https://github.com/yourusername/terminal-task-tracker.git\\ncd terminal-task-tracker\\n\\n# Install dependencies\\npip install -e .\\n```\\n\\n## Usage\\n\\n### Terminal UI\\n\\nTo start the terminal UI:\\n\\n```bash\\npython -m main.py\\n```\\n\\nKey bindings:\\n- `Tab`: Cycle between windows\\n- `Up/Down`: Navigate lists\\n- `Enter`: Select task (in task list)\\n- `n`: New item (in task list or plan)\\n- `e`: Edit item\\n- `d`: Delete item\\n- `Space`: Toggle completion (in plan)\\n- `Esc`: Exit\\n\\n### Command-line Interface\\n\\nThe CLI provides access to all functionality:\\n\\n```bash\\n# List all tasks\\npython -m app.api.cli task list\\n\\n# Add a new task\\npython -m app.api.cli task add \\\"Implement feature X\\\" --description \\\"Details about feature X\\\" --priority 2\\n\\n# Mark a plan step as completed\\npython -m app.api.cli plan toggle STEP_ID\\n\\n# Export data to JSON\\npython -m app.api.cli export data.json\\n```\\n\\n### API Usage\\n\\n```python\\nfrom app.core.task_manager import TaskManager\\nfrom app.core.plan_manager import PlanManager\\nfrom app.api.api import TaskTrackerAPI\\n\\n# Initialize managers\\ntask_manager = TaskManager(\\\"tasks.json\\\")\\nplan_manager = PlanManager(\\\"plan.json\\\")\\n\\n# Create API\\napi = TaskTrackerAPI(task_manager, plan_manager)\\n\\n# Add a task\\ntask = api.add_task(\\\"Implement feature X\\\", \\\"Details about feature X\\\", priority=2)\\n\\n# Add a plan step\\nstep = api.add_plan_step(\\\"Design architecture for shared operations module\\\")\\n\\n# Mark step as completed\\napi.toggle_plan_step(step[\\\"id\\\"])\\n\\n# Save data\\napi.save_all()\\n```\\n\\n## Project Structure\\n\\n```\\nterminal-task-tracker/\\n\\u251c\\u2500\\u2500 app/\\n\\u2502   \\u251c\\u2500\\u2500 __init__.py\\n\\u2502   \\u251c\\u2500\\u2500 core/               # Business logic\\n\\u2502   \\u2502   \\u251c\\u2500\\u2500 __init__.py\\n\\u2502   \\u2502   \\u251c\\u2500\\u2500 task_manager.py\\n\\u2502   \\u2502   \\u2514\\u2500\\u2500 plan_manager.py\\n\\u2502   \\u251c\\u2500\\u2500 ui/                 # Terminal UI\\n\\u2502   \\u2502   \\u251c\\u2500\\u2500 __init__.py\\n\\u2502   \\u2502   \\u251c\\u2500\\u2500 terminal_ui.py\\n\\u2502   \\u2502   \\u251c\\u2500\\u2500 ui_components.py\\n\\u2502   \\u2502   \\u2514\\u2500\\u2500 input_handler.py\\n\\u2502   \\u2514\\u2500\\u2500 api/                # API and CLI\\n\\u2502       \\u251c\\u2500\\u2500 __init__.py\\n\\u2502       \\u251c\\u2500\\u2500 api.py\\n\\u2502       \\u2514\\u2500\\u2500 cli.py\\n\\u251c\\u2500\\u2500 main.py                 # Main application entry point\\n\\u2514\\u2500\\u2500 README.md\\n```\\n\\n## Data Storage\\n\\nBy default, data is stored in the `~/.tasktracker` directory:\\n- `tasks.json`: Tasks data\\n- `plan.json`: Project plan data\\n- `notes.json`: Notes data\\n\\n## License\\n\\nMIT\", \"tools\": [{\"name\": \"Tab\", \"description\": \"Cycle between windows\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"input\": {\"type\": \"string\", \"description\": \"Input parameter for Tab\"}}, \"required\": [\"input\"]}, \"source\": \"readme\", \"access_level\": \"read\"}, {\"name\": \"Enter\", \"description\": \"Select task (in task list)\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"input\": {\"type\": \"string\", \"description\": \"Input parameter for Enter\"}}, \"required\": [\"input\"]}, \"source\": \"readme\", \"access_level\": \"read\"}, {\"name\": \"Space\", \"description\": \"Toggle completion (in plan)\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"input\": {\"type\": \"string\", \"description\": \"Input parameter for Space\"}}, \"required\": [\"input\"]}, \"source\": \"readme\", \"access_level\": \"read\"}, {\"name\": \"Esc\", \"description\": \"Exit\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"input\": {\"type\": \"string\", \"description\": \"Input parameter for Esc\"}}, \"required\": [\"input\"]}, \"source\": \"readme\", \"access_level\": \"read\"}], \"tools_count\": 4, \"homepage\": \"\", \"url\": \"https://github.com/MrYanMYN/task-manager-mcp\", \"topics\": [\"agent\", \"cli\", \"llm\", \"mcp\", \"mcp-server\", \"mcpe-server\"], \"data_sources\": [\"github\"]}", "target": "", "id": "mryanmyn/task-manager-mcp", "metadata": {"stage": "finance_filter"}}
{"input": "ONLY RESPOND WITH JSON. NO EXPLANATIONS. NO MARKDOWN. NO TEXT OUTSIDE JSON.\n\nAnalyze the MCP server for financial relevance. Look for keywords: payment, banking, credit, loan, finance, money, currency, crypto, investment, trading, portfolio, market, exchange, wallet, account, budget, expense, income, tax, invoice, billing, accounting, insurance, compliance, KYC, AML.\n\nJSON FORMAT (NOTHING ELSE):\n{\n  \"server_name\": \"string\",\n  \"server_id\": \"string\", \n  \"is_finance_llm\": \"yes|no|unclear\",\n  \"confidence\": \"high|medium|low\",\n  \"threat_models\": [],\n  \"analysis_notes\": \"Brief reason\"\n}\n\nIf financial keywords found: is_finance_llm=\"yes\". If not: is_finance_llm=\"no\". If unclear: is_finance_llm=\"unclear\".\n\nRESPOND ONLY WITH JSON.\n\nMCP Server Data:\n{\"server_name\": \"VibeShift\", \"server_id\": \"groundng/vibeshift\", \"description\": \"[MCP Server] The Security Agent for AI assisted coding\", \"readme\": \"# VibeShift: The Security Engineer for Vibe Coders\\n\\n**VibeShift** is an intelligent security agent designed to integrate seamlessly with AI coding assistants (like Cursor, GitHub Copilot, Claude Code, etc.). It acts as your automated security engineer, analyzing code generated by AI, identifying vulnerabilities, and facilitating AI-driven remediation *before* insecure code makes it to your codebase. It leverages the **MCP (Model Context Protocol)** for smooth interaction within your existing AI coding environment.\\n\\n<a href=\\\"https://www.producthunt.com/posts/vibeshift-mcp?embed=true&utm_source=badge-featured&utm_medium=badge&utm_source=badge-vibeshift&#0045;mcp\\\" target=\\\"_blank\\\"><img src=\\\"https://api.producthunt.com/widgets/embed-image/v1/featured.svg?post_id=966186&theme=light&t=1747654611925\\\" alt=\\\"VibeShift&#0032;MCP - Get&#0032;secure&#0044;&#0032;working&#0032;code&#0032;in&#0032;1&#0032;shot | Product Hunt\\\" style=\\\"width: 115px; height: 25px;\\\" width=\\\"250\\\" height=\\\"54\\\" /></a>\\n[![Twitter Follow](https://img.shields.io/twitter/follow/Omiiee_Chan?style=social)](https://x.com/Omiiee_Chan)\\n[![Twitter Follow](https://img.shields.io/twitter/follow/_gauravkabra_?style=social)](https://x.com/_gauravkabra_)\\n![](https://img.shields.io/github/stars/groundng/vibeshift)\\n\\n\\n**The Problem:** AI coding assistants accelerate development dramatically, but they can also generate code with subtle or overt security vulnerabilities. Manually reviewing all AI-generated code for security flaws is slow, error-prone, and doesn't scale with the speed of AI development. This \\\"vibe-driven development\\\" can leave applications exposed.\\n\\n**The Solution: GroundNG's VibeShift** bridges this critical security gap by enabling your AI coding assistant to:\\n\\n1.  **Automatically Analyze AI-Generated Code:** As code is generated or modified by an AI assistant, VibeShift can be triggered to perform security analysis using a suite of tools (SAST, DAST components) and AI-driven checks.\\n2.  **Identify Security Vulnerabilities:** Pinpoints common and complex vulnerabilities (e.g., XSS, SQLi, insecure configurations, logic flaws) within the AI-generated snippets or larger code blocks.\\n3.  **Facilitate AI-Driven Remediation:** Provides detailed feedback and vulnerability information directly to the AI coding assistant, enabling it to suggest or even automatically apply fixes.\\n4.  **Create a Security Feedback Loop:** Ensures that developers and their AI assistants are immediately aware of potential security risks, allowing for rapid correction and learning.\\n\\nThis creates a \\\"shift-left\\\" security paradigm for AI-assisted coding, embedding security directly into the development workflow and helping to ship more secure code, faster.\\n\\n# Demo (Click to play these videos)\\n[![Demo](https://img.youtube.com/vi/bN_RgQGa8B0/maxresdefault.jpg)](https://www.youtube.com/watch?v=bN_RgQGa8B0)\\n[![Click to play](https://img.youtube.com/vi/wCbCUCqjnXQ/maxresdefault.jpg)](https://youtu.be/wCbCUCqjnXQ)\\n\\n\\n## Features\\n\\n*   **MCP Integration:** Seamlessly integrates with Cursor/Windsurf/Github Copilot/Roo Code\\n*   **Automated Security Scanning:** Triggers on AI code generation/modification to perform:\\n    *   **Static Code Analysis (SAST):** Integrates tools like Semgrep to find vulnerabilities in source code.\\n    *   **Dynamic Analysis (DAST Primitives):** Can invoke tools like Nuclei or ZAP for checks against running components (where applicable).\\n*   **AI-Assisted Test Recording:** Generate Playwright-based test scripts from natural language descriptions (in automated mode).\\n*   **Deterministic Test Execution:** Run recorded JSON test files reliably using Playwright.\\n*   **AI-Powered Test Discovery:** Crawl websites and leverage any LLM (in openai compliant format) to suggest test steps for discovered pages.\\n*   **Regression Testing:** Easily run existing test suites to catch regressions.\\n*   **Automated Feedback Loop:** Execution results (including failures, screenshots, console logs) are returned, providing direct feedback to the AI assistant.\\n*   **Self Healing:** Existing tests self heal in case of code changes. No need to manually update.\\n*   **UI tests:** UI tests which aren't supported by playwright directly are also supported. For example, `Check if the text is overflowing in the div`\\n*   **Visual Regression Testing**: Using traditional pixelmatch and vision LLM approach.\\n\\n## How it Works\\n\\n```\\n+-------------+       +-----------------+       +---------------------+       +-----------------+       +-------------+\\n|    User     | ----> | AI Coding Agent | ----> |     MCP Server      | ----> | Scan, test, exec| ----> | Browser     |\\n| (Developer) |       | (e.g., Copilot) |       | (mcp_server.py)     |       | (SAST, Record)  |       | (Playwright)|\\n+-------------+       +-----------------+       +---------------------+       +-----------------+       +-------------+\\n      ^                                                  |                            |                     |\\n[...truncated for length...]\", \"tools\": [{\"name\": \"get_security_scan\", \"description\": \", `record_test_flow`, `run_regression_test`, `discover_test_flows`, `list_recorded_tests`).\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"input\": {\"type\": \"string\", \"description\": \"Input parameter for get_security_scan\"}}, \"required\": [\"input\"]}, \"source\": \"readme\", \"access_level\": \"execute\"}, {\"name\": \"WebAgent\", \"description\": \"(in automated mode) interacts with the LLM to plan steps, controls the browser via `BrowserController` (Playwright), processes HTML/Vision, and saves the resulting test steps to a JSON file in the `output/` directory.\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"file_path\": {\"type\": \"string\", \"description\": \"File path or file to process\"}}, \"required\": [\"file_path\"]}, \"source\": \"readme\", \"access_level\": \"write\"}, {\"name\": \"TestExecutor\", \"description\": \"loads the specified JSON test file, uses `BrowserController` to interact with the browser according to the recorded steps, and captures results, screenshots, and console logs.\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"file_path\": {\"type\": \"string\", \"description\": \"File path or file to process\"}}, \"required\": [\"file_path\"]}, \"source\": \"readme\", \"access_level\": \"read\"}, {\"name\": \"CrawlerAgent\", \"description\": \"uses `BrowserController` and `LLMClient` to crawl pages and suggest test steps.\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"input\": {\"type\": \"string\", \"description\": \"Input parameter for CrawlerAgent\"}}, \"required\": [\"input\"]}, \"source\": \"readme\", \"access_level\": \"read\"}, {\"name\": \"YOUR_LLM_API_KEY\", \"description\": \"with your actual key.\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"input\": {\"type\": \"string\", \"description\": \"Input parameter for YOUR_LLM_API_KEY\"}}, \"required\": [\"input\"]}, \"source\": \"readme\", \"access_level\": \"read\"}], \"tools_count\": 5, \"homepage\": \"https://groundng.site\", \"url\": \"https://github.com/GroundNG/VibeShift\", \"topics\": [\"debugging\", \"debugging-tool\", \"mcp\", \"mcp-server\", \"playwright\", \"qa\", \"testing\", \"vibe-coding\", \"vibe-testing\", \"web\"], \"data_sources\": [\"github\"]}", "target": "", "id": "groundng/vibeshift", "metadata": {"stage": "finance_filter"}}
{"input": "ONLY RESPOND WITH JSON. NO EXPLANATIONS. NO MARKDOWN. NO TEXT OUTSIDE JSON.\n\nAnalyze the MCP server for financial relevance. Look for keywords: payment, banking, credit, loan, finance, money, currency, crypto, investment, trading, portfolio, market, exchange, wallet, account, budget, expense, income, tax, invoice, billing, accounting, insurance, compliance, KYC, AML.\n\nJSON FORMAT (NOTHING ELSE):\n{\n  \"server_name\": \"string\",\n  \"server_id\": \"string\", \n  \"is_finance_llm\": \"yes|no|unclear\",\n  \"confidence\": \"high|medium|low\",\n  \"threat_models\": [],\n  \"analysis_notes\": \"Brief reason\"\n}\n\nIf financial keywords found: is_finance_llm=\"yes\". If not: is_finance_llm=\"no\". If unclear: is_finance_llm=\"unclear\".\n\nRESPOND ONLY WITH JSON.\n\nMCP Server Data:\n{\"server_name\": \"celo-mcp\", \"server_id\": \"celo-org/celo-mcp\", \"description\": \"MCP server that provides AI agents with access to Celo blockchain data and functionality\", \"readme\": \"# Celo MCP Server\\n\\nA Model Context Protocol (MCP) server for interacting with the Celo blockchain. This server provides comprehensive access to Celo blockchain data, token operations, NFT management, smart contract interactions, transaction handling, and governance operations.\\n\\n## Installation\\n\\n1. Clone the repository:\\n\\n```bash\\ngit clone https://github.com/celo-org/celo-mcp\\ncd celo-mcp\\n```\\n\\n2. Install dependencies:\\n\\n```bash\\npip install -e .\\n```\\n\\n3. Set up environment variables (optional):\\n\\n```bash\\nexport CELO_RPC_URL=\\\"https://forno.celo.org\\\"  # Default: Celo mainnet\\nexport CELO_TESTNET_RPC_URL=\\\"https://alfajores-forno.celo-testnet.org\\\"  # Alfajores testnet\\n```\\n\\n## MCP Integration\\n\\n### Cursor IDE Integration\\n\\nTo use this MCP server with Cursor IDE, add the following configuration to your MCP settings file (`~/.cursor/mcp.json`):\\n\\n```json\\n{\\n  \\\"mcpServers\\\": {\\n    \\\"celo-mcp\\\": {\\n      \\\"command\\\": \\\"uvx\\\",\\n      \\\"args\\\": [\\\"--refresh\\\", \\\"celo-mcp\\\"]\\n    }\\n  }\\n}\\n```\\n\\nThe `--refresh` flag ensures that the latest code is always loaded when the MCP server starts.\\n\\n### Claude Desktop Integration\\n\\nFor Claude Desktop, add this configuration to your MCP settings file (`~/Library/Application Support/Claude/claude_desktop_config.json` on macOS):\\n\\n```json\\n{\\n  \\\"mcpServers\\\": {\\n    \\\"celo-mcp\\\": {\\n      \\\"command\\\": \\\"uvx\\\",\\n      \\\"args\\\": [\\\"--refresh\\\", \\\"celo-mcp\\\"]\\n    }\\n  }\\n}\\n```\\n\\n## Usage\\n\\n### Running the Server\\n\\n```bash\\n# Run the MCP server\\npython -m celo_mcp.server\\n\\n# Or use the CLI entry point\\ncelo-mcp-server\\n```\\n\\n### Available Tools\\n\\n#### Blockchain Data Operations\\n\\n1. **get_network_status**\\n\\n   - Get current network status and connection information\\n   - No parameters required\\n\\n2. **get_block**\\n\\n   - Fetch block information by number, hash, or \\\"latest\\\"\\n   - Parameters: `block_identifier`, `include_transactions` (optional)\\n\\n3. **get_transaction**\\n\\n   - Get transaction details by hash\\n   - Parameters: `tx_hash`\\n\\n4. **get_account**\\n\\n   - Get account information including balance and nonce\\n   - Parameters: `address`\\n\\n5. **get_latest_blocks**\\n   - Get information about recent blocks\\n   - Parameters: `count` (optional, default: 10, max: 100)\\n\\n#### Token Operations\\n\\n6. **get_token_info**\\n\\n   - Get detailed token information (name, symbol, decimals, supply)\\n   - Parameters: `token_address`\\n\\n7. **get_token_balance**\\n\\n   - Get token balance for a specific address\\n   - Parameters: `token_address`, `address`\\n\\n8. **get_celo_balances**\\n   - Get CELO and stable token balances for an address\\n   - Parameters: `address`\\n\\n#### NFT Operations\\n\\n9. **get_nft_info**\\n\\n   - Get NFT information including metadata and collection details\\n   - Parameters: `contract_address`, `token_id`\\n\\n10. **get_nft_balance**\\n    - Get NFT balance for an address (supports ERC721 and ERC1155)\\n    - Parameters: `contract_address`, `address`, `token_id` (optional for ERC1155)\\n\\n#### Smart Contract Operations\\n\\n11. **call_contract_function**\\n\\n    - Call a read-only contract function\\n    - Parameters: `contract_address`, `function_name`, `abi`, `function_args` (optional), `from_address` (optional)\\n\\n12. **estimate_contract_gas**\\n    - Estimate gas for a contract function call\\n    - Parameters: `contract_address`, `function_name`, `abi`, `from_address`, `function_args` (optional), `value` (optional)\\n\\n#### Transaction Operations\\n\\n13. **estimate_transaction**\\n\\n    - Estimate gas and cost for a transaction\\n    - Parameters: `to`, `from_address`, `value` (optional), `data` (optional)\\n\\n14. **get_gas_fee_data**\\n    - Get current gas fee data including EIP-1559 fees\\n    - No parameters required\\n\\n#### Governance Operations\\n\\n15. **get_governance_proposals**\\n\\n    - Get Celo governance proposals with pagination support\\n    - Parameters: `include_inactive` (optional), `include_metadata` (optional), `page` (optional), `page_size` (optional), `offset` (optional), `limit` (optional)\\n\\n16. **get_proposal_details**\\n    - Get detailed information about a specific governance proposal including content and voting history\\n    - Parameters: `proposal_id`\\n\\n#### Staking Operations\\n\\n17. **get_staking_balances**\\n\\n    - Get staking balances for an address, including active and pending stakes broken down by validator group\\n    - Parameters: `address`\\n\\n18. **get_activatable_stakes**\\n\\n    - Get information about pending stakes that can be activated for earning rewards\\n    - Parameters: `address`\\n\\n19. **get_validator_groups**\\n\\n    - Get information about all validator groups, including their members, votes, capacity, and performance metrics\\n    - No parameters required\\n\\n20. **get_validator_group_details**\\n\\n    - Get detailed information about a specific validator group including its members and performance data\\n    - Parameters: `group_address`\\n\\n21. **get_total_staking_info**\\n    - Get network-wide staking information including total votes and participation metrics\\n    - No parameters required\\n\\n## Key Features\\n\\n### Token Support\\n\\n- **ERC20 Standard**: Full support for ERC20 tokens\\n- **Celo Stable Tokens**: Built-in su\\n[...truncated for length...]\", \"tools\": [{\"name\": \"block_identifier\", \"description\": \", `include_transactions` (optional)\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"input\": {\"type\": \"string\", \"description\": \"Input parameter for block_identifier\"}}, \"required\": [\"input\"]}, \"source\": \"readme\", \"access_level\": \"read\"}, {\"name\": \"tx_hash\", \"description\": \"4. **get_account**\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"input\": {\"type\": \"string\", \"description\": \"Input parameter for tx_hash\"}}, \"required\": [\"input\"]}, \"source\": \"readme\", \"access_level\": \"read\"}, {\"name\": \"address\", \"description\": \"5. **get_latest_blocks**\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"input\": {\"type\": \"string\", \"description\": \"Input parameter for address\"}}, \"required\": [\"input\"]}, \"source\": \"readme\", \"access_level\": \"write\"}, {\"name\": \"count\", \"description\": \"(optional, default: 10, max: 100)\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"input\": {\"type\": \"string\", \"description\": \"Input parameter for count\"}}, \"required\": [\"input\"]}, \"source\": \"readme\", \"access_level\": \"read\"}, {\"name\": \"token_address\", \"description\": \"7. **get_token_balance**\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"input\": {\"type\": \"string\", \"description\": \"Input parameter for token_address\"}}, \"required\": [\"input\"]}, \"source\": \"readme\", \"access_level\": \"write\"}, {\"name\": \"contract_address\", \"description\": \", `token_id`\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"input\": {\"type\": \"string\", \"description\": \"Input parameter for contract_address\"}}, \"required\": [\"input\"]}, \"source\": \"readme\", \"access_level\": \"write\"}, {\"name\": \"to\", \"description\": \", `from_address`, `value` (optional), `data` (optional)\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"amount\": {\"type\": \"number\", \"description\": \"Numeric amount or value\"}}, \"required\": [\"amount\"]}, \"source\": \"readme\", \"access_level\": \"write\"}, {\"name\": \"include_inactive\", \"description\": \"(optional), `include_metadata` (optional), `page` (optional), `page_size` (optional), `offset` (optional), `limit` (optional)\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"input\": {\"type\": \"string\", \"description\": \"Input parameter for include_inactive\"}}, \"required\": [\"input\"]}, \"source\": \"readme\", \"access_level\": \"write\"}, {\"name\": \"proposal_id\", \"description\": \"#### Staking Operations\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"input\": {\"type\": \"string\", \"description\": \"Input parameter for proposal_id\"}}, \"required\": [\"input\"]}, \"source\": \"readme\", \"access_level\": \"read\"}, {\"name\": \"group_address\", \"description\": \"21. **get_total_staking_info**\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"input\": {\"type\": \"string\", \"description\": \"Input parameter for group_address\"}}, \"required\": [\"input\"]}, \"source\": \"readme\", \"access_level\": \"write\"}], \"tools_count\": 10, \"homepage\": \"\", \"url\": \"https://github.com/celo-org/celo-mcp\", \"topics\": [], \"data_sources\": [\"github\"]}", "target": "", "id": "celo-org/celo-mcp", "metadata": {"stage": "finance_filter"}}
{"input": "ONLY RESPOND WITH JSON. NO EXPLANATIONS. NO MARKDOWN. NO TEXT OUTSIDE JSON.\n\nAnalyze the MCP server for financial relevance. Look for keywords: payment, banking, credit, loan, finance, money, currency, crypto, investment, trading, portfolio, market, exchange, wallet, account, budget, expense, income, tax, invoice, billing, accounting, insurance, compliance, KYC, AML.\n\nJSON FORMAT (NOTHING ELSE):\n{\n  \"server_name\": \"string\",\n  \"server_id\": \"string\", \n  \"is_finance_llm\": \"yes|no|unclear\",\n  \"confidence\": \"high|medium|low\",\n  \"threat_models\": [],\n  \"analysis_notes\": \"Brief reason\"\n}\n\nIf financial keywords found: is_finance_llm=\"yes\". If not: is_finance_llm=\"no\". If unclear: is_finance_llm=\"unclear\".\n\nRESPOND ONLY WITH JSON.\n\nMCP Server Data:\n{\"server_name\": \"VideoDB Director MCP Server\", \"server_id\": \"@samihalawa/video-agent-mcp\", \"description\": \"Provide seamless integration of VideoDB context and capabilities to AI agents and LLM-powered applications. Enable automated context generation, maintenance, and discoverability for enhanced AI-driven workflows. Simplify access to VideoDB features through a standardized MCP interface.\", \"readme\": \"\", \"tools\": [{\"name\": \"doc_assistant\", \"description\": \"Context for creating video applications using VideoDB\", \"inputSchema\": {\"type\": \"object\", \"title\": \"doc_assistantArguments\", \"properties\": {}}, \"source\": \"smithery\", \"access_level\": \"read\"}, {\"name\": \"code_assistant\", \"description\": \"Will give you data related to VideoDB SDK which allows developers to use videodb in python. IMPORTANT: Whenever user wants to write code related to videos, youtube videos or VideoDB specifically, always call this tool.\", \"inputSchema\": {\"type\": \"object\", \"title\": \"code_assistantArguments\", \"properties\": {}}, \"source\": \"smithery\", \"access_level\": \"write\"}, {\"name\": \"play_video\", \"description\": \"Play the video of the given stream link\", \"inputSchema\": {\"type\": \"object\", \"title\": \"play_videoArguments\", \"required\": [\"stream_link\"], \"properties\": {\"stream_link\": {\"type\": \"string\", \"title\": \"Stream Link\"}}}, \"source\": \"smithery\", \"access_level\": \"read\"}, {\"name\": \"call_director\", \"description\": \"The Director tool orchestrates specialized agents within the VideoDB server, efficiently handling multimedia and video-related queries. Clients should send queries that Director can interpret clearly, specifying tasks in natural language. Director will then delegate these queries to appropriate agents for optimized results, utilizing defaults and contextual information if explicit parameters are not provided.\\n\\nDirector handles queries such as:\\n\\n- Uploading & Downloading:\\n  - Upload media from URLs or local paths (supported media: video, audio, image)\\n  - Download the VideoDB generated video streams.\\n\\n- Indexing & Search:\\n  - Index spoken words or scenes in videos (spoken_words, scene indexing; scene indexing supports shot or time-based type)\\n  - Search VideoDB collections semantically or by keyword (semantic, keyword search; indexing types: spoken_word, scene)\\n\\n- Summarization & Subtitles:\\n  - Summarize video content based on custom prompts\\n  - Add subtitles in various languages\\n\\n- Dubbing:\\n  - Dub videos into target languages\\n\\n- Creating Videos:\\n  - Generate videos using specific models or engines (Fal, StabilityAI; job types: text_to_video, image_to_video)\\n  - Compare multiple video generation models (video_generation_comparison)\\n\\n- Audio Generation & Editing:\\n  - Generate speech, sound effects, or background music (engines: ElevenLabs for speech/sound effects, Beatoven for music)\\n  - Clone voices from audio sources or overlay cloned voices onto videos\\n  - Censor the video on given prompt\\n\\n- Image and Frame Generation:\\n  - Generate static image frames from videos at specified timestamps\\n  - Create or enhance images using GenAI models (job types: text_to_image, image_to_image using Fal, Replicate)\\n\\n- Video Editing & Clip Generation:\\n  - Edit or combine multiple videos and audio files\\n  - Generate targeted video clips from user prompts\\n\\n- Streaming & Web Search:\\n  - Stream videos by video ID or URL\\n  - Search for relevant online videos (engine: Serp)\\n\\n- Transcription:\\n  - Generate transcripts for videos\\n\\n- Pricing & Usage Information:\\n  - Provide detailed cost information and usage estimates\\n\\nClients should provide queries clearly aligned with Director's capabilities, allowing Director to use contextual defaults when explicit parameters like IDs or collection details are not specified.\\n\\nIMPORTANT: if you have a previous response of this method with an appropriate session_id, please provide that session_id in the next request to continue the conversation.\\nIMPORTANT: It is MANDATORY to send the `session_id` param if any earlier response from this method exists with a `session_id` in its output\", \"inputSchema\": {\"type\": \"object\", \"title\": \"call_directorArguments\", \"required\": [\"text_message\"], \"properties\": {\"agents\": {\"type\": \"array\", \"items\": {\"type\": \"string\"}, \"title\": \"Agents\", \"default\": []}, \"session_id\": {\"anyOf\": [{\"type\": \"string\"}, {\"type\": \"null\"}], \"title\": \"Session Id\", \"default\": null}, \"text_message\": {\"type\": \"string\", \"title\": \"Text Message\"}}}, \"source\": \"smithery\", \"access_level\": \"execute\"}, {\"name\": \"summarize_video\", \"description\": \"Generate a summary of a video using VideoDB\", \"inputSchema\": {\"type\": \"object\", \"title\": \"summarize_videoArguments\", \"required\": [\"collection_id\", \"video_id\"], \"properties\": {\"prompt\": {\"anyOf\": [{\"type\": \"string\"}, {\"type\": \"null\"}], \"title\": \"Prompt\", \"default\": null}, \"video_id\": {\"type\": \"string\", \"title\": \"Video Id\"}, \"collection_id\": {\"type\": \"string\", \"title\": \"Collection Id\"}}}, \"source\": \"smithery\", \"access_level\": \"write\"}, {\"name\": \"upload\", \"description\": \"Upload media content (video, audio, or image) to VideoDB\", \"inputSchema\": {\"type\": \"object\", \"title\": \"uploadArguments\", \"required\": [\"source\"], \"properties\": {\"name\": {\"anyOf\": [{\"type\": \"string\"}, {\"type\": \"null\"}], \"title\": \"Name\", \"default\": null}, \"source\": {\"type\": \"string\", \"title\": \"Source\"}, \"media_type\": {\"type\": \"string\", \"title\": \"Media Type\", \"default\": \"video\"}, \"source_type\": {\"type\": \"string\", \"title\": \"Source Type\", \"default\": \"url\"}}}, \"source\": \"smithery\", \"access_level\": \"read\"}, {\"name\": \"index\", \"description\": \"Index a video for search purposes (spoken words or scenes)\", \"inputSchema\": {\"type\": \"object\", \"title\": \"indexArguments\", \"required\": [\"video_id\"], \"properties\": {\"video_id\": {\"type\": \"string\", \"title\": \"Video Id\"}, \"index_type\": {\"type\": \"string\", \"title\": \"Index Type\", \"default\": \"spoken_words\"}, \"collection_id\": {\"anyOf\": [{\"type\": \"string\"}, {\"type\": \"null\"}], \"title\": \"Collection Id\", \"default\": null}}}, \"source\": \"smithery\", \"access_level\": \"read\"}, {\"name\": \"search\", \"description\": \"Search for content within videos using semantic or keyword search\", \"inputSchema\": {\"type\": \"object\", \"title\": \"searchArguments\", \"required\": [\"query\"], \"properties\": {\"query\": {\"type\": \"string\", \"title\": \"Query\"}, \"index_type\": {\"type\": \"string\", \"title\": \"Index Type\", \"default\": \"spoken_word\"}, \"search_type\": {\"type\": \"string\", \"title\": \"Search Type\", \"default\": \"semantic\"}, \"collection_id\": {\"anyOf\": [{\"type\": \"string\"}, {\"type\": \"null\"}], \"title\": \"Collection Id\", \"default\": null}}}, \"source\": \"smithery\", \"access_level\": \"read\"}, {\"name\": \"prompt_clip\", \"description\": \"Create clips from a video based on prompts\", \"inputSchema\": {\"type\": \"object\", \"title\": \"prompt_clipArguments\", \"required\": [\"prompt\", \"video_id\", \"collection_id\"], \"properties\": {\"prompt\": {\"type\": \"string\", \"title\": \"Prompt\"}, \"video_id\": {\"type\": \"string\", \"title\": \"Video Id\"}, \"content_type\": {\"type\": \"string\", \"title\": \"Content Type\", \"default\": \"multimodal\"}, \"collection_id\": {\"type\": \"string\", \"title\": \"Collection Id\"}}}, \"source\": \"smithery\", \"access_level\": \"write\"}, {\"name\": \"frame\", \"description\": \"Extract a single frame from a video\", \"inputSchema\": {\"type\": \"object\", \"title\": \"frameArguments\", \"required\": [\"video_id\", \"collection_id\"], \"properties\": {\"video_id\": {\"type\": \"string\", \"title\": \"Video Id\"}, \"timestamp\": {\"anyOf\": [{\"type\": \"number\"}, {\"type\": \"null\"}], \"title\": \"Timestamp\", \"default\": null}, \"collection_id\": {\"type\": \"string\", \"title\": \"Collection Id\"}}}, \"source\": \"smithery\", \"access_level\": \"read\"}, {\"name\": \"stream_video\", \"description\": \"Get streaming URL for a video\", \"inputSchema\": {\"type\": \"object\", \"title\": \"stream_videoArguments\", \"required\": [\"video_id\", \"collection_id\"], \"properties\": {\"video_id\": {\"type\": \"string\", \"title\": \"Video Id\"}, \"collection_id\": {\"type\": \"string\", \"title\": \"Collection Id\"}}}, \"source\": \"smithery\", \"access_level\": \"read\"}, {\"name\": \"download\", \"description\": \"Get download URL for a video\", \"inputSchema\": {\"type\": \"object\", \"title\": \"downloadArguments\", \"required\": [\"stream_link\"], \"properties\": {\"name\": {\"anyOf\": [{\"type\": \"string\"}, {\"type\": \"null\"}], \"title\": \"Name\", \"default\": null}, \"stream_link\": {\"type\": \"string\", \"title\": \"Stream Link\"}}}, \"source\": \"smithery\", \"access_level\": \"execute\"}, {\"name\": \"subtitle\", \"description\": \"Add subtitles to a video in a specified language\", \"inputSchema\": {\"type\": \"object\", \"title\": \"subtitleArguments\", \"required\": [\"video_id\", \"collection_id\", \"language\"], \"properties\": {\"language\": {\"type\": \"string\", \"title\": \"Language\"}, \"video_id\": {\"type\": \"string\", \"title\": \"Video Id\"}, \"style_notes\": {\"anyOf\": [{\"type\": \"string\"}, {\"type\": \"null\"}], \"title\": \"Style Notes\", \"default\": null}, \"collection_id\": {\"type\": \"string\", \"title\": \"Collection Id\"}}}, \"source\": \"smithery\", \"access_level\": \"write\"}, {\"name\": \"transcription\", \"description\": \"Get transcription of a video\", \"inputSchema\": {\"type\": \"object\", \"title\": \"transcriptionArguments\", \"required\": [\"video_id\", \"collection_id\"], \"properties\": {\"video_id\": {\"type\": \"string\", \"title\": \"Video Id\"}, \"time_range\": {\"anyOf\": [{\"type\": \"array\", \"items\": {\"type\": \"number\"}}, {\"type\": \"null\"}], \"title\": \"Time Range\", \"default\": null}, \"collection_id\": {\"type\": \"string\", \"title\": \"Collection Id\"}, \"include_timestamps\": {\"type\": \"boolean\", \"title\": \"Include Timestamps\", \"default\": true}}}, \"source\": \"smithery\", \"access_level\": \"read\"}, {\"name\": \"dubbing\", \"description\": \"Dub a video into another language\", \"inputSchema\": {\"type\": \"object\", \"title\": \"dubbingArguments\", \"required\": [\"video_id\", \"collection_id\", \"target_language\", \"language_code\"], \"properties\": {\"engine\": {\"anyOf\": [{\"type\": \"string\"}, {\"type\": \"null\"}], \"title\": \"Engine\", \"default\": null}, \"video_id\": {\"type\": \"string\", \"title\": \"Video Id\"}, \"collection_id\": {\"type\": \"string\", \"title\": \"Collection Id\"}, \"language_code\": {\"type\": \"string\", \"title\": \"Language Code\"}, \"target_language\": {\"type\": \"string\", \"title\": \"Target Language\"}}}, \"source\": \"smithery\", \"access_level\": \"read\"}, {\"name\": \"editing\", \"description\": \"Edit or combine videos in a collection\", \"inputSchema\": {\"type\": \"object\", \"title\": \"editingArguments\", \"required\": [\"collection_id\", \"instructions\"], \"properties\": {\"instructions\": {\"type\": \"string\", \"title\": \"Instructions\"}, \"collection_id\": {\"type\": \"string\", \"title\": \"Collection Id\"}}}, \"source\": \"smithery\", \"access_level\": \"write\"}, {\"name\": \"censor\", \"description\": \"Censor profanities or specified content in a video\", \"inputSchema\": {\"type\": \"object\", \"title\": \"censorArguments\", \"required\": [\"video_id\", \"collection_id\"], \"properties\": {\"video_id\": {\"type\": \"string\", \"title\": \"Video Id\"}, \"collection_id\": {\"type\": \"string\", \"title\": \"Collection Id\"}, \"custom_prompt\": {\"anyOf\": [{\"type\": \"string\"}, {\"type\": \"null\"}], \"title\": \"Custom Prompt\", \"default\": null}}}, \"source\": \"smithery\", \"access_level\": \"read\"}, {\"name\": \"video_generation\", \"description\": \"Generate videos from text or images\", \"inputSchema\": {\"type\": \"object\", \"title\": \"video_generationArguments\", \"required\": [\"collection_id\", \"prompt\"], \"properties\": {\"config\": {\"anyOf\": [{\"type\": \"object\", \"additionalProperties\": true}, {\"type\": \"null\"}], \"title\": \"Config\", \"default\": null}, \"engine\": {\"anyOf\": [{\"type\": \"string\"}, {\"type\": \"null\"}], \"title\": \"Engine\", \"default\": null}, \"prompt\": {\"type\": \"string\", \"title\": \"Prompt\"}, \"collection_id\": {\"type\": \"string\", \"title\": \"Collection Id\"}, \"generation_type\": {\"type\": \"string\", \"title\": \"Generation Type\", \"default\": \"text_to_video\"}}}, \"source\": \"smithery\", \"access_level\": \"write\"}, {\"name\": \"audio_generation\", \"description\": \"Generate speech, sound effects, or music\", \"inputSchema\": {\"type\": \"object\", \"title\": \"audio_generationArguments\", \"required\": [\"collection_id\", \"text\"], \"properties\": {\"text\": {\"type\": \"string\", \"title\": \"Text\"}, \"config\": {\"anyOf\": [{\"type\": \"object\", \"additionalProperties\": true}, {\"type\": \"null\"}], \"title\": \"Config\", \"default\": null}, \"engine\": {\"anyOf\": [{\"type\": \"string\"}, {\"type\": \"null\"}], \"title\": \"Engine\", \"default\": null}, \"job_type\": {\"type\": \"string\", \"title\": \"Job Type\", \"default\": \"text_to_speech\"}, \"collection_id\": {\"type\": \"string\", \"title\": \"Collection Id\"}}}, \"source\": \"smithery\", \"access_level\": \"write\"}, {\"name\": \"image_generation\", \"description\": \"Generate or enhance images\", \"inputSchema\": {\"type\": \"object\", \"title\": \"image_generationArguments\", \"required\": [\"collection_id\", \"prompt\"], \"properties\": {\"config\": {\"anyOf\": [{\"type\": \"object\", \"additionalProperties\": true}, {\"type\": \"null\"}], \"title\": \"Config\", \"default\": null}, \"prompt\": {\"type\": \"string\", \"title\": \"Prompt\"}, \"collection_id\": {\"type\": \"string\", \"title\": \"Collection Id\"}, \"generation_type\": {\"type\": \"string\", \"title\": \"Generation Type\", \"default\": \"text_to_image\"}}}, \"source\": \"smithery\", \"access_level\": \"write\"}, {\"name\": \"meeting_recorder\", \"description\": \"Record meetings from Google Meet or MS Teams\", \"inputSchema\": {\"type\": \"object\", \"title\": \"meeting_recorderArguments\", \"required\": [\"meeting_url\"], \"properties\": {\"title\": {\"anyOf\": [{\"type\": \"string\"}, {\"type\": \"null\"}], \"title\": \"Title\", \"default\": null}, \"password\": {\"anyOf\": [{\"type\": \"string\"}, {\"type\": \"null\"}], \"title\": \"Password\", \"default\": null}, \"meeting_url\": {\"type\": \"string\", \"title\": \"Meeting Url\"}}}, \"source\": \"smithery\", \"access_level\": \"read\"}, {\"name\": \"web_search\", \"description\": \"Search for videos on the web\", \"inputSchema\": {\"type\": \"object\", \"title\": \"web_searchArguments\", \"required\": [\"query\"], \"properties\": {\"query\": {\"type\": \"string\", \"title\": \"Query\"}, \"num_results\": {\"type\": \"integer\", \"title\": \"Num Results\", \"default\": 10}, \"duration_filter\": {\"anyOf\": [{\"type\": \"string\"}, {\"type\": \"null\"}], \"title\": \"Duration Filter\", \"default\": null}}}, \"source\": \"smithery\", \"access_level\": \"read\"}, {\"name\": \"pricing\", \"description\": \"Get pricing or usage information for VideoDB services\", \"inputSchema\": {\"type\": \"object\", \"title\": \"pricingArguments\", \"required\": [\"query\"], \"properties\": {\"query\": {\"type\": \"string\", \"title\": \"Query\"}}}, \"source\": \"smithery\", \"access_level\": \"read\"}, {\"name\": \"code_generator\", \"description\": \"Generate VideoDB-related code from natural language\", \"inputSchema\": {\"type\": \"object\", \"title\": \"code_generatorArguments\", \"required\": [\"prompt\"], \"properties\": {\"prompt\": {\"type\": \"string\", \"title\": \"Prompt\"}, \"language\": {\"type\": \"string\", \"title\": \"Language\", \"default\": \"python\"}}}, \"source\": \"smithery\", \"access_level\": \"write\"}], \"tools_count\": 24, \"homepage\": \"https://smithery.ai/server/@samihalawa/video-agent-mcp\", \"url\": \"\", \"topics\": [], \"data_sources\": [\"smithery\"]}", "target": "", "id": "@samihalawa/video-agent-mcp", "metadata": {"stage": "finance_filter"}}
{"input": "ONLY RESPOND WITH JSON. NO EXPLANATIONS. NO MARKDOWN. NO TEXT OUTSIDE JSON.\n\nAnalyze the MCP server for financial relevance. Look for keywords: payment, banking, credit, loan, finance, money, currency, crypto, investment, trading, portfolio, market, exchange, wallet, account, budget, expense, income, tax, invoice, billing, accounting, insurance, compliance, KYC, AML.\n\nJSON FORMAT (NOTHING ELSE):\n{\n  \"server_name\": \"string\",\n  \"server_id\": \"string\", \n  \"is_finance_llm\": \"yes|no|unclear\",\n  \"confidence\": \"high|medium|low\",\n  \"threat_models\": [],\n  \"analysis_notes\": \"Brief reason\"\n}\n\nIf financial keywords found: is_finance_llm=\"yes\". If not: is_finance_llm=\"no\". If unclear: is_finance_llm=\"unclear\".\n\nRESPOND ONLY WITH JSON.\n\nMCP Server Data:\n{\"server_name\": \"OP.GG\", \"server_id\": \"@opgginc/opgg-mcp\", \"description\": \"The OP.GG MCP Server provides AI agents with a comprehensive suite of tools that deliver gaming data across popular titles, including champion analysis and rankings for League of Legends, match schedules and team standings for LoL esports, meta deck compositions, item combinations, champion build recommendations and playstyle insights for Teamfight Tactics, as well as map meta, character statistics, leaderboards, agent compositions and player match history for Valorant, along with various other gaming information.\", \"readme\": \"\", \"tools\": [{\"name\": \"lol-champion-leader-board\", \"description\": \"Retrieves the leaderboard of master players who play a specific champion well. You can also look up the high ranked players, like the high winrate 5 players in #1-#30, to retrieve their champion performance or recent match history to teach how to play the champions.\", \"inputSchema\": {\"type\": \"object\", \"required\": [\"region\", \"champion\"], \"properties\": {\"region\": {\"enum\": [\"KR\", \"BR\", \"EUNE\", \"EUW\", \"LAN\", \"LAS\", \"NA\", \"OCE\", \"RU\", \"TR\", \"JP\", \"PH\", \"SG\", \"TH\", \"TW\", \"VN\", \"ME\", \"SEA\"], \"type\": \"string\", \"description\": \"Regions in the game League of Legends.\"}, \"champion\": {\"enum\": [\"ANNIE\", \"OLAF\", \"GALIO\", \"TWISTED_FATE\", \"XIN_ZHAO\", \"URGOT\", \"LEBLANC\", \"VLADIMIR\", \"FIDDLESTICKS\", \"KAYLE\", \"MASTER_YI\", \"ALISTAR\", \"RYZE\", \"SION\", \"SIVIR\", \"SORAKA\", \"TEEMO\", \"TRISTANA\", \"WARWICK\", \"NUNU_WILLUMP\", \"MISS_FORTUNE\", \"ASHE\", \"TRYNDAMERE\", \"JAX\", \"MORGANA\", \"ZILEAN\", \"SINGED\", \"EVELYNN\", \"TWITCH\", \"KARTHUS\", \"CHOGATH\", \"AMUMU\", \"RAMMUS\", \"ANIVIA\", \"SHACO\", \"DR_MUNDO\", \"SONA\", \"KASSADIN\", \"IRELIA\", \"JANNA\", \"GANGPLANK\", \"CORKI\", \"KARMA\", \"TARIC\", \"VEIGAR\", \"TRUNDLE\", \"SWAIN\", \"CAITLYN\", \"BLITZCRANK\", \"MALPHITE\", \"KATARINA\", \"NOCTURNE\", \"MAOKAI\", \"RENEKTON\", \"JARVAN_IV\", \"ELISE\", \"ORIANNA\", \"WUKONG\", \"BRAND\", \"LEE_SIN\", \"VAYNE\", \"RUMBLE\", \"CASSIOPEIA\", \"SKARNER\", \"HEIMERDINGER\", \"NASUS\", \"NIDALEE\", \"UDYR\", \"POPPY\", \"GRAGAS\", \"PANTHEON\", \"EZREAL\", \"MORDEKAISER\", \"YORICK\", \"AKALI\", \"KENNEN\", \"GAREN\", \"LEONA\", \"MALZAHAR\", \"TALON\", \"RIVEN\", \"KOGMAW\", \"SHEN\", \"LUX\", \"XERATH\", \"SHYVANA\", \"AHRI\", \"GRAVES\", \"FIZZ\", \"VOLIBEAR\", \"RENGAR\", \"VARUS\", \"NAUTILUS\", \"VIKTOR\", \"SEJUANI\", \"FIORA\", \"ZIGGS\", \"LULU\", \"DRAVEN\", \"HECARIM\", \"KHAZIX\", \"DARIUS\", \"JAYCE\", \"LISSANDRA\", \"DIANA\", \"QUINN\", \"SYNDRA\", \"AURELION_SOL\", \"KAYN\", \"ZOE\", \"ZYRA\", \"KAISA\", \"SERAPHINE\", \"GNAR\", \"ZAC\", \"YASUO\", \"VELKOZ\", \"TALIYAH\", \"CAMILLE\", \"AKSHAN\", \"BELVETH\", \"BRAUM\", \"JHIN\", \"KINDRED\", \"ZERI\", \"JINX\", \"TAHM_KENCH\", \"BRIAR\", \"VIEGO\", \"SENNA\", \"LUCIAN\", \"ZED\", \"KLED\", \"EKKO\", \"QIYANA\", \"VI\", \"AATROX\", \"NAMI\", \"AZIR\", \"YUUMI\", \"SAMIRA\", \"THRESH\", \"ILLAOI\", \"REKSAI\", \"IVERN\", \"KALISTA\", \"BARD\", \"RAKAN\", \"XAYAH\", \"ORNN\", \"SYLAS\", \"NEEKO\", \"APHELIOS\", \"RELL\", \"PYKE\", \"VEX\", \"YONE\", \"AMBESSA\", \"SETT\", \"LILLIA\", \"GWEN\", \"RENATA_GLASC\", \"AURORA\", \"NILAH\", \"KSANTE\", \"SMOLDER\", \"MILIO\", \"HWEI\", \"NAAFIRI\"], \"type\": \"string\", \"description\": \"These are the champion names in the game League of Legends.\"}}}, \"source\": \"smithery\", \"access_level\": \"read\"}, {\"name\": \"lol-champion-analysis\", \"description\": \"Retrieves very detailed information about a specific champion, such as win rate, pick rate, recommended builds, recommended skill order, recommended items, etc. If a user mentions a specific champion, you *must* always call this function, review the data, and then respond. If the user asks some tips during playing game, you should also occasionally call this function to advice how to play the game well. If the users asks like 'what items should I buy?', 'which skill should I level up?', also you need to call this function to see the high winrate champions. (Counter Picks ban/pick data is available in the `weakCounters` field). You must assume the position user want to know.\", \"inputSchema\": {\"type\": \"object\", \"required\": [\"champion\", \"position\", \"lang\"], \"properties\": {\"lang\": {\"enum\": [\"ar_AE\", \"cs_CZ\", \"de_DE\", \"el_GR\", \"en_US\", \"en_AU\", \"en_GB\", \"en_PH\", \"en_SG\", \"es_AR\", \"es_ES\", \"es_MX\", \"fr_FR\", \"hu_HU\", \"it_IT\", \"ja_JP\", \"ko_KR\", \"pl_PL\", \"pt_BR\", \"ro_RO\", \"ru_RU\", \"th_TH\", \"tr_TR\", \"vi_VN\", \"zh_CN\", \"zh_MY\", \"zh_TW\"], \"type\": \"string\", \"description\": \"Language code for localized content. Determines the language of returned data.\"}, \"champion\": {\"enum\": [\"ANNIE\", \"OLAF\", \"GALIO\", \"TWISTED_FATE\", \"XIN_ZHAO\", \"URGOT\", \"LEBLANC\", \"VLADIMIR\", \"FIDDLESTICKS\", \"KAYLE\", \"MASTER_YI\", \"ALISTAR\", \"RYZE\", \"SION\", \"SIVIR\", \"SORAKA\", \"TEEMO\", \"TRISTANA\", \"WARWICK\", \"NUNU_WILLUMP\", \"MISS_FORTUNE\", \"ASHE\", \"TRYNDAMERE\", \"JAX\", \"MORGANA\", \"ZILEAN\", \"SINGED\", \"EVELYNN\", \"TWITCH\", \"KARTHUS\", \"CHOGATH\", \"AMUMU\", \"RAMMUS\", \"ANIVIA\", \"SHACO\", \"DR_MUNDO\", \"SONA\", \"KASSADIN\", \"IRELIA\", \"JANNA\", \"GANGPLANK\", \"CORKI\", \"KARMA\", \"TARIC\", \"VEIGAR\", \"TRUNDLE\", \"SWAIN\", \"CAITLYN\", \"BLITZCRANK\", \"MALPHITE\", \"KATARINA\", \"NOCTURNE\", \"MAOKAI\", \"RENEKTON\", \"JARVAN_IV\", \"ELISE\", \"ORIANNA\", \"WUKONG\", \"BRAND\", \"LEE_SIN\", \"VAYNE\", \"RUMBLE\", \"CASSIOPEIA\", \"SKARNER\", \"HEIMERDINGER\", \"NASUS\", \"NIDALEE\", \"UDYR\", \"POPPY\", \"GRAGAS\", \"PANTHEON\", \"EZREAL\", \"MORDEKAISER\", \"YORICK\", \"AKALI\", \"KENNEN\", \"GAREN\", \"LEONA\", \"MALZAHAR\", \"TALON\", \"RIVEN\", \"KOGMAW\", \"SHEN\", \"LUX\", \"XERATH\", \"SHYVANA\", \"AHRI\", \"GRAVES\", \"FIZZ\", \"VOLIBEAR\", \"RENGAR\", \"VARUS\", \"NAUTILUS\", \"VIKTOR\", \"SEJUANI\", \"FIORA\", \"ZIGGS\", \"LULU\", \"DRAVEN\", \"HECARIM\", \"KHAZIX\", \"DARIUS\", \"JAYCE\", \"LISSANDRA\", \"DIANA\", \"QUINN\", \"SYNDRA\", \"AURELION_SOL\", \"KAYN\", \"ZOE\", \"ZYRA\", \"KAISA\", \"SERAPHINE\", \"GNAR\", \"ZAC\", \"YASUO\", \"VELKOZ\", \"TALIYAH\", \"CAMILLE\", \"AKSHAN\", \"BELVETH\", \"BRAUM\", \"JHIN\", \"KINDRED\", \"ZERI\", \"JINX\", \"TAHM_KENCH\", \"BRIAR\", \"VIEGO\", \"SENNA\", \"LUCIAN\", \"ZED\", \"KLED\", \"EKKO\", \"QIYANA\", \"VI\", \"AATROX\", \"NAMI\", \"AZIR\", \"YUUMI\", \"SAMIRA\", \"THRESH\", \"ILLAOI\", \"REKSAI\", \"IVERN\", \"KALISTA\", \"BARD\", \"RAKAN\", \"XAYAH\", \"ORNN\", \"SYLAS\", \"NEEKO\", \"APHELIOS\", \"RELL\", \"PYKE\", \"VEX\", \"YONE\", \"AMBESSA\", \"SETT\", \"LILLIA\", \"GWEN\", \"RENATA_GLASC\", \"AURORA\", \"NILAH\", \"KSANTE\", \"SMOLDER\", \"MILIO\", \"HWEI\", \"NAAFIRI\"], \"type\": \"string\", \"description\": \"These are the champion names in the game League of Legends.\"}, \"position\": {\"enum\": [\"TOP\", \"MID\", \"JUNGLE\", \"ADC\", \"SUPPORT\", \"NONE\"], \"type\": \"string\", \"description\": \"These are the champion positions in the game League of Legends.\"}}}, \"source\": \"smithery\", \"access_level\": \"execute\"}, {\"name\": \"lol-champion-meta-data\", \"description\": \"Retrieves meta data for a specific champion, including statistics and performance metrics.\", \"inputSchema\": {\"type\": \"object\", \"required\": [\"champion\", \"lang\"], \"properties\": {\"lang\": {\"enum\": [\"ar_AE\", \"cs_CZ\", \"de_DE\", \"el_GR\", \"en_US\", \"en_AU\", \"en_GB\", \"en_PH\", \"en_SG\", \"es_AR\", \"es_ES\", \"es_MX\", \"fr_FR\", \"hu_HU\", \"it_IT\", \"ja_JP\", \"ko_KR\", \"pl_PL\", \"pt_BR\", \"ro_RO\", \"ru_RU\", \"th_TH\", \"tr_TR\", \"vi_VN\", \"zh_CN\", \"zh_MY\", \"zh_TW\"], \"type\": \"string\", \"description\": \"Language code for localized content. Determines the language of returned data.\"}, \"champion\": {\"enum\": [\"ANNIE\", \"OLAF\", \"GALIO\", \"TWISTED_FATE\", \"XIN_ZHAO\", \"URGOT\", \"LEBLANC\", \"VLADIMIR\", \"FIDDLESTICKS\", \"KAYLE\", \"MASTER_YI\", \"ALISTAR\", \"RYZE\", \"SION\", \"SIVIR\", \"SORAKA\", \"TEEMO\", \"TRISTANA\", \"WARWICK\", \"NUNU_WILLUMP\", \"MISS_FORTUNE\", \"ASHE\", \"TRYNDAMERE\", \"JAX\", \"MORGANA\", \"ZILEAN\", \"SINGED\", \"EVELYNN\", \"TWITCH\", \"KARTHUS\", \"CHOGATH\", \"AMUMU\", \"RAMMUS\", \"ANIVIA\", \"SHACO\", \"DR_MUNDO\", \"SONA\", \"KASSADIN\", \"IRELIA\", \"JANNA\", \"GANGPLANK\", \"CORKI\", \"KARMA\", \"TARIC\", \"VEIGAR\", \"TRUNDLE\", \"SWAIN\", \"CAITLYN\", \"BLITZCRANK\", \"MALPHITE\", \"KATARINA\", \"NOCTURNE\", \"MAOKAI\", \"RENEKTON\", \"JARVAN_IV\", \"ELISE\", \"ORIANNA\", \"WUKONG\", \"BRAND\", \"LEE_SIN\", \"VAYNE\", \"RUMBLE\", \"CASSIOPEIA\", \"SKARNER\", \"HEIMERDINGER\", \"NASUS\", \"NIDALEE\", \"UDYR\", \"POPPY\", \"GRAGAS\", \"PANTHEON\", \"EZREAL\", \"MORDEKAISER\", \"YORICK\", \"AKALI\", \"KENNEN\", \"GAREN\", \"LEONA\", \"MALZAHAR\", \"TALON\", \"RIVEN\", \"KOGMAW\", \"SHEN\", \"LUX\", \"XERATH\", \"SHYVANA\", \"AHRI\", \"GRAVES\", \"FIZZ\", \"VOLIBEAR\", \"RENGAR\", \"VARUS\", \"NAUTILUS\", \"VIKTOR\", \"SEJUANI\", \"FIORA\", \"ZIGGS\", \"LULU\", \"DRAVEN\", \"HECARIM\", \"KHAZIX\", \"DARIUS\", \"JAYCE\", \"LISSANDRA\", \"DIANA\", \"QUINN\", \"SYNDRA\", \"AURELION_SOL\", \"KAYN\", \"ZOE\", \"ZYRA\", \"KAISA\", \"SERAPHINE\", \"GNAR\", \"ZAC\", \"YASUO\", \"VELKOZ\", \"TALIYAH\", \"CAMILLE\", \"AKSHAN\", \"BELVETH\", \"BRAUM\", \"JHIN\", \"KINDRED\", \"ZERI\", \"JINX\", \"TAHM_KENCH\", \"BRIAR\", \"VIEGO\", \"SENNA\", \"LUCIAN\", \"ZED\", \"KLED\", \"EKKO\", \"QIYANA\", \"VI\", \"AATROX\", \"NAMI\", \"AZIR\", \"YUUMI\", \"SAMIRA\", \"THRESH\", \"ILLAOI\", \"REKSAI\", \"IVERN\", \"KALISTA\", \"BARD\", \"RAKAN\", \"XAYAH\", \"ORNN\", \"SYLAS\", \"NEEKO\", \"APHELIOS\", \"RELL\", \"PYKE\", \"VEX\", \"YONE\", \"AMBESSA\", \"SETT\", \"LILLIA\", \"GWEN\", \"RENATA_GLASC\", \"AURORA\", \"NILAH\", \"KSANTE\", \"SMOLDER\", \"MILIO\", \"HWEI\", \"NAAFIRI\"], \"type\": \"string\", \"description\": \"These are the champion names in the game League of Legends.\"}}}, \"source\": \"smithery\", \"access_level\": \"read\"}, {\"name\": \"lol-champion-skin-sale\", \"description\": \"Retrieves information about champion skins that are currently on sale.\", \"inputSchema\": {\"type\": \"object\", \"required\": [\"lang\"], \"properties\": {\"lang\": {\"enum\": [\"ar_AE\", \"cs_CZ\", \"de_DE\", \"el_GR\", \"en_US\", \"en_AU\", \"en_GB\", \"en_PH\", \"en_SG\", \"es_AR\", \"es_ES\", \"es_MX\", \"fr_FR\", \"hu_HU\", \"it_IT\", \"ja_JP\", \"ko_KR\", \"pl_PL\", \"pt_BR\", \"ro_RO\", \"ru_RU\", \"th_TH\", \"tr_TR\", \"vi_VN\", \"zh_CN\", \"zh_MY\", \"zh_TW\"], \"type\": \"string\", \"description\": \"Language code for localized content. Determines the language of returned data.\"}}}, \"source\": \"smithery\", \"access_level\": \"read\"}, {\"name\": \"lol-summoner-search\", \"description\": \"Retrieves information about a specific summoner, such as their rank, win rate, and recent match history. If a user mentions a specific summoner or wants to know about themselves, you *must* always call this function.\", \"inputSchema\": {\"type\": \"object\", \"required\": [\"game_name\", \"tag_line\", \"region\", \"lang\"], \"properties\": {\"lang\": {\"enum\": [\"ar_AE\", \"cs_CZ\", \"de_DE\", \"el_GR\", \"en_US\", \"en_AU\", \"en_GB\", \"en_PH\", \"en_SG\", \"es_AR\", \"es_ES\", \"es_MX\", \"fr_FR\", \"hu_HU\", \"it_IT\", \"ja_JP\", \"ko_KR\", \"pl_PL\", \"pt_BR\", \"ro_RO\", \"ru_RU\", \"th_TH\", \"tr_TR\", \"vi_VN\", \"zh_CN\", \"zh_MY\", \"zh_TW\"], \"type\": \"string\", \"description\": \"Language code for localized content. Determines the language of returned data.\"}, \"region\": {\"enum\": [\"KR\", \"BR\", \"EUNE\", \"EUW\", \"LAN\", \"LAS\", \"NA\", \"OCE\", \"RU\", \"TR\", \"JP\", \"PH\", \"SG\", \"TH\", \"TW\", \"VN\", \"ME\", \"SEA\"], \"type\": \"string\", \"description\": \"The region to search in (e.g., KR, NA, EUW).\"}, \"tag_line\": {\"type\": \"string\", \"description\": \"The second part of a Riot ID (e.g., \\\"Opgg\\\" in \\\"Annie#Opgg\\\").\"}, \"game_name\": {\"type\": \"string\", \"description\": \"The first part of a Riot ID (e.g., \\\"Annie\\\" in \\\"Annie#Opgg\\\").\"}}}, \"source\": \"smithery\", \"access_level\": \"read\"}, {\"name\": \"lol-champion-positions-data\", \"description\": \"Retrieves the analytics of champions by each positions. You can also look up the winrate, banrate, plays, wins, kills, kda and etc. `tier_data` is champion tier which tells which champion is powerful (OP) or not, for example `tier 1` champion is easy to play and powerful champion. (You can recommend this champion to the user if they want recommandation)\", \"inputSchema\": {\"type\": \"object\", \"required\": [\"lang\"], \"properties\": {\"lang\": {\"enum\": [\"ar_AE\", \"cs_CZ\", \"de_DE\", \"el_GR\", \"en_US\", \"en_AU\", \"en_GB\", \"en_PH\", \"en_SG\", \"es_AR\", \"es_ES\", \"es_MX\", \"fr_FR\", \"hu_HU\", \"it_IT\", \"ja_JP\", \"ko_KR\", \"pl_PL\", \"pt_BR\", \"ro_RO\", \"ru_RU\", \"th_TH\", \"tr_TR\", \"vi_VN\", \"zh_CN\", \"zh_MY\", \"zh_TW\"], \"type\": \"string\", \"description\": \"Language code for localized content. Determines the language of returned data.\"}}}, \"source\": \"smithery\", \"access_level\": \"execute\"}, {\"name\": \"lol-summoner-game-history\", \"description\": \"Retrieves the recent match history of a specific summoner. If a user mentions a specific summoner, wants to know about their recent matches, wants to know how to improve or wants to get an advice, you *must* always call this function.\", \"inputSchema\": {\"type\": \"object\", \"required\": [\"game_name\", \"tag_line\", \"region\", \"lang\"], \"properties\": {\"lang\": {\"enum\": [\"ar_AE\", \"cs_CZ\", \"de_DE\", \"el_GR\", \"en_US\", \"en_AU\", \"en_GB\", \"en_PH\", \"en_SG\", \"es_AR\", \"es_ES\", \"es_MX\", \"fr_FR\", \"hu_HU\", \"it_IT\", \"ja_JP\", \"ko_KR\", \"pl_PL\", \"pt_BR\", \"ro_RO\", \"ru_RU\", \"th_TH\", \"tr_TR\", \"vi_VN\", \"zh_CN\", \"zh_MY\", \"zh_TW\"], \"type\": \"string\", \"description\": \"Language code for localized content. Determines the language of returned data.\"}, \"region\": {\"enum\": [\"KR\", \"BR\", \"EUNE\", \"EUW\", \"LAN\", \"LAS\", \"NA\", \"OCE\", \"RU\", \"TR\", \"JP\", \"PH\", \"SG\", \"TH\", \"TW\", \"VN\", \"ME\", \"SEA\"], \"type\": \"string\", \"description\": \"The region to search in (e.g., KR, NA, EUW).\"}, \"tag_line\": {\"type\": \"string\", \"description\": \"The second part of a Riot ID (e.g., \\\"Opgg\\\" in \\\"Annie#Opgg\\\").\"}, \"game_name\": {\"type\": \"string\", \"description\": \"The first part of a Riot ID (e.g., \\\"Annie\\\" in \\\"Annie#Opgg\\\").\"}}}, \"source\": \"smithery\", \"access_level\": \"read\"}, {\"name\": \"lol-summoner-renewal\", \"description\": \"Renew the summoner's data of OP.GG through RiotAPI. When you retrieve summoner data, you *must* always call this function first, and then call the next functions.\", \"inputSchema\": {\"type\": \"object\", \"required\": [\"game_name\", \"tag_line\", \"region\"], \"properties\": {\"region\": {\"enum\": [\"KR\", \"BR\", \"EUNE\", \"EUW\", \"LAN\", \"LAS\", \"NA\", \"OCE\", \"RU\", \"TR\", \"JP\", \"PH\", \"SG\", \"TH\", \"TW\", \"VN\", \"ME\", \"SEA\"], \"type\": \"string\", \"description\": \"The region to search in (e.g., KR, NA, EUW).\"}, \"tag_line\": {\"type\": \"string\", \"description\": \"The second part of a Riot ID (e.g., \\\"Opgg\\\" in \\\"Annie#Opgg\\\").\"}, \"game_name\": {\"type\": \"string\", \"description\": \"The first part of a Riot ID (e.g., \\\"Annie\\\" in \\\"Annie#Opgg\\\").\"}}}, \"source\": \"smithery\", \"access_level\": \"read\"}, {\"name\": \"esports-lol-schedules\", \"description\": \"Get upcoming LoL match schedules.\", \"inputSchema\": {\"type\": \"object\", \"required\": [], \"properties\": {}}, \"source\": \"smithery\", \"access_level\": \"read\"}, {\"name\": \"esports-lol-team-standings\", \"description\": \"Get team standings for a LoL league.\", \"inputSchema\": {\"type\": \"object\", \"required\": [\"shortName\"], \"properties\": {\"shortName\": {\"enum\": [\"lck\", \"lpl\", \"lec\", \"lcs\", \"ljl\", \"vcs\", \"cblol\", \"lcl\", \"lla\", \"tcl\", \"pcs\", \"lco\", \"lta south\", \"lta north\", \"lcp\", \"first stand\", \"fst\", \"al\", \"msi\", \"worlds\"], \"type\": \"string\", \"description\": \"League short name (LCK, LPL, Worlds, ...)\"}}}, \"source\": \"smithery\", \"access_level\": \"read\"}, {\"name\": \"tft-meta-trend-deck-list\", \"description\": \"TFT deck list tool for retrieving current meta decks.\", \"inputSchema\": {\"type\": \"object\", \"required\": [], \"properties\": {}}, \"source\": \"smithery\", \"access_level\": \"read\"}, {\"name\": \"tft-meta-item-combinations\", \"description\": \"TFT tool for retrieving information about item combinations and recipes.\", \"inputSchema\": {\"type\": \"object\", \"required\": [], \"properties\": {\"language\": {\"enum\": [\"en_US\", \"ko_KR\", \"ja_JP\", \"zh_CN\", \"zh_TW\", \"fr_FR\", \"de_DE\", \"es_ES\", \"it_IT\", \"pl_PL\", \"pt_BR\", \"ru_RU\", \"tr_TR\", \"vi_VN\"], \"type\": \"string\", \"description\": \"These are the champion names in the game League of Legends.\"}}}, \"source\": \"smithery\", \"access_level\": \"read\"}, {\"name\": \"tft-champion-item-build\", \"description\": \"TFT tool for retrieving champion item build information.\", \"inputSchema\": {\"type\": \"object\", \"required\": [\"championId\"], \"properties\": {\"championId\": {\"enum\": [\"TFT14_DrMundo\", \"TFT14_Shaco\", \"TFT14_Kindred\", \"TFT14_Ekko\", \"TFT14_Urgot\", \"TFT14_Varus\", \"TFT14_Jinx\", \"TFT14_Sejuani\", \"TFT14_Morgana\", \"TFT14_Yuumi\", \"TFT14_Senna\", \"TFT14_Viego\", \"TFT14_Zeri\", \"TFT14_Neeko\", \"TFT14_Vi\", \"TFT14_KogMaw\", \"TFT14_Zed\", \"TFT14_Aphelios\", \"TFT14_SummonLevel2\", \"TFT14_NidaleeCougar\", \"TFT14_Annie\", \"TFT14_Renekton\", \"TFT14_Mordekaiser\", \"TFT14_Poppy\", \"TFT14_Jax\", \"TFT14_LeBlanc\", \"TFT14_Elise\", \"TFT14_Kobuko\", \"TFT14_Fiddlesticks\", \"TFT14_Rhaast\", \"TFT14_Naafiri\", \"TFT14_Gragas\", \"TFT14_Seraphine\", \"TFT14_Brand\", \"TFT14_Ziggs\", \"TFT14_Alistar\", \"TFT14_Samira\", \"TFT14_Rengar\", \"TFT14_Garen\", \"TFT14_Braum\", \"TFT14_Vex\", \"TFT14_Shyvana\", \"TFT14_MissFortune\", \"TFT14_TwistedFate\", \"TFT14_Summon_Turret\", \"TFT14_Aurora\", \"TFT14_Vayne\", \"TFT14_Graves\", \"TFT14_Galio\", \"TFT14_Jarvan\", \"TFT14_Chogath\", \"TFT14_Xayah\", \"TFT14_Skarner\", \"TFT14_Draven\", \"TFT14_Zyra\", \"TFT14_Illaoi\", \"TFT14_Leona\", \"TFT14_Veigar\", \"TFT14_Sylas\", \"TFT14_SummonLevel4\", \"TFT14_Jhin\", \"TFT14_Zac\", \"TFT14_Darius\"], \"type\": \"string\", \"description\": \"TFT champion ID to retrieve item build for\"}}}, \"source\": \"smithery\", \"access_level\": \"write\"}, {\"name\": \"tft-recommend-champion-for-item\", \"description\": \"TFT tool for retrieving champion recommendations for a specific item.\", \"inputSchema\": {\"type\": \"object\", \"required\": [\"itemId\"], \"properties\": {\"itemId\": {\"enum\": [\"TFT5_Item_SpearOfShojinRadiant\", \"TFT_Item_ThiefsGloves\", \"TFT_Item_RapidFireCannon\", \"TFT_Item_Artifact_TalismanOfAscension\", \"TFT_Item_NightHarvester\", \"TFT14_MordekaiserCyberneticItem_Radiant\", \"TFT_Item_GiantsBelt\", \"TFT5_Item_TrapClawRadiant\", \"TFT_Item_Artifact_LichBane\", \"TFT5_Item_LastWhisperRadiant\", \"TFT5_Item_LeviathanRadiant\", \"TFT_Item_Artifact_Mittens\", \"TFT14_JhinCyberneticItem\", \"TFT_Item_FrozenHeart\", \"TFT14_Item_BruiserEmblemItem\", \"TFT_Item_RabadonsDeathcap\", \"TFT_Item_BrambleVest\", \"TFT14_JaxCyberneticItem\", \"TFT_Item_RecurveBow\", \"TFT5_Item_IonicSparkRadiant\", \"TFT14_NaafiriCyberneticItem_Radiant\", \"TFT4_Item_OrnnDeathsDefiance\", \"TFT_Item_Deathblade\", \"TFT_Item_Artifact_TitanicHydra\", \"TFT_Item_HextechGunblade\", \"TFT_Item_TacticiansRing\", \"TFT14_Item_SwiftEmblemItem\", \"TFT_Item_RunaansHurricane\", \"TFT_Item_SpectralGauntlet\", \"TFT_Item_Artifact_StatikkShiv\", \"TFT_Item_WarmogsArmor\", \"TFT5_Item_GiantSlayerRadiant\", \"TFT_Item_NegatronCloak\", \"TFT_Item_Artifact_SilvermereDawn\", \"TFT_Item_ArchangelsStaff\", \"TFT_Item_TitansResolve\", \"TFT_Item_GuardianAngel\", \"TFT9_Item_OrnnHullbreaker\", \"TFT_Item_Artifact_LightshieldCrest\", \"TFT_Item_BansheesVeil\", \"TFT_Item_JeweledGauntlet\", \"TFT14_VarusCyberneticItem\", \"TFT5_Item_QuicksilverRadiant\", \"TFT14_JhinCyberneticItem_Radiant\", \"TFT4_Item_OrnnObsidianCleaver\", \"TFT14_Item_DivinicorpEmblemItem\", \"TFT_Item_StatikkShiv\", \"TFT_Item_AdaptiveHelm\", \"TFT14_JaxCyberneticItem_Radiant\", \"TFT5_Item_GargoyleStoneplateRadiant\", \"TFT_Item_BFSword\", \"TFT14_Item_ArmorcladEmblemItem\", \"TFT5_Item_StatikkShivRadiant\", \"TFT5_Item_SpectralGauntletRadiant\", \"TFT_Item_Moonstone\", \"TFT_Item_InfinityEdge\", \"TFT5_Item_RabadonsDeathcapRadiant\", \"TFT4_Item_OrnnRanduinsSanctum\", \"TFT_Item_IonicSpark\", \"TFT5_Item_DeathbladeRadiant\", \"TFT14_Item_GuardianEmblemItem\", \"TFT9_Item_OrnnDeathfireGrasp\", \"TFT_Item_Chalice\", \"TFT5_Item_CrownguardRadiant\", \"TFT_Item_Redemption\", \"TFT_Item_Artifact_SpectralCutlass\", \"TFT_Item_Artifact_UnendingDespair\", \"TFT14_VarusCyberneticItem_Radiant\", \"TFT14_Item_Nitro_ChromeCounter\", \"TFT_Item_SteraksGage\", \"TFT_Item_Artifact_Fishbones\", \"TFT5_Item_WarmogsArmorRadiant\", \"TFT14_SejuaniCyberneticItem\", \"TFT_Item_BlueBuff\", \"TFT_Item_LocketOfTheIronSolari\", \"TFT_Item_Morellonomicon\", \"TFT14_Item_MarksmanEmblemItem\", \"TFT5_Item_ThiefsGlovesRadiant\", \"TFT14_Item_StrongEmblemItem\", \"TFT_Item_NeedlesslyLargeRod\", \"TFT_Item_RadiantVirtue\", \"TFT_Item_Leviathan\", \"TFT_Item_Quicksilver\", \"TFT5_Item_ZzRotPortalRadiant\", \"TFT4_Item_OrnnZhonyasParadox\", \"TFT7_Item_ShimmerscaleMogulsMail\", \"TFT_Item_Artifact_HorizonFocus\", \"TFT14_Item_StreetDemonEmblemItem\", \"TFT5_Item_BloodthirsterRadiant\", \"TFT5_Item_NightHarvesterRadiant\", \"TFT_Item_Artifact_WitsEnd\", \"TFT_Item_Artifact_LudensTempest\", \"TFT5_Item_RedemptionRadiant\", \"TFT_Item_DragonsClaw\", \"TFT5_Item_SteraksGageRadiant\", \"TFT4_Item_OrnnInfinityForce\", \"TFT_Item_Artifact_ProwlersClaw\", \"TFT5_Item_DragonsClawRadiant\", \"TFT5_Item_BrambleVestRadiant\", \"TFT4_Item_OrnnMuramana\", \"TFT_Item_ForceOfNature\", \"TFT7_Item_ShimmerscaleHeartOfGold\", \"TFT_Item_SpearOfShojin\", \"TFT_Item_AegisOfTheLegion\", \"TFT5_Item_SunfireCapeRadiant\", \"TFT14_ZeriCyberneticItem\", \"TFT14_Item_ImmortalEmblemItem\", \"TFT5_Item_RunaansHurricaneRadiant\", \"TFT5_Item_AdaptiveHelmRadiant\", \"TFT_Item_Artifact_BlightingJewel\", \"TFT_Item_Artifact_RapidFirecannon\", \"TFT_Item_ChainVest\", \"TFT14_MordekaiserCyberneticItem\", \"TFT_Item_TearOfTheGoddess\", \"TFT5_Item_RapidFirecannonRadiant\", \"TFT_Item_MadredsBloodrazor\", \"TFT_Item_FryingPan\", \"TFT5_Item_ArchangelsStaffRadiant\", \"TFT_Item_SparringGloves\", \"TFT9_Item_OrnnTrickstersGlass\", \"TFT_Item_SupportKnightsVow\", \"TFT_Item_EternalFlame\", \"TFT_Item_Shroud\", \"TFT14_Item_DarkWebEmblemItem\", \"TFT_Item_PowerGauntlet\", \"TFT_Item_Artifact_SuspiciousTrenchCoat\", \"TFT5_Item_JeweledGauntletRadiant\", \"TFT14_Item_EdgeRunnerEmblemItem\", \"TFT14_Item_BallistekEmblemItem\", \"TFT_Item_Bloodthirster\", \"TFT_Item_Artifact_SeekersArmguard\", \"TFT5_Item_FrozenHeartRadiant\", \"TFT5_Item_GuinsoosRagebladeRadiant\", \"TFT14_Item_ControllerEmblemItem\", \"TFT14_SejuaniCyberneticItem_Radiant\", \"TFT5_Item_MorellonomiconRadiant\", \"TFT_Item_Artifact_NavoriFlickerblades\", \"TFT5_Item_HandOfJusticeRadiant\", \"TFT14_Item_ThirstyEmblemItem\", \"TFT_Item_TacticiansScepter\", \"TFT_Item_UnstableConcoction\", \"TFT5_Item_HextechGunbladeRadiant\", \"TFT5_Item_GuardianAngelRadiant\", \"TFT_Item_UnstableTreasureChest\", \"TFT_Item_Crownguard\", \"TFT_Item_RedBuff\", \"TFT5_Item_InfinityEdgeRadiant\", \"TFT_Item_Zephyr\", \"TFT14_Item_TechieEmblemItem\", \"TFT4_Item_OrnnTheCollector\", \"TFT9_Item_OrnnHorizonFocus\", \"TFT_Item_LastWhisper\", \"TFT_Item_ZekesHerald\", \"TFT7_Item_ShimmerscaleGamblersBlade\", \"TFT14_Item_CutterEmblemItem\", \"TFT5_Item_TitansResolveRadiant\", \"TFT5_Item_BlueBuffRadiant\", \"TFT_Item_Artifact_TheIndomitable\", \"TFT14_Item_MobEmblemItem\", \"TFT_Item_Artifact_InnervatingLocket\", \"TFT_Item_Spatula\", \"TFT_Item_GargoyleStoneplate\", \"TFT_Item_GuinsoosRageblade\", \"TFT14_ZeriCyberneticItem_Radiant\", \"TFT14_NaafiriCyberneticItem\"], \"type\": \"string\", \"description\": \"TFT item ID to get champion recommendations for\"}}}, \"source\": \"smithery\", \"access_level\": \"read\"}, {\"name\": \"tft-play-style-comment\", \"description\": \"This tool provides comments on the playstyle of TFT champions.\", \"inputSchema\": {\"type\": \"object\", \"required\": [\"region\", \"puuid\"], \"properties\": {\"puuid\": {\"type\": \"string\", \"description\": \"Riot unique puuid value\"}, \"region\": {\"enum\": [\"KR\", \"BR\", \"EUNE\", \"EUW\", \"LAN\", \"LAS\", \"NA\", \"OCE\", \"RU\", \"TR\", \"JP\", \"PH\", \"SG\", \"TH\", \"TW\", \"VN\", \"ME\"], \"type\": \"string\", \"description\": \"TFT region\"}}}, \"source\": \"smithery\", \"access_level\": \"read\"}, {\"name\": \"valorant-meta-maps\", \"description\": \"Valorant map meta data\", \"inputSchema\": {\"type\": \"object\", \"required\": [], \"properties\": {}}, \"source\": \"smithery\", \"access_level\": \"read\"}, {\"name\": \"valorant-meta-characters\", \"description\": \"Valorant character meta data\", \"inputSchema\": {\"type\": \"object\", \"required\": [], \"properties\": {}}, \"source\": \"smithery\", \"access_level\": \"read\"}, {\"name\": \"valorant-leaderboard\", \"description\": \"Fetch Valorant leaderboard by region\", \"inputSchema\": {\"type\": \"object\", \"required\": [\"region\"], \"properties\": {\"region\": {\"enum\": [\"AP\", \"BR\", \"EU\", \"KR\", \"LATAM\", \"NA\"], \"type\": \"string\", \"description\": \"Regions in Valorant\"}}}, \"source\": \"smithery\", \"access_level\": \"read\"}, {\"name\": \"valorant-agents-composition-with-map\", \"description\": \"Retrieve agent composition data for a Valorant map.\", \"inputSchema\": {\"type\": \"object\", \"required\": [\"mapId\"], \"properties\": {\"mapId\": {\"type\": \"string\", \"description\": \"Map ID in Valorant\"}}}, \"source\": \"smithery\", \"access_level\": \"read\"}, {\"name\": \"valorant-characters-statistics\", \"description\": \"Retrieve character statistics data for Valorant, optionally filtered by map.\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"mapId\": {\"type\": \"string\", \"description\": \"Optional Map ID in Valorant\"}}}, \"source\": \"smithery\", \"access_level\": \"read\"}, {\"name\": \"valorant-player-match-history\", \"description\": \"Retrieve match history for a Valorant player using their game name and tag line.\", \"inputSchema\": {\"type\": \"object\", \"required\": [\"gameName\", \"tagLine\"], \"properties\": {\"tagLine\": {\"type\": \"string\", \"description\": \"Tag line of the player\"}, \"gameName\": {\"type\": \"string\", \"description\": \"Game name of the player\"}}}, \"source\": \"smithery\", \"access_level\": \"read\"}], \"tools_count\": 21, \"homepage\": \"https://smithery.ai/server/@opgginc/opgg-mcp\", \"url\": \"\", \"topics\": [], \"data_sources\": [\"smithery\"]}", "target": "", "id": "@opgginc/opgg-mcp", "metadata": {"stage": "finance_filter"}}
{"input": "ONLY RESPOND WITH JSON. NO EXPLANATIONS. NO MARKDOWN. NO TEXT OUTSIDE JSON.\n\nAnalyze the MCP server for financial relevance. Look for keywords: payment, banking, credit, loan, finance, money, currency, crypto, investment, trading, portfolio, market, exchange, wallet, account, budget, expense, income, tax, invoice, billing, accounting, insurance, compliance, KYC, AML.\n\nJSON FORMAT (NOTHING ELSE):\n{\n  \"server_name\": \"string\",\n  \"server_id\": \"string\", \n  \"is_finance_llm\": \"yes|no|unclear\",\n  \"confidence\": \"high|medium|low\",\n  \"threat_models\": [],\n  \"analysis_notes\": \"Brief reason\"\n}\n\nIf financial keywords found: is_finance_llm=\"yes\". If not: is_finance_llm=\"no\". If unclear: is_finance_llm=\"unclear\".\n\nRESPOND ONLY WITH JSON.\n\nMCP Server Data:\n{\"server_name\": \"Markdown Rules\", \"server_id\": \"@valstro/markdown-rules-mcp\", \"description\": \"The portable alternative to Cursor Rules and IDE-specific rules.\\n\\nTransform your project documentation into intelligent AI context using standard Markdown files that work across any MCP-compatible AI tool. Escape vendor lock-in and scattered documentation forever.\\n\\nWhy Choose Markdown Rules?\\n\\n\\ud83d\\ude80 Universal Compatibility \\u2014 Write once, use everywhere. Your documentation works with Cursor, Claude Desktop, and any future MCP-enabled AI tool. No vendor lock-in.\\n\\n\\ud83d\\udd17 Smart Dependency Resolution \\u2014 Automatically traverse and include linked files & docs, ensuring AI agents receive complete context for complex projects without manual file hunting or relying on the AI agent to follow links.\\n\\n\\ud83c\\udfaf Precision Context Control \\u2014 Inject exact inline code snippets with line-range embeds (?md-embed=50-100) instead of dumping entire files. Get relevant context, not noise.\\n\\n\\ud83c\\udfd7\\ufe0f Perfect for Complex Codebases \\u2014 Ideal for large projects with custom tooling, internal libraries, or proprietary frameworks that AI models have limited training data for. Provide the context they need to understand your unique architecture.\", \"readme\": \"\", \"tools\": [{\"name\": \"get_relevant_docs\", \"description\": \"Get relevant markdown docs inside this project before answering the user's query to help you reply based on more context.\\n\\n      # Usage Instructions\\n\\n## When to use \\\"get_relevant_docs\\\" tool\\n\\n*   You **must** call the \\\"get_relevant_docs\\\" MCP tool before providing your first response in any new chat session.\\n*   After the initial call in a chat, you should **only** call \\\"get_relevant_docs\\\" again if one of these specific situations occurs:\\n    *   The user explicitly requests it.\\n    *   The user attaches new files.\\n    *   The user's query introduces a completely new topic unrelated to the previous discussion.\\n\\n## How to use \\\"get_relevant_docs\\\" tool\\n\\n*   \\\"attachedFiles\\\": ALWAYS include file paths the user has attached in their query.\\n*   \\\"projectDocs\\\"\\n    *   ONLY include project docs that are VERY RELEVANT to user's query.\\n    *   You must have a high confidence when picking docs that may be relevant.\\n    *   If the user's query is a generic question unrelated to this specific project, leave this empty.\\n    *   Always heavily bias towards leaving this empty.\", \"inputSchema\": {\"type\": \"object\", \"$schema\": \"http://json-schema.org/draft-07/schema#\", \"properties\": {\"projectDocs\": {\"type\": \"array\", \"items\": {\"enum\": [], \"type\": \"string\"}, \"description\": \"A list of docs by their description in the project.\"}, \"attachedFiles\": {\"type\": \"array\", \"items\": {\"type\": \"string\", \"description\": \"The file path to attach\"}, \"description\": \"A list of file paths included in the user's query.\"}}, \"additionalProperties\": false}, \"source\": \"smithery\", \"access_level\": \"read\"}, {\"name\": \"reindex_docs\", \"description\": \"Reindex the docs. Useful for when you want to force a re-index of the docs because there were changes to the docs or the index\", \"inputSchema\": {\"type\": \"object\", \"$schema\": \"http://json-schema.org/draft-07/schema#\", \"properties\": {}, \"additionalProperties\": false}, \"source\": \"smithery\", \"access_level\": \"write\"}, {\"name\": \"list_indexed_docs\", \"description\": \"Print a full count & summary of the docs in the index. Also shows the usage instructions for the `get_relevant_docs` tool. Useful for debugging. Will only show the first 20 docs in each category & a small preview of the content.\", \"inputSchema\": {\"type\": \"object\", \"$schema\": \"http://json-schema.org/draft-07/schema#\", \"properties\": {}, \"additionalProperties\": false}, \"source\": \"smithery\", \"access_level\": \"read\"}], \"tools_count\": 3, \"homepage\": \"https://smithery.ai/server/@valstro/markdown-rules-mcp\", \"url\": \"\", \"topics\": [], \"data_sources\": [\"smithery\"]}", "target": "", "id": "@valstro/markdown-rules-mcp", "metadata": {"stage": "finance_filter"}}
{"input": "ONLY RESPOND WITH JSON. NO EXPLANATIONS. NO MARKDOWN. NO TEXT OUTSIDE JSON.\n\nAnalyze the MCP server for financial relevance. Look for keywords: payment, banking, credit, loan, finance, money, currency, crypto, investment, trading, portfolio, market, exchange, wallet, account, budget, expense, income, tax, invoice, billing, accounting, insurance, compliance, KYC, AML.\n\nJSON FORMAT (NOTHING ELSE):\n{\n  \"server_name\": \"string\",\n  \"server_id\": \"string\", \n  \"is_finance_llm\": \"yes|no|unclear\",\n  \"confidence\": \"high|medium|low\",\n  \"threat_models\": [],\n  \"analysis_notes\": \"Brief reason\"\n}\n\nIf financial keywords found: is_finance_llm=\"yes\". If not: is_finance_llm=\"no\". If unclear: is_finance_llm=\"unclear\".\n\nRESPOND ONLY WITH JSON.\n\nMCP Server Data:\n{\"server_name\": \"Freshservice Integration Server\", \"server_id\": \"@effytech/freshservice_mcp\", \"description\": \"Enable AI assistants to manage IT service tickets and operations by integrating directly with Freshservice. Automate ticket creation, updates, and asset management to streamline your IT support workflows. Accelerate routine IT service tasks with seamless AI-driven interactions.\", \"readme\": \"\", \"tools\": [{\"name\": \"get_ticket_fields\", \"description\": \"Get ticket fields from Freshservice.\", \"inputSchema\": {\"type\": \"object\", \"title\": \"get_ticket_fieldsArguments\", \"properties\": {}}, \"source\": \"smithery\", \"access_level\": \"read\"}, {\"name\": \"get_tickets\", \"description\": \"Get tickets from Freshservice with pagination support.\", \"inputSchema\": {\"type\": \"object\", \"title\": \"get_ticketsArguments\", \"properties\": {\"page\": {\"anyOf\": [{\"type\": \"integer\"}, {\"type\": \"null\"}], \"title\": \"Page\", \"default\": 1}, \"per_page\": {\"anyOf\": [{\"type\": \"integer\"}, {\"type\": \"null\"}], \"title\": \"Per Page\", \"default\": 30}}}, \"source\": \"smithery\", \"access_level\": \"read\"}, {\"name\": \"create_ticket\", \"description\": \"Create a ticket in Freshservice.\", \"inputSchema\": {\"type\": \"object\", \"title\": \"create_ticketArguments\", \"required\": [\"subject\", \"description\", \"source\", \"priority\", \"status\"], \"properties\": {\"email\": {\"anyOf\": [{\"type\": \"string\"}, {\"type\": \"null\"}], \"title\": \"Email\", \"default\": null}, \"source\": {\"anyOf\": [{\"type\": \"integer\"}, {\"type\": \"string\"}], \"title\": \"Source\"}, \"status\": {\"anyOf\": [{\"type\": \"integer\"}, {\"type\": \"string\"}], \"title\": \"Status\"}, \"subject\": {\"type\": \"string\", \"title\": \"Subject\"}, \"priority\": {\"anyOf\": [{\"type\": \"integer\"}, {\"type\": \"string\"}], \"title\": \"Priority\"}, \"description\": {\"type\": \"string\", \"title\": \"Description\"}, \"requester_id\": {\"anyOf\": [{\"type\": \"integer\"}, {\"type\": \"null\"}], \"title\": \"Requester Id\", \"default\": null}, \"custom_fields\": {\"anyOf\": [{\"type\": \"object\", \"additionalProperties\": true}, {\"type\": \"null\"}], \"title\": \"Custom Fields\", \"default\": null}}}, \"source\": \"smithery\", \"access_level\": \"write\"}, {\"name\": \"update_ticket\", \"description\": \"Update a ticket in Freshservice.\", \"inputSchema\": {\"type\": \"object\", \"title\": \"update_ticketArguments\", \"required\": [\"ticket_id\", \"ticket_fields\"], \"properties\": {\"ticket_id\": {\"type\": \"integer\", \"title\": \"Ticket Id\"}, \"ticket_fields\": {\"type\": \"object\", \"title\": \"Ticket Fields\", \"additionalProperties\": true}}}, \"source\": \"smithery\", \"access_level\": \"write\"}, {\"name\": \"filter_tickets\", \"description\": \"Filter the tickets in Freshservice.\", \"inputSchema\": {\"type\": \"object\", \"title\": \"filter_ticketsArguments\", \"required\": [\"query\"], \"properties\": {\"page\": {\"type\": \"integer\", \"title\": \"Page\", \"default\": 1}, \"query\": {\"type\": \"string\", \"title\": \"Query\"}, \"workspace_id\": {\"anyOf\": [{\"type\": \"integer\"}, {\"type\": \"null\"}], \"title\": \"Workspace Id\", \"default\": null}}}, \"source\": \"smithery\", \"access_level\": \"read\"}, {\"name\": \"delete_ticket\", \"description\": \"Delete a ticket in Freshservice.\", \"inputSchema\": {\"type\": \"object\", \"title\": \"delete_ticketArguments\", \"required\": [\"ticket_id\"], \"properties\": {\"ticket_id\": {\"type\": \"integer\", \"title\": \"Ticket Id\"}}}, \"source\": \"smithery\", \"access_level\": \"execute\"}, {\"name\": \"get_ticket_by_id\", \"description\": \"Get a ticket in Freshservice.\", \"inputSchema\": {\"type\": \"object\", \"title\": \"get_ticket_by_idArguments\", \"required\": [\"ticket_id\"], \"properties\": {\"ticket_id\": {\"type\": \"integer\", \"title\": \"Ticket Id\"}}}, \"source\": \"smithery\", \"access_level\": \"read\"}, {\"name\": \"list_service_items\", \"description\": \"Get list of service items from Freshservice.\", \"inputSchema\": {\"type\": \"object\", \"title\": \"list_service_itemsArguments\", \"properties\": {\"page\": {\"anyOf\": [{\"type\": \"integer\"}, {\"type\": \"null\"}], \"title\": \"Page\", \"default\": 1}, \"per_page\": {\"anyOf\": [{\"type\": \"integer\"}, {\"type\": \"null\"}], \"title\": \"Per Page\", \"default\": 30}}}, \"source\": \"smithery\", \"access_level\": \"read\"}, {\"name\": \"get_requested_items\", \"description\": \"Fetch requested items for a specific ticket if the ticket is a service request.\", \"inputSchema\": {\"type\": \"object\", \"title\": \"get_requested_itemsArguments\", \"required\": [\"ticket_id\"], \"properties\": {\"ticket_id\": {\"type\": \"integer\", \"title\": \"Ticket Id\"}}}, \"source\": \"smithery\", \"access_level\": \"read\"}, {\"name\": \"create_service_request\", \"description\": \"Create a service request in Freshservice.\", \"inputSchema\": {\"type\": \"object\", \"title\": \"create_service_requestArguments\", \"required\": [\"display_id\", \"email\"], \"properties\": {\"email\": {\"type\": \"string\", \"title\": \"Email\"}, \"quantity\": {\"type\": \"integer\", \"title\": \"Quantity\", \"default\": 1}, \"display_id\": {\"type\": \"integer\", \"title\": \"Display Id\"}, \"requested_for\": {\"anyOf\": [{\"type\": \"string\"}, {\"type\": \"null\"}], \"title\": \"Requested For\", \"default\": null}}}, \"source\": \"smithery\", \"access_level\": \"write\"}, {\"name\": \"send_ticket_reply\", \"description\": \"\\nSend reply to a ticket in Freshservice.\", \"inputSchema\": {\"type\": \"object\", \"title\": \"send_ticket_replyArguments\", \"required\": [\"ticket_id\", \"body\"], \"properties\": {\"body\": {\"type\": \"string\", \"title\": \"Body\"}, \"user_id\": {\"anyOf\": [{\"type\": \"integer\"}, {\"type\": \"null\"}], \"title\": \"User Id\", \"default\": null}, \"cc_emails\": {\"anyOf\": [{\"type\": \"string\"}, {\"type\": \"array\", \"items\": {\"type\": \"string\"}}, {\"type\": \"null\"}], \"title\": \"Cc Emails\", \"default\": null}, \"ticket_id\": {\"type\": \"integer\", \"title\": \"Ticket Id\"}, \"bcc_emails\": {\"anyOf\": [{\"type\": \"string\"}, {\"type\": \"array\", \"items\": {\"type\": \"string\"}}, {\"type\": \"null\"}], \"title\": \"Bcc Emails\", \"default\": null}, \"from_email\": {\"anyOf\": [{\"type\": \"string\"}, {\"type\": \"null\"}], \"title\": \"From Email\", \"default\": null}}}, \"source\": \"smithery\", \"access_level\": \"execute\"}, {\"name\": \"create_ticket_note\", \"description\": \"Create a note for a ticket in Freshservice.\", \"inputSchema\": {\"type\": \"object\", \"title\": \"create_ticket_noteArguments\", \"required\": [\"ticket_id\", \"body\"], \"properties\": {\"body\": {\"type\": \"string\", \"title\": \"Body\"}, \"ticket_id\": {\"type\": \"integer\", \"title\": \"Ticket Id\"}}}, \"source\": \"smithery\", \"access_level\": \"write\"}, {\"name\": \"update_ticket_conversation\", \"description\": \"Update a conversation for a ticket in Freshservice.\", \"inputSchema\": {\"type\": \"object\", \"title\": \"update_ticket_conversationArguments\", \"required\": [\"conversation_id\", \"body\"], \"properties\": {\"body\": {\"type\": \"string\", \"title\": \"Body\"}, \"conversation_id\": {\"type\": \"integer\", \"title\": \"Conversation Id\"}}}, \"source\": \"smithery\", \"access_level\": \"write\"}, {\"name\": \"list_all_ticket_conversation\", \"description\": \"List all conversation of a ticket in freshservice.\", \"inputSchema\": {\"type\": \"object\", \"title\": \"list_all_ticket_conversationArguments\", \"required\": [\"ticket_id\"], \"properties\": {\"ticket_id\": {\"type\": \"integer\", \"title\": \"Ticket Id\"}}}, \"source\": \"smithery\", \"access_level\": \"read\"}, {\"name\": \"get_all_products\", \"description\": \"List all the products from Freshservice.\", \"inputSchema\": {\"type\": \"object\", \"title\": \"get_all_productsArguments\", \"properties\": {\"page\": {\"anyOf\": [{\"type\": \"integer\"}, {\"type\": \"null\"}], \"title\": \"Page\", \"default\": 1}, \"per_page\": {\"anyOf\": [{\"type\": \"integer\"}, {\"type\": \"null\"}], \"title\": \"Per Page\", \"default\": 30}}}, \"source\": \"smithery\", \"access_level\": \"read\"}, {\"name\": \"get_products_by_id\", \"description\": \"Get product by product ID in Freshservice.\", \"inputSchema\": {\"type\": \"object\", \"title\": \"get_products_by_idArguments\", \"required\": [\"product_id\"], \"properties\": {\"product_id\": {\"type\": \"integer\", \"title\": \"Product Id\"}}}, \"source\": \"smithery\", \"access_level\": \"read\"}, {\"name\": \"create_product\", \"description\": \"Create a product in Freshservice.\", \"inputSchema\": {\"type\": \"object\", \"title\": \"create_productArguments\", \"required\": [\"name\", \"asset_type_id\"], \"properties\": {\"name\": {\"type\": \"string\", \"title\": \"Name\"}, \"status\": {\"anyOf\": [{\"type\": \"string\"}, {\"type\": \"integer\"}, {\"type\": \"null\"}], \"title\": \"Status\", \"default\": null}, \"description\": {\"anyOf\": [{\"type\": \"string\"}, {\"type\": \"null\"}], \"title\": \"Description\", \"default\": null}, \"manufacturer\": {\"anyOf\": [{\"type\": \"string\"}, {\"type\": \"null\"}], \"title\": \"Manufacturer\", \"default\": null}, \"asset_type_id\": {\"type\": \"integer\", \"title\": \"Asset Type Id\"}, \"description_text\": {\"anyOf\": [{\"type\": \"string\"}, {\"type\": \"null\"}], \"title\": \"Description Text\", \"default\": null}, \"mode_of_procurement\": {\"anyOf\": [{\"type\": \"string\"}, {\"type\": \"null\"}], \"title\": \"Mode Of Procurement\", \"default\": null}, \"depreciation_type_id\": {\"anyOf\": [{\"type\": \"integer\"}, {\"type\": \"null\"}], \"title\": \"Depreciation Type Id\", \"default\": null}}}, \"source\": \"smithery\", \"access_level\": \"write\"}, {\"name\": \"update_product\", \"description\": \"Update a product in Freshservice.\", \"inputSchema\": {\"type\": \"object\", \"title\": \"update_productArguments\", \"required\": [\"id\", \"name\", \"asset_type_id\"], \"properties\": {\"id\": {\"type\": \"integer\", \"title\": \"Id\"}, \"name\": {\"type\": \"string\", \"title\": \"Name\"}, \"status\": {\"anyOf\": [{\"type\": \"string\"}, {\"type\": \"integer\"}, {\"type\": \"null\"}], \"title\": \"Status\", \"default\": null}, \"description\": {\"anyOf\": [{\"type\": \"string\"}, {\"type\": \"null\"}], \"title\": \"Description\", \"default\": null}, \"manufacturer\": {\"anyOf\": [{\"type\": \"string\"}, {\"type\": \"null\"}], \"title\": \"Manufacturer\", \"default\": null}, \"asset_type_id\": {\"type\": \"integer\", \"title\": \"Asset Type Id\"}, \"description_text\": {\"anyOf\": [{\"type\": \"string\"}, {\"type\": \"null\"}], \"title\": \"Description Text\", \"default\": null}, \"mode_of_procurement\": {\"anyOf\": [{\"type\": \"string\"}, {\"type\": \"null\"}], \"title\": \"Mode Of Procurement\", \"default\": null}, \"depreciation_type_id\": {\"anyOf\": [{\"type\": \"integer\"}, {\"type\": \"null\"}], \"title\": \"Depreciation Type Id\", \"default\": null}}}, \"source\": \"smithery\", \"access_level\": \"write\"}, {\"name\": \"create_requester\", \"description\": \"Creates a requester in Freshservice.\", \"inputSchema\": {\"type\": \"object\", \"title\": \"create_requesterArguments\", \"required\": [\"first_name\"], \"properties\": {\"address\": {\"anyOf\": [{\"type\": \"string\"}, {\"type\": \"null\"}], \"title\": \"Address\", \"default\": null}, \"language\": {\"anyOf\": [{\"type\": \"string\"}, {\"type\": \"null\"}], \"title\": \"Language\", \"default\": null}, \"job_title\": {\"anyOf\": [{\"type\": \"string\"}, {\"type\": \"null\"}], \"title\": \"Job Title\", \"default\": null}, \"last_name\": {\"anyOf\": [{\"type\": \"string\"}, {\"type\": \"null\"}], \"title\": \"Last Name\", \"default\": null}, \"time_zone\": {\"anyOf\": [{\"type\": \"string\"}, {\"type\": \"null\"}], \"title\": \"Time Zone\", \"default\": null}, \"first_name\": {\"type\": \"string\", \"title\": \"First Name\"}, \"location_id\": {\"anyOf\": [{\"type\": \"integer\"}, {\"type\": \"null\"}], \"title\": \"Location Id\", \"default\": null}, \"time_format\": {\"anyOf\": [{\"type\": \"string\"}, {\"type\": \"null\"}], \"title\": \"Time Format\", \"default\": null}, \"custom_fields\": {\"anyOf\": [{\"type\": \"object\", \"additionalProperties\": true}, {\"type\": \"null\"}], \"title\": \"Custom Fields\", \"default\": null}, \"primary_email\": {\"anyOf\": [{\"type\": \"string\"}, {\"type\": \"null\"}], \"title\": \"Primary Email\", \"default\": null}, \"department_ids\": {\"anyOf\": [{\"type\": \"array\", \"items\": {\"type\": \"integer\"}}, {\"type\": \"null\"}], \"title\": \"Department Ids\", \"default\": null}, \"secondary_emails\": {\"anyOf\": [{\"type\": \"array\", \"items\": {\"type\": \"string\"}}, {\"type\": \"null\"}], \"title\": \"Secondary Emails\", \"default\": null}, \"work_phone_number\": {\"anyOf\": [{\"type\": \"string\"}, {\"type\": \"null\"}], \"title\": \"Work Phone Number\", \"default\": null}, \"mobile_phone_number\": {\"anyOf\": [{\"type\": \"string\"}, {\"type\": \"null\"}], \"title\": \"Mobile Phone Number\", \"default\": null}, \"reporting_manager_id\": {\"anyOf\": [{\"type\": \"integer\"}, {\"type\": \"null\"}], \"title\": \"Reporting Manager Id\", \"default\": null}, \"background_information\": {\"anyOf\": [{\"type\": \"string\"}, {\"type\": \"null\"}], \"title\": \"Background Information\", \"default\": null}, \"can_see_all_tickets_from_associated_departments\": {\"anyOf\": [{\"type\": \"boolean\"}, {\"type\": \"null\"}], \"title\": \"Can See All Tickets From Associated Departments\", \"default\": null}}}, \"source\": \"smithery\", \"access_level\": \"write\"}, {\"name\": \"get_all_requesters\", \"description\": \"Fetch all requesters from Freshservice.\", \"inputSchema\": {\"type\": \"object\", \"title\": \"get_all_requestersArguments\", \"properties\": {\"page\": {\"type\": \"integer\", \"title\": \"Page\", \"default\": 1}, \"per_page\": {\"type\": \"integer\", \"title\": \"Per Page\", \"default\": 30}}}, \"source\": \"smithery\", \"access_level\": \"read\"}, {\"name\": \"get_requester_id\", \"description\": \"Get requester by ID in Freshservice.\", \"inputSchema\": {\"type\": \"object\", \"title\": \"get_requester_idArguments\", \"required\": [\"requester_id\"], \"properties\": {\"requester_id\": {\"type\": \"integer\", \"title\": \"Requester Id\"}}}, \"source\": \"smithery\", \"access_level\": \"read\"}, {\"name\": \"list_all_requester_fields\", \"description\": \"List all requester fields in Freshservice.\", \"inputSchema\": {\"type\": \"object\", \"title\": \"list_all_requester_fieldsArguments\", \"properties\": {}}, \"source\": \"smithery\", \"access_level\": \"read\"}, {\"name\": \"update_requester\", \"description\": \"Update a requester in Freshservice.\", \"inputSchema\": {\"type\": \"object\", \"title\": \"update_requesterArguments\", \"required\": [\"requester_id\"], \"properties\": {\"address\": {\"anyOf\": [{\"type\": \"string\"}, {\"type\": \"null\"}], \"title\": \"Address\", \"default\": null}, \"language\": {\"anyOf\": [{\"type\": \"string\"}, {\"type\": \"null\"}], \"title\": \"Language\", \"default\": null}, \"job_title\": {\"anyOf\": [{\"type\": \"string\"}, {\"type\": \"null\"}], \"title\": \"Job Title\", \"default\": null}, \"last_name\": {\"anyOf\": [{\"type\": \"string\"}, {\"type\": \"null\"}], \"title\": \"Last Name\", \"default\": null}, \"time_zone\": {\"anyOf\": [{\"type\": \"string\"}, {\"type\": \"null\"}], \"title\": \"Time Zone\", \"default\": null}, \"first_name\": {\"anyOf\": [{\"type\": \"string\"}, {\"type\": \"null\"}], \"title\": \"First Name\", \"default\": null}, \"location_id\": {\"anyOf\": [{\"type\": \"integer\"}, {\"type\": \"null\"}], \"title\": \"Location Id\", \"default\": null}, \"time_format\": {\"anyOf\": [{\"type\": \"string\"}, {\"type\": \"null\"}], \"title\": \"Time Format\", \"default\": null}, \"requester_id\": {\"type\": \"integer\", \"title\": \"Requester Id\"}, \"custom_fields\": {\"anyOf\": [{\"type\": \"object\", \"additionalProperties\": true}, {\"type\": \"null\"}], \"title\": \"Custom Fields\", \"default\": null}, \"primary_email\": {\"anyOf\": [{\"type\": \"string\"}, {\"type\": \"null\"}], \"title\": \"Primary Email\", \"default\": null}, \"department_ids\": {\"anyOf\": [{\"type\": \"array\", \"items\": {\"type\": \"integer\"}}, {\"type\": \"null\"}], \"title\": \"Department Ids\", \"default\": null}, \"secondary_emails\": {\"anyOf\": [{\"type\": \"array\", \"items\": {\"type\": \"string\"}}, {\"type\": \"null\"}], \"title\": \"Secondary Emails\", \"default\": null}, \"work_phone_number\": {\"anyOf\": [{\"type\": \"integer\"}, {\"type\": \"null\"}], \"title\": \"Work Phone Number\", \"default\": null}, \"mobile_phone_number\": {\"anyOf\": [{\"type\": \"integer\"}, {\"type\": \"null\"}], \"title\": \"Mobile Phone Number\", \"default\": null}, \"reporting_manager_id\": {\"anyOf\": [{\"type\": \"integer\"}, {\"type\": \"null\"}], \"title\": \"Reporting Manager Id\", \"default\": null}, \"background_information\": {\"anyOf\": [{\"type\": \"string\"}, {\"type\": \"null\"}], \"title\": \"Background Information\", \"default\": null}, \"can_see_all_tickets_from_associated_departments\": {\"anyOf\": [{\"type\": \"boolean\"}, {\"type\": \"null\"}], \"title\": \"Can See All Tickets From Associated Departments\", \"default\": false}}}, \"source\": \"smithery\", \"access_level\": \"write\"}, {\"name\": \"filter_requesters\", \"description\": \"Filter requesters in Freshservice.\", \"inputSchema\": {\"type\": \"object\", \"title\": \"filter_requestersArguments\", \"required\": [\"query\"], \"properties\": {\"query\": {\"type\": \"string\", \"title\": \"Query\"}, \"include_agents\": {\"type\": \"boolean\", \"title\": \"Include Agents\", \"default\": false}}}, \"source\": \"smithery\", \"access_level\": \"read\"}, {\"name\": \"create_agent\", \"description\": \"Create a new agent in Freshservice.\", \"inputSchema\": {\"type\": \"object\", \"title\": \"create_agentArguments\", \"required\": [\"first_name\"], \"properties\": {\"email\": {\"type\": \"string\", \"title\": \"Email\", \"default\": null}, \"job_title\": {\"anyOf\": [{\"type\": \"string\"}, {\"type\": \"null\"}], \"title\": \"Job Title\", \"default\": null}, \"last_name\": {\"anyOf\": [{\"type\": \"string\"}, {\"type\": \"null\"}], \"title\": \"Last Name\", \"default\": null}, \"first_name\": {\"type\": \"string\", \"title\": \"First Name\"}, \"occasional\": {\"anyOf\": [{\"type\": \"boolean\"}, {\"type\": \"null\"}], \"title\": \"Occasional\", \"default\": false}, \"work_phone_number\": {\"anyOf\": [{\"type\": \"integer\"}, {\"type\": \"null\"}], \"title\": \"Work Phone Number\", \"default\": null}, \"mobile_phone_number\": {\"anyOf\": [{\"type\": \"integer\"}, {\"type\": \"null\"}], \"title\": \"Mobile Phone Number\", \"default\": null}}}, \"source\": \"smithery\", \"access_level\": \"write\"}, {\"name\": \"get_agent\", \"description\": \"Get agent by id in Freshservice.\", \"inputSchema\": {\"type\": \"object\", \"title\": \"get_agentArguments\", \"required\": [\"agent_id\"], \"properties\": {\"agent_id\": {\"type\": \"integer\", \"title\": \"Agent Id\"}}}, \"source\": \"smithery\", \"access_level\": \"read\"}, {\"name\": \"get_all_agents\", \"description\": \"Fetch agents from Freshservice.\", \"inputSchema\": {\"type\": \"object\", \"title\": \"get_all_agentsArguments\", \"properties\": {\"page\": {\"type\": \"integer\", \"title\": \"Page\", \"default\": 1}, \"per_page\": {\"type\": \"integer\", \"title\": \"Per Page\", \"default\": 30}}}, \"source\": \"smithery\", \"access_level\": \"read\"}, {\"name\": \"filter_agents\", \"description\": \"Filter Freshservice agents based on a query.\", \"inputSchema\": {\"type\": \"object\", \"title\": \"filter_agentsArguments\", \"required\": [\"query\"], \"properties\": {\"query\": {\"type\": \"string\", \"title\": \"Query\"}}}, \"source\": \"smithery\", \"access_level\": \"read\"}, {\"name\": \"update_agent\", \"description\": \"Update the agent details in the Freshservice.\", \"inputSchema\": {\"type\": \"object\", \"title\": \"update_agentArguments\", \"required\": [\"agent_id\"], \"properties\": {\"email\": {\"type\": \"string\", \"title\": \"email\", \"default\": null}, \"address\": {\"type\": \"string\", \"title\": \"address\", \"default\": null}, \"agent_id\": {\"type\": \"string\", \"title\": \"agent_id\"}, \"language\": {\"type\": \"string\", \"title\": \"language\", \"default\": null}, \"time_zone\": {\"type\": \"string\", \"title\": \"time_zone\", \"default\": null}, \"occasional\": {\"type\": \"string\", \"title\": \"occasional\", \"default\": null}, \"location_id\": {\"type\": \"string\", \"title\": \"location_id\", \"default\": null}, \"time_format\": {\"type\": \"string\", \"title\": \"time_format\", \"default\": null}, \"department_ids\": {\"type\": \"string\", \"title\": \"department_ids\", \"default\": null}, \"scoreboard_level_id\": {\"type\": \"string\", \"title\": \"scoreboard_level_id\", \"default\": null}, \"reporting_manager_id\": {\"type\": \"string\", \"title\": \"reporting_manager_id\", \"default\": null}, \"background_information\": {\"type\": \"string\", \"title\": \"background_information\", \"default\": null}, \"can_see_all_tickets_from_associated_departments\": {\"type\": \"string\", \"title\": \"can_see_all_tickets_from_associated_departments\", \"default\": null}}}, \"source\": \"smithery\", \"access_level\": \"write\"}, {\"name\": \"get_agent_fields\", \"description\": \"Get all agent fields in Freshservice.\", \"inputSchema\": {\"type\": \"object\", \"title\": \"get_agent_fieldsArguments\", \"properties\": {}}, \"source\": \"smithery\", \"access_level\": \"read\"}, {\"name\": \"get_all_agent_groups\", \"description\": \"Get all agent groups in Freshservice.\", \"inputSchema\": {\"type\": \"object\", \"title\": \"get_all_agent_groupsArguments\", \"properties\": {}}, \"source\": \"smithery\", \"access_level\": \"read\"}, {\"name\": \"getAgentGroupById\", \"description\": \"Get agent groups by its group id in Freshservice.\", \"inputSchema\": {\"type\": \"object\", \"title\": \"getAgentGroupByIdArguments\", \"required\": [\"group_id\"], \"properties\": {\"group_id\": {\"type\": \"integer\", \"title\": \"Group Id\"}}}, \"source\": \"smithery\", \"access_level\": \"read\"}, {\"name\": \"add_requester_to_group\", \"description\": \"Add a requester to a manual requester group in Freshservice.\", \"inputSchema\": {\"type\": \"object\", \"title\": \"add_requester_to_groupArguments\", \"required\": [\"group_id\", \"requester_id\"], \"properties\": {\"group_id\": {\"type\": \"integer\", \"title\": \"Group Id\"}, \"requester_id\": {\"type\": \"integer\", \"title\": \"Requester Id\"}}}, \"source\": \"smithery\", \"access_level\": \"write\"}, {\"name\": \"create_group\", \"description\": \"Create a group in Freshservice.\", \"inputSchema\": {\"type\": \"object\", \"title\": \"create_groupArguments\", \"required\": [\"group_data\"], \"properties\": {\"group_data\": {\"type\": \"object\", \"title\": \"Group Data\", \"additionalProperties\": true}}}, \"source\": \"smithery\", \"access_level\": \"write\"}, {\"name\": \"update_group\", \"description\": \"Update a group in Freshservice.\", \"inputSchema\": {\"type\": \"object\", \"title\": \"update_groupArguments\", \"required\": [\"group_id\", \"group_fields\"], \"properties\": {\"group_id\": {\"type\": \"integer\", \"title\": \"Group Id\"}, \"group_fields\": {\"type\": \"object\", \"title\": \"Group Fields\", \"additionalProperties\": true}}}, \"source\": \"smithery\", \"access_level\": \"write\"}, {\"name\": \"get_all_requester_groups\", \"description\": \"Get all requester groups in Freshservice.\", \"inputSchema\": {\"type\": \"object\", \"title\": \"get_all_requester_groupsArguments\", \"properties\": {\"page\": {\"anyOf\": [{\"type\": \"integer\"}, {\"type\": \"null\"}], \"title\": \"Page\", \"default\": 1}, \"per_page\": {\"anyOf\": [{\"type\": \"integer\"}, {\"type\": \"null\"}], \"title\": \"Per Page\", \"default\": 30}}}, \"source\": \"smithery\", \"access_level\": \"read\"}, {\"name\": \"get_requester_groups_by_id\", \"description\": \"Get requester groups in Freshservice.\", \"inputSchema\": {\"type\": \"object\", \"title\": \"get_requester_groups_by_idArguments\", \"required\": [\"requester_group_id\"], \"properties\": {\"requester_group_id\": {\"type\": \"integer\", \"title\": \"Requester Group Id\"}}}, \"source\": \"smithery\", \"access_level\": \"read\"}, {\"name\": \"create_requester_group\", \"description\": \"Create a requester group in Freshservice.\", \"inputSchema\": {\"type\": \"object\", \"title\": \"create_requester_groupArguments\", \"required\": [\"name\"], \"properties\": {\"name\": {\"type\": \"string\", \"title\": \"Name\"}, \"description\": {\"anyOf\": [{\"type\": \"string\"}, {\"type\": \"null\"}], \"title\": \"Description\", \"default\": null}}}, \"source\": \"smithery\", \"access_level\": \"write\"}, {\"name\": \"update_requester_group\", \"description\": \"Update an requester group in Freshservice.\", \"inputSchema\": {\"type\": \"object\", \"title\": \"update_requester_groupArguments\", \"required\": [\"id\"], \"properties\": {\"id\": {\"type\": \"integer\", \"title\": \"Id\"}, \"name\": {\"anyOf\": [{\"type\": \"string\"}, {\"type\": \"null\"}], \"title\": \"Name\", \"default\": null}, \"description\": {\"anyOf\": [{\"type\": \"string\"}, {\"type\": \"null\"}], \"title\": \"Description\", \"default\": null}}}, \"source\": \"smithery\", \"access_level\": \"write\"}, {\"name\": \"list_requester_group_members\", \"description\": \"List all members of a requester group in Freshservice.\", \"inputSchema\": {\"type\": \"object\", \"title\": \"list_requester_group_membersArguments\", \"required\": [\"group_id\"], \"properties\": {\"group_id\": {\"type\": \"integer\", \"title\": \"Group Id\"}}}, \"source\": \"smithery\", \"access_level\": \"read\"}, {\"name\": \"get_all_canned_response\", \"description\": \"List all canned response in Freshservice.\", \"inputSchema\": {\"type\": \"object\", \"title\": \"get_all_canned_responseArguments\", \"properties\": {}}, \"source\": \"smithery\", \"access_level\": \"read\"}, {\"name\": \"get_canned_response\", \"description\": \"Get a canned response in Freshservice.\", \"inputSchema\": {\"type\": \"object\", \"title\": \"get_canned_responseArguments\", \"required\": [\"id\"], \"properties\": {\"id\": {\"type\": \"integer\", \"title\": \"Id\"}}}, \"source\": \"smithery\", \"access_level\": \"read\"}, {\"name\": \"list_all_canned_response_folder\", \"description\": \"List all canned response of a folder in Freshservice.\", \"inputSchema\": {\"type\": \"object\", \"title\": \"list_all_canned_response_folderArguments\", \"properties\": {}}, \"source\": \"smithery\", \"access_level\": \"read\"}, {\"name\": \"list_canned_response_folder\", \"description\": \"List canned response folder in Freshservice.\", \"inputSchema\": {\"type\": \"object\", \"title\": \"list_canned_response_folderArguments\", \"required\": [\"id\"], \"properties\": {\"id\": {\"type\": \"integer\", \"title\": \"Id\"}}}, \"source\": \"smithery\", \"access_level\": \"read\"}, {\"name\": \"list_all_workspaces\", \"description\": \"List all workspaces in Freshservice.\", \"inputSchema\": {\"type\": \"object\", \"title\": \"list_all_workspacesArguments\", \"properties\": {}}, \"source\": \"smithery\", \"access_level\": \"read\"}, {\"name\": \"get_workspace\", \"description\": \"Get a workspace by its ID in Freshservice.\", \"inputSchema\": {\"type\": \"object\", \"title\": \"get_workspaceArguments\", \"required\": [\"id\"], \"properties\": {\"id\": {\"type\": \"integer\", \"title\": \"Id\"}}}, \"source\": \"smithery\", \"access_level\": \"read\"}, {\"name\": \"get_all_solution_category\", \"description\": \"Get all solution category in Freshservice.\", \"inputSchema\": {\"type\": \"object\", \"title\": \"get_all_solution_categoryArguments\", \"properties\": {}}, \"source\": \"smithery\", \"access_level\": \"read\"}, {\"name\": \"get_solution_category\", \"description\": \"Get solution category by its ID in Freshservice.\", \"inputSchema\": {\"type\": \"object\", \"title\": \"get_solution_categoryArguments\", \"required\": [\"id\"], \"properties\": {\"id\": {\"type\": \"integer\", \"title\": \"Id\"}}}, \"source\": \"smithery\", \"access_level\": \"read\"}, {\"name\": \"create_solution_category\", \"description\": \"Create a new solution category in Freshservice.\", \"inputSchema\": {\"type\": \"object\", \"title\": \"create_solution_categoryArguments\", \"required\": [\"name\"], \"properties\": {\"name\": {\"type\": \"string\", \"title\": \"Name\"}, \"description\": {\"type\": \"string\", \"title\": \"Description\", \"default\": null}, \"workspace_id\": {\"type\": \"integer\", \"title\": \"Workspace Id\", \"default\": null}}}, \"source\": \"smithery\", \"access_level\": \"write\"}, {\"name\": \"update_solution_category\", \"description\": \"Update a solution category in Freshservice.\", \"inputSchema\": {\"type\": \"object\", \"title\": \"update_solution_categoryArguments\", \"required\": [\"category_id\", \"name\"], \"properties\": {\"name\": {\"type\": \"string\", \"title\": \"Name\"}, \"category_id\": {\"type\": \"integer\", \"title\": \"Category Id\"}, \"description\": {\"type\": \"string\", \"title\": \"Description\", \"default\": null}, \"workspace_id\": {\"type\": \"integer\", \"title\": \"Workspace Id\", \"default\": null}, \"default_category\": {\"type\": \"boolean\", \"title\": \"Default Category\", \"default\": null}}}, \"source\": \"smithery\", \"access_level\": \"write\"}, {\"name\": \"get_list_of_solution_folder\", \"description\": \"Get list of solution folder by its ID in Freshservice.\", \"inputSchema\": {\"type\": \"object\", \"title\": \"get_list_of_solution_folderArguments\", \"required\": [\"id\"], \"properties\": {\"id\": {\"type\": \"integer\", \"title\": \"Id\"}}}, \"source\": \"smithery\", \"access_level\": \"read\"}, {\"name\": \"get_solution_folder\", \"description\": \"Get solution folder by its ID in Freshservice.\", \"inputSchema\": {\"type\": \"object\", \"title\": \"get_solution_folderArguments\", \"required\": [\"id\"], \"properties\": {\"id\": {\"type\": \"integer\", \"title\": \"Id\"}}}, \"source\": \"smithery\", \"access_level\": \"read\"}, {\"name\": \"get_list_of_solution_article\", \"description\": \"Get list of solution article in Freshservice.\", \"inputSchema\": {\"type\": \"object\", \"title\": \"get_list_of_solution_articleArguments\", \"required\": [\"id\"], \"properties\": {\"id\": {\"type\": \"integer\", \"title\": \"Id\"}}}, \"source\": \"smithery\", \"access_level\": \"read\"}, {\"name\": \"get_solution_article\", \"description\": \"Get solution article by id in Freshservice.\", \"inputSchema\": {\"type\": \"object\", \"title\": \"get_solution_articleArguments\", \"required\": [\"id\"], \"properties\": {\"id\": {\"type\": \"integer\", \"title\": \"Id\"}}}, \"source\": \"smithery\", \"access_level\": \"read\"}, {\"name\": \"create_solution_article\", \"description\": \"Create a new solution article in Freshservice.\", \"inputSchema\": {\"type\": \"object\", \"title\": \"create_solution_articleArguments\", \"required\": [\"title\", \"description\", \"folder_id\"], \"properties\": {\"tags\": {\"anyOf\": [{\"type\": \"array\", \"items\": {\"type\": \"string\"}}, {\"type\": \"null\"}], \"title\": \"Tags\", \"default\": null}, \"title\": {\"type\": \"string\", \"title\": \"Title\"}, \"status\": {\"anyOf\": [{\"type\": \"integer\"}, {\"type\": \"null\"}], \"title\": \"Status\", \"default\": 1}, \"keywords\": {\"anyOf\": [{\"type\": \"array\", \"items\": {\"type\": \"string\"}}, {\"type\": \"null\"}], \"title\": \"Keywords\", \"default\": null}, \"folder_id\": {\"type\": \"integer\", \"title\": \"Folder Id\"}, \"description\": {\"type\": \"string\", \"title\": \"Description\"}, \"review_date\": {\"anyOf\": [{\"type\": \"string\"}, {\"type\": \"null\"}], \"title\": \"Review Date\", \"default\": null}, \"article_type\": {\"anyOf\": [{\"type\": \"integer\"}, {\"type\": \"null\"}], \"title\": \"Article Type\", \"default\": 1}}}, \"source\": \"smithery\", \"access_level\": \"write\"}, {\"name\": \"update_solution_article\", \"description\": \"Update a solution article in Freshservice.\", \"inputSchema\": {\"type\": \"object\", \"title\": \"update_solution_articleArguments\", \"required\": [\"article_id\"], \"properties\": {\"tags\": {\"anyOf\": [{\"type\": \"array\", \"items\": {\"type\": \"string\"}}, {\"type\": \"null\"}], \"title\": \"Tags\", \"default\": null}, \"title\": {\"anyOf\": [{\"type\": \"string\"}, {\"type\": \"null\"}], \"title\": \"Title\", \"default\": null}, \"status\": {\"anyOf\": [{\"type\": \"integer\"}, {\"type\": \"null\"}], \"title\": \"Status\", \"default\": null}, \"keywords\": {\"anyOf\": [{\"type\": \"array\", \"items\": {\"type\": \"string\"}}, {\"type\": \"null\"}], \"title\": \"Keywords\", \"default\": null}, \"folder_id\": {\"anyOf\": [{\"type\": \"integer\"}, {\"type\": \"null\"}], \"title\": \"Folder Id\", \"default\": null}, \"article_id\": {\"type\": \"integer\", \"title\": \"Article Id\"}, \"description\": {\"anyOf\": [{\"type\": \"string\"}, {\"type\": \"null\"}], \"title\": \"Description\", \"default\": null}, \"review_date\": {\"anyOf\": [{\"type\": \"string\"}, {\"type\": \"null\"}], \"title\": \"Review Date\", \"default\": null}, \"article_type\": {\"anyOf\": [{\"type\": \"integer\"}, {\"type\": \"null\"}], \"title\": \"Article Type\", \"default\": null}}}, \"source\": \"smithery\", \"access_level\": \"write\"}, {\"name\": \"create_solution_folder\", \"description\": \"Create a new folder under a solution category in Freshservice.\", \"inputSchema\": {\"type\": \"object\", \"title\": \"create_solution_folderArguments\", \"required\": [\"name\", \"category_id\", \"department_ids\"], \"properties\": {\"name\": {\"type\": \"string\", \"title\": \"Name\"}, \"visibility\": {\"type\": \"integer\", \"title\": \"Visibility\", \"default\": 4}, \"category_id\": {\"type\": \"integer\", \"title\": \"Category Id\"}, \"description\": {\"anyOf\": [{\"type\": \"string\"}, {\"type\": \"null\"}], \"title\": \"Description\", \"default\": null}, \"department_ids\": {\"type\": \"array\", \"items\": {\"type\": \"integer\"}, \"title\": \"Department Ids\"}}}, \"source\": \"smithery\", \"access_level\": \"write\"}, {\"name\": \"update_solution_folder\", \"description\": \"Update an existing solution folder's details in Freshservice.\", \"inputSchema\": {\"type\": \"object\", \"title\": \"update_solution_folderArguments\", \"required\": [\"id\"], \"properties\": {\"id\": {\"type\": \"integer\", \"title\": \"Id\"}, \"name\": {\"anyOf\": [{\"type\": \"string\"}, {\"type\": \"null\"}], \"title\": \"Name\", \"default\": null}, \"visibility\": {\"anyOf\": [{\"type\": \"integer\"}, {\"type\": \"null\"}], \"title\": \"Visibility\", \"default\": null}, \"description\": {\"anyOf\": [{\"type\": \"string\"}, {\"type\": \"null\"}], \"title\": \"Description\", \"default\": null}}}, \"source\": \"smithery\", \"access_level\": \"write\"}, {\"name\": \"publish_solution_article\", \"description\": \"Publish a solution article in Freshservice.\", \"inputSchema\": {\"type\": \"object\", \"title\": \"publish_solution_articleArguments\", \"required\": [\"article_id\"], \"properties\": {\"article_id\": {\"type\": \"integer\", \"title\": \"Article Id\"}}}, \"source\": \"smithery\", \"access_level\": \"read\"}], \"tools_count\": 59, \"homepage\": \"https://smithery.ai/server/@effytech/freshservice_mcp\", \"url\": \"\", \"topics\": [], \"data_sources\": [\"smithery\"]}", "target": "", "id": "@effytech/freshservice_mcp", "metadata": {"stage": "finance_filter"}}
{"input": "ONLY RESPOND WITH JSON. NO EXPLANATIONS. NO MARKDOWN. NO TEXT OUTSIDE JSON.\n\nAnalyze the MCP server for financial relevance. Look for keywords: payment, banking, credit, loan, finance, money, currency, crypto, investment, trading, portfolio, market, exchange, wallet, account, budget, expense, income, tax, invoice, billing, accounting, insurance, compliance, KYC, AML.\n\nJSON FORMAT (NOTHING ELSE):\n{\n  \"server_name\": \"string\",\n  \"server_id\": \"string\", \n  \"is_finance_llm\": \"yes|no|unclear\",\n  \"confidence\": \"high|medium|low\",\n  \"threat_models\": [],\n  \"analysis_notes\": \"Brief reason\"\n}\n\nIf financial keywords found: is_finance_llm=\"yes\". If not: is_finance_llm=\"no\". If unclear: is_finance_llm=\"unclear\".\n\nRESPOND ONLY WITH JSON.\n\nMCP Server Data:\n{\"server_name\": \"COTI Blockchain MCP Server\", \"server_id\": \"@davibauer/coti-mcp\", \"description\": \"This tool lets you play with the COTI blockchain right from your AI assistant.\", \"readme\": \"\", \"tools\": [{\"name\": \"change_default_account\", \"description\": \"Change the default account used for COTI blockchain operations. This allows switching between different accounts configured in the environment. The account must be configured in the environment variables with corresponding private and AES keys. Returns the new default account address upon successful change.\", \"inputSchema\": {\"type\": \"object\", \"required\": [\"account_address\"], \"properties\": {\"account_address\": {\"type\": \"string\", \"description\": \"COTI account address to set as default, e.g., 0x0D7C5C1DA069fd7C1fAFBeb922482B2C7B15D273\"}}}, \"source\": \"smithery\", \"access_level\": \"write\"}, {\"name\": \"create_account\", \"description\": \"Create a new COTI account with a randomly generated private key and AES key. Returns the new account address, private key, and AES key.\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"set_as_default\": {\"type\": \"boolean\", \"description\": \"Optional, whether to set the new account as the default account. Default is false.\"}}}, \"source\": \"smithery\", \"access_level\": \"write\"}, {\"name\": \"decrypt_value\", \"description\": \"Decrypt a value using the COTI AES key. Requires a ciphertext as input. Returns the decrypted value.\", \"inputSchema\": {\"type\": \"object\", \"required\": [\"ciphertext\"], \"properties\": {\"ciphertext\": {\"type\": \"string\", \"description\": \"Ciphertext to decrypt\"}}}, \"source\": \"smithery\", \"access_level\": \"read\"}, {\"name\": \"encrypt_value\", \"description\": \"Encrypt a value using the COTI AES key. This is used for encrypting values to be sent to another address. Requires a value, contract address, and function selector as input. Returns the signature.\", \"inputSchema\": {\"type\": \"object\", \"required\": [\"message\", \"contract_address\", \"function_selector\"], \"properties\": {\"message\": {\"type\": \"string\", \"description\": \"Message to encrypt\"}, \"contract_address\": {\"type\": \"string\", \"description\": \"Contract address\"}, \"function_selector\": {\"type\": \"string\", \"description\": \"Function selector. To get the function selector, use the keccak256 hash of the function signature. For instance, for the transfer function of an ERC20 token, the function selector is '0xa9059cbb'.\"}}}, \"source\": \"smithery\", \"access_level\": \"write\"}, {\"name\": \"export_accounts\", \"description\": \"Backup all available COTI accounts and export them as a JSON string for future import. Returns a JSON string that can be copied and used for importing later.\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"account_addresses\": {\"type\": \"array\", \"items\": {\"type\": \"string\"}, \"description\": \"Optional list of account addresses to export. If not provided, all accounts will be exported.\"}, \"include_sensitive_data\": {\"type\": \"boolean\", \"description\": \"Whether to include sensitive data (private keys and AES keys) in the output. Default is true.\"}}}, \"source\": \"smithery\", \"access_level\": \"write\"}, {\"name\": \"generate_aes_key\", \"description\": \"Generate a new AES key for the current account. Returns the AES key.\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"account_address\": {\"type\": \"string\", \"description\": \"The address of the account to generate the AES key for.\"}}}, \"source\": \"smithery\", \"access_level\": \"write\"}, {\"name\": \"import_accounts\", \"description\": \"Import COTI accounts from a JSON backup string previously created with the export_accounts tool.\", \"inputSchema\": {\"type\": \"object\", \"required\": [\"backup_data\"], \"properties\": {\"backup_data\": {\"type\": \"string\", \"description\": \"The JSON backup string containing the accounts to import. Example:\\n\\n{\\n    \\\"timestamp\\\": \\\"2025-06-03T17:18:55.123Z\\\",\\n    \\\"accounts\\\": [\\n        {\\n            \\\"address\\\": \\\"0x123...\\\",\\n            \\\"private_key\\\": \\\"0x456...\\\",\\n            \\\"aes_key\\\": \\\"0x789...\\\",\\n            \\\"is_default\\\": true\\n        },\\n        ...\\n    ]\\n}\\n\"}, \"merge_with_existing\": {\"type\": \"boolean\", \"description\": \"Whether to merge with existing accounts or replace them. Default is true (merge).\"}, \"set_default_account\": {\"type\": \"string\", \"description\": \"Optional address to set as the default account after import. If not provided, will use the default from the backup.\"}}}, \"source\": \"smithery\", \"access_level\": \"write\"}, {\"name\": \"list_accounts\", \"description\": \"List all available COTI accounts configured in the environment. Returns the account addresses, current default account, and masked versions of the private and AES keys.\", \"inputSchema\": {\"type\": \"object\", \"properties\": {}}, \"source\": \"smithery\", \"access_level\": \"write\"}, {\"name\": \"sign_message\", \"description\": \"Sign a message using the COTI private key. This creates a cryptographic signature that proves the message was signed by the owner of the private key. Requires a message to sign as input. Returns the signature.\", \"inputSchema\": {\"type\": \"object\", \"required\": [\"message\"], \"properties\": {\"message\": {\"type\": \"string\", \"description\": \"Message to sign\"}}}, \"source\": \"smithery\", \"access_level\": \"write\"}, {\"name\": \"verify_signature\", \"description\": \"Verify a message signature and recover the address that signed it. This is used to determine who signed a specific message. Requires the original message and the signature as input. Returns the address that created the signature.\", \"inputSchema\": {\"type\": \"object\", \"required\": [\"message\", \"signature\"], \"properties\": {\"message\": {\"type\": \"string\", \"description\": \"Original message that was signed\"}, \"signature\": {\"type\": \"string\", \"description\": \"Signature to verify (hexadecimal string)\"}}}, \"source\": \"smithery\", \"access_level\": \"write\"}, {\"name\": \"approve_erc20_spender\", \"description\": \"Approve another address to spend tokens on behalf of the owner. This is used for allowing another address (like a contract) to transfer your tokens. Requires token contract address, spender address, and amount as input. Returns the transaction hash upon successful approval.\", \"inputSchema\": {\"type\": \"object\", \"required\": [\"token_address\", \"spender_address\", \"amount_wei\"], \"properties\": {\"gas_limit\": {\"type\": \"string\", \"description\": \"Optional gas limit for the transaction\"}, \"amount_wei\": {\"type\": \"string\", \"description\": \"Amount of tokens to approve (in Wei)\"}, \"token_address\": {\"type\": \"string\", \"description\": \"ERC20 token contract address on COTI blockchain\"}, \"spender_address\": {\"type\": \"string\", \"description\": \"Address to approve as spender, e.g., 0x0D7C5C1DA069fd7C1fAFBeb922482B2C7B15D273\"}}}, \"source\": \"smithery\", \"access_level\": \"write\"}, {\"name\": \"deploy_private_erc20_contract\", \"description\": \"Deploy a new standard private ERC20 token contract on the COTI blockchain. This creates a new private token with the specified name, symbol, and decimals. Returns the deployed contract address upon successful deployment.\", \"inputSchema\": {\"type\": \"object\", \"required\": [\"name\", \"symbol\", \"decimals\"], \"properties\": {\"name\": {\"type\": \"string\", \"description\": \"Name of the token\"}, \"symbol\": {\"type\": \"string\", \"description\": \"Symbol of the token (typically 3-5 characters)\"}, \"decimals\": {\"type\": \"number\", \"description\": \"Number of decimals for the token\"}, \"gas_limit\": {\"type\": \"string\", \"description\": \"Optional gas limit for the deployment transaction\"}}}, \"source\": \"smithery\", \"access_level\": \"execute\"}, {\"name\": \"get_erc20_allowance\", \"description\": \"Check how many tokens a spender is allowed to use. This is used for checking the current allowance a spender has for an owner's tokens. Requires token contract address, owner address, and spender address as input. Returns the allowance amount.\", \"inputSchema\": {\"type\": \"object\", \"required\": [\"token_address\", \"owner_address\", \"spender_address\"], \"properties\": {\"owner_address\": {\"type\": \"string\", \"description\": \"Address of the token owner\"}, \"token_address\": {\"type\": \"string\", \"description\": \"ERC20 token contract address on COTI blockchain\"}, \"spender_address\": {\"type\": \"string\", \"description\": \"Address of the spender to check allowance for\"}}}, \"source\": \"smithery\", \"access_level\": \"write\"}, {\"name\": \"get_private_erc20_balance\", \"description\": \"Get the balance of a private ERC20 token on the COTI blockchain. This is used for checking the current balance of a private token for a COTI account. Requires a COTI account address and token contract address as input. Returns the decrypted token balance.\", \"inputSchema\": {\"type\": \"object\", \"required\": [\"account_address\", \"token_address\"], \"properties\": {\"token_address\": {\"type\": \"string\", \"description\": \"ERC20 token contract address on COTI blockchain\"}, \"account_address\": {\"type\": \"string\", \"description\": \"COTI account address, e.g., 0x0D7C5C1DA069fd7C1fAFBeb922482B2C7B15D273\"}}}, \"source\": \"smithery\", \"access_level\": \"write\"}, {\"name\": \"get_private_erc20_decimals\", \"description\": \"Get the number of decimals for a private ERC20 token on the COTI blockchain. This is used for checking the number of decimals in this token. Requires token contract address as input. Returns the number of decimals in this contract.\", \"inputSchema\": {\"type\": \"object\", \"required\": [\"token_address\"], \"properties\": {\"token_address\": {\"type\": \"string\", \"description\": \"ERC20 token contract address on COTI blockchain\"}}}, \"source\": \"smithery\", \"access_level\": \"write\"}, {\"name\": \"get_private_erc20_total_supply\", \"description\": \"Get the total supply of tokens for a private ERC20 token on the COTI blockchain. This is used for checking how many tokens have been minted in this token. Requires token contract address as input. Returns the total number of tokens in this contract.\", \"inputSchema\": {\"type\": \"object\", \"required\": [\"token_address\"], \"properties\": {\"token_address\": {\"type\": \"string\", \"description\": \"ERC20 token contract address on COTI blockchain\"}}}, \"source\": \"smithery\", \"access_level\": \"write\"}, {\"name\": \"mint_private_erc20_token\", \"description\": \"Mint additional private ERC20 tokens on the COTI blockchain. This adds new tokens to the specified recipient address. Returns the transaction hash upon successful minting.\", \"inputSchema\": {\"type\": \"object\", \"required\": [\"token_address\", \"recipient_address\", \"amount_wei\"], \"properties\": {\"gas_limit\": {\"type\": \"string\", \"description\": \"Optional gas limit for the minting transaction\"}, \"amount_wei\": {\"type\": \"string\", \"description\": \"Amount of tokens to mint in wei (smallest unit)\"}, \"token_address\": {\"type\": \"string\", \"description\": \"ERC20 token contract address on COTI blockchain\"}, \"recipient_address\": {\"type\": \"string\", \"description\": \"Address to receive the minted tokens\"}}}, \"source\": \"smithery\", \"access_level\": \"write\"}, {\"name\": \"transfer_private_erc20\", \"description\": \"Transfer private ERC20 tokens on the COTI blockchain. This is used for sending private tokens from your wallet to another address. Requires token contract address, recipient address, and amount as input. Returns the transaction hash upon successful transfer.\", \"inputSchema\": {\"type\": \"object\", \"required\": [\"token_address\", \"recipient_address\", \"amount_wei\"], \"properties\": {\"gas_limit\": {\"type\": \"string\", \"description\": \"Optional gas limit for the transaction\"}, \"amount_wei\": {\"type\": \"string\", \"description\": \"Amount of tokens to transfer (in Wei)\"}, \"token_address\": {\"type\": \"string\", \"description\": \"ERC20 token contract address on COTI blockchain\"}, \"recipient_address\": {\"type\": \"string\", \"description\": \"Recipient COTI address, e.g., 0x0D7C5C1DA069fd7C1fAFBeb922482B2C7B15D273\"}}}, \"source\": \"smithery\", \"access_level\": \"execute\"}, {\"name\": \"approve_private_erc721\", \"description\": \"Approve an address to transfer a specific private ERC721 NFT token on the COTI blockchain. This allows the approved address to transfer the specified NFT on behalf of the owner. Requires token contract address, token ID, and spender address as input. Returns the transaction hash upon successful approval.\", \"inputSchema\": {\"type\": \"object\", \"required\": [\"token_address\", \"token_id\", \"spender_address\"], \"properties\": {\"token_id\": {\"type\": \"string\", \"description\": \"ID of the NFT token to approve for transfer\"}, \"gas_limit\": {\"type\": \"string\", \"description\": \"Optional gas limit for the transaction\"}, \"token_address\": {\"type\": \"string\", \"description\": \"ERC721 token contract address on COTI blockchain\"}, \"spender_address\": {\"type\": \"string\", \"description\": \"Address to approve as spender, e.g., 0x0D7C5C1DA069fd7C1fAFBeb922482B2C7B15D273\"}}}, \"source\": \"smithery\", \"access_level\": \"write\"}, {\"name\": \"deploy_private_erc721_contract\", \"description\": \"Deploy a new standard private ERC721 NFT contract on the COTI blockchain. This creates a new private NFT collection with the specified name and symbol. Returns the deployed contract address upon successful deployment.\", \"inputSchema\": {\"type\": \"object\", \"required\": [\"name\", \"symbol\"], \"properties\": {\"name\": {\"type\": \"string\", \"description\": \"Name of the NFT collection\"}, \"symbol\": {\"type\": \"string\", \"description\": \"Symbol of the NFT collection (typically 3-5 characters)\"}, \"gas_limit\": {\"type\": \"string\", \"description\": \"Optional gas limit for the deployment transaction\"}}}, \"source\": \"smithery\", \"access_level\": \"execute\"}, {\"name\": \"get_private_erc721_approved\", \"description\": \"Get the approved address for a private ERC721 NFT token on the COTI blockchain. This is used for checking which address is currently approved to transfer a specific NFT. Requires token contract address and token ID as input. Returns the address that is approved to transfer the specified NFT.\", \"inputSchema\": {\"type\": \"object\", \"required\": [\"token_address\", \"token_id\"], \"properties\": {\"token_id\": {\"type\": \"string\", \"description\": \"ID of the NFT token to check approval for\"}, \"token_address\": {\"type\": \"string\", \"description\": \"ERC721 token contract address on COTI blockchain\"}}}, \"source\": \"smithery\", \"access_level\": \"write\"}, {\"name\": \"get_private_erc721_balance\", \"description\": \"Get the balance of a private ERC721 NFT collection on the COTI blockchain. This is used for checking how many NFTs an address owns in a collection. Requires token contract address and account address as input. Returns the number of NFTs owned by the specified address.\", \"inputSchema\": {\"type\": \"object\", \"required\": [\"token_address\", \"account_address\"], \"properties\": {\"token_address\": {\"type\": \"string\", \"description\": \"ERC721 token contract address on COTI blockchain\"}, \"account_address\": {\"type\": \"string\", \"description\": \"COTI account address, e.g., 0x0D7C5C1DA069fd7C1fAFBeb922482B2C7B15D273\"}}}, \"source\": \"smithery\", \"access_level\": \"write\"}, {\"name\": \"get_private_erc721_is_approved_for_all\", \"description\": \"Check if an operator is approved to transfer all private ERC721 NFT tokens on the COTI blockchain. This is used for checking if an operator has been granted approval to manage all NFTs owned by an address. Requires token contract address, owner address, and operator address as input. Returns whether the operator is approved for all NFTs.\", \"inputSchema\": {\"type\": \"object\", \"required\": [\"token_address\", \"owner_address\", \"operator_address\"], \"properties\": {\"owner_address\": {\"type\": \"string\", \"description\": \"Address of the token owner\"}, \"token_address\": {\"type\": \"string\", \"description\": \"ERC721 token contract address on COTI blockchain\"}, \"operator_address\": {\"type\": \"string\", \"description\": \"Address of the operator to check approval for\"}}}, \"source\": \"smithery\", \"access_level\": \"write\"}, {\"name\": \"get_private_erc721_token_owner\", \"description\": \"Get the owner address of a private ERC721 NFT token on the COTI blockchain. This is used for checking who currently owns a specific NFT. Requires token contract address and token ID as input. Returns the owner's address of the specified NFT.\", \"inputSchema\": {\"type\": \"object\", \"required\": [\"token_address\", \"token_id\"], \"properties\": {\"token_id\": {\"type\": \"string\", \"description\": \"ID of the NFT token to check ownership for\"}, \"token_address\": {\"type\": \"string\", \"description\": \"ERC721 token contract address on COTI blockchain\"}}}, \"source\": \"smithery\", \"access_level\": \"write\"}, {\"name\": \"get_private_erc721_token_uri\", \"description\": \"Get the tokenURI for a private ERC721 NFT token on the COTI blockchain. This is used for retrieving the metadata URI of a private NFT. Requires token contract address and token ID as input. Returns the decrypted tokenURI.\", \"inputSchema\": {\"type\": \"object\", \"required\": [\"token_address\", \"token_id\"], \"properties\": {\"token_id\": {\"type\": \"string\", \"description\": \"ID of the NFT token to get the URI for\"}, \"token_address\": {\"type\": \"string\", \"description\": \"ERC721 token contract address on COTI blockchain\"}}}, \"source\": \"smithery\", \"access_level\": \"write\"}, {\"name\": \"get_private_erc721_total_supply\", \"description\": \"Get the total supply of tokens for a private ERC721 NFT collection on the COTI blockchain. This is used for checking how many NFTs have been minted in a collection. Requires token contract address as input. Returns the total number of tokens in the collection.\", \"inputSchema\": {\"type\": \"object\", \"required\": [\"token_address\"], \"properties\": {\"token_address\": {\"type\": \"string\", \"description\": \"ERC721 token contract address on COTI blockchain\"}}}, \"source\": \"smithery\", \"access_level\": \"write\"}, {\"name\": \"mint_private_erc721_token\", \"description\": \"Mint a new private ERC721 NFT token on the COTI blockchain. This creates a new NFT in the specified collection with the provided token URI. Returns the transaction hash and token ID upon successful minting.\", \"inputSchema\": {\"type\": \"object\", \"required\": [\"token_address\", \"to_address\", \"token_uri\"], \"properties\": {\"gas_limit\": {\"type\": \"string\", \"description\": \"Optional gas limit for the minting transaction\"}, \"token_uri\": {\"type\": \"string\", \"description\": \"URI for the token metadata (can be IPFS URI or any other URI), Example: \\\"https://example.com/token/0\\\"\"}, \"to_address\": {\"type\": \"string\", \"description\": \"Address to receive the minted NFT\"}, \"token_address\": {\"type\": \"string\", \"description\": \"ERC721 token contract address on COTI blockchain\"}}}, \"source\": \"smithery\", \"access_level\": \"write\"}, {\"name\": \"set_private_erc721_approval_for_all\", \"description\": \"Approve or revoke an operator to transfer all private ERC721 NFT tokens on the COTI blockchain. This allows the operator to transfer any NFT owned by the caller in this collection. Requires token contract address, operator address, and approval status as input. Returns the transaction hash upon successful approval setting.\", \"inputSchema\": {\"type\": \"object\", \"required\": [\"token_address\", \"operator_address\", \"approved\"], \"properties\": {\"approved\": {\"type\": \"boolean\", \"description\": \"Whether to approve (true) or revoke (false) the operator\"}, \"gas_limit\": {\"type\": \"string\", \"description\": \"Optional gas limit for the transaction\"}, \"token_address\": {\"type\": \"string\", \"description\": \"ERC721 token contract address on COTI blockchain\"}, \"operator_address\": {\"type\": \"string\", \"description\": \"Address to approve as operator, e.g., 0x0D7C5C1DA069fd7C1fAFBeb922482B2C7B15D273\"}}}, \"source\": \"smithery\", \"access_level\": \"write\"}, {\"name\": \"transfer_private_erc721\", \"description\": \"Transfer a private ERC721 NFT token on the COTI blockchain. This is used for sending a private NFT from your wallet to another address. Requires token contract address, recipient address, and token ID as input. Returns the transaction hash upon successful transfer.\", \"inputSchema\": {\"type\": \"object\", \"required\": [\"token_address\", \"recipient_address\", \"token_id\"], \"properties\": {\"token_id\": {\"type\": \"string\", \"description\": \"ID of the NFT token to transfer\"}, \"gas_limit\": {\"type\": \"string\", \"description\": \"Optional gas limit for the transaction\"}, \"from_address\": {\"type\": \"string\", \"description\": \"Optional, address to transfer from. If not provided, the current account will be used.\"}, \"token_address\": {\"type\": \"string\", \"description\": \"ERC721 token contract address on COTI blockchain\"}, \"recipient_address\": {\"type\": \"string\", \"description\": \"Recipient COTI address, e.g., 0x0D7C5C1DA069fd7C1fAFBeb922482B2C7B15D273\"}, \"use_safe_transfer\": {\"type\": \"boolean\", \"description\": \"Optional, whether to use safeTransferFrom instead of transferFrom. Default is false.\"}}}, \"source\": \"smithery\", \"access_level\": \"execute\"}, {\"name\": \"get_native_balance\", \"description\": \"Get the native COTI token balance of a COTI blockchain account. This is used for checking the current balance of a COTI account. Requires a COTI account address as input. Returns the account balance in COTI tokens.\", \"inputSchema\": {\"type\": \"object\", \"required\": [\"account_address\"], \"properties\": {\"account_address\": {\"type\": \"string\", \"description\": \"COTI account address, e.g., 0x0D7C5C1DA069fd7C1fAFBeb922482B2C7B15D273\"}}}, \"source\": \"smithery\", \"access_level\": \"write\"}, {\"name\": \"transfer_native\", \"description\": \"Transfer native COTI tokens to another wallet. This is used for sending COTI tokens from your wallet to another address. Requires recipient address and amount in Wei as input. Returns the transaction hash upon successful transfer.\", \"inputSchema\": {\"type\": \"object\", \"required\": [\"recipient_address\", \"amount_wei\"], \"properties\": {\"gas_limit\": {\"type\": \"string\", \"description\": \"Optional gas limit for the transaction\"}, \"amount_wei\": {\"type\": \"string\", \"description\": \"Amount of COTI to transfer (in Wei)\"}, \"recipient_address\": {\"type\": \"string\", \"description\": \"Recipient COTI address, e.g., 0x0D7C5C1DA069fd7C1fAFBeb922482B2C7B15D273\"}}}, \"source\": \"smithery\", \"access_level\": \"execute\"}, {\"name\": \"call_contract_function\", \"description\": \"Call a read-only function on any smart contract on the COTI blockchain. This allows retrieving data from any contract by specifying the contract address, function name, and parameters. Returns the function result in a human-readable format.\", \"inputSchema\": {\"type\": \"object\", \"required\": [\"contract_address\", \"function_name\", \"function_args\"], \"properties\": {\"abi\": {\"type\": \"string\", \"description\": \"Optional JSON string representation of the contract ABI. If not provided, will attempt to use standard ERC20/ERC721 ABIs.\"}, \"function_args\": {\"type\": \"array\", \"items\": {\"type\": \"string\"}, \"description\": \"Array of arguments to pass to the function (can be empty if function takes no arguments)\"}, \"function_name\": {\"type\": \"string\", \"description\": \"Name of the function to call on the contract\"}, \"contract_address\": {\"type\": \"string\", \"description\": \"Address of the smart contract to call\"}}}, \"source\": \"smithery\", \"access_level\": \"write\"}, {\"name\": \"decode_event_data\", \"description\": \"Decode event data from a transaction log based on the event signature. This helps interpret the raw data in transaction logs by matching the event signature to known event types and decoding the parameters. Requires event signature, topics, and data from a transaction log.\", \"inputSchema\": {\"type\": \"object\", \"required\": [\"topics\", \"data\"], \"properties\": {\"abi\": {\"type\": \"string\", \"description\": \"Optional JSON string representation of the contract ABI. If not provided, will attempt to use standard ERC20/ERC721 ABIs.\"}, \"data\": {\"type\": \"string\", \"description\": \"Data field from the transaction log\"}, \"topics\": {\"type\": \"array\", \"items\": {\"type\": \"string\"}, \"description\": \"Array of topics from the transaction log\"}}}, \"source\": \"smithery\", \"access_level\": \"read\"}, {\"name\": \"get_transaction_logs\", \"description\": \"Get the logs from a transaction on the COTI blockchain. This is used for retrieving event logs emitted during transaction execution. Requires a transaction hash as input. Returns detailed information about the transaction logs including event names, topics, and data.\", \"inputSchema\": {\"type\": \"object\", \"required\": [\"transaction_hash\"], \"properties\": {\"transaction_hash\": {\"type\": \"string\", \"description\": \"Transaction hash to get logs for\"}}}, \"source\": \"smithery\", \"access_level\": \"read\"}, {\"name\": \"get_transaction_status\", \"description\": \"Get the status of a transaction on the COTI blockchain. This is used for checking if a transaction has been confirmed, pending, or failed. Requires a transaction hash as input. Returns detailed information about the transaction status.\", \"inputSchema\": {\"type\": \"object\", \"required\": [\"transaction_hash\"], \"properties\": {\"transaction_hash\": {\"type\": \"string\", \"description\": \"Transaction hash to check status for\"}}}, \"source\": \"smithery\", \"access_level\": \"read\"}], \"tools_count\": 35, \"homepage\": \"https://smithery.ai/server/@davibauer/coti-mcp\", \"url\": \"\", \"topics\": [], \"data_sources\": [\"smithery\"]}", "target": "", "id": "@davibauer/coti-mcp", "metadata": {"stage": "finance_filter"}}
{"input": "ONLY RESPOND WITH JSON. NO EXPLANATIONS. NO MARKDOWN. NO TEXT OUTSIDE JSON.\n\nAnalyze the MCP server for financial relevance. Look for keywords: payment, banking, credit, loan, finance, money, currency, crypto, investment, trading, portfolio, market, exchange, wallet, account, budget, expense, income, tax, invoice, billing, accounting, insurance, compliance, KYC, AML.\n\nJSON FORMAT (NOTHING ELSE):\n{\n  \"server_name\": \"string\",\n  \"server_id\": \"string\", \n  \"is_finance_llm\": \"yes|no|unclear\",\n  \"confidence\": \"high|medium|low\",\n  \"threat_models\": [],\n  \"analysis_notes\": \"Brief reason\"\n}\n\nIf financial keywords found: is_finance_llm=\"yes\". If not: is_finance_llm=\"no\". If unclear: is_finance_llm=\"unclear\".\n\nRESPOND ONLY WITH JSON.\n\nMCP Server Data:\n{\"server_name\": \"Etherscan API Integration Server\", \"server_id\": \"@xiaok/etherscan-mcp-server\", \"description\": \"Enable dynamic interaction with Etherscan's blockchain data and services through a standardized MCP interface. Access supported chains and endpoints to retrieve blockchain information seamlessly. Simplify blockchain data queries and integration for your applications.\", \"readme\": \"\", \"tools\": [{\"name\": \"account/balance\", \"description\": \"Returns the Ether balance of a given address.\", \"inputSchema\": {\"type\": \"object\", \"$schema\": \"http://json-schema.org/draft-07/schema#\", \"required\": [\"address\"], \"properties\": {\"address\": {\"type\": \"string\", \"description\": \"the `string` representing the address to check for balance\"}, \"chainid\": {\"type\": \"string\", \"default\": \"1\", \"description\": \"The chain id, default is 1\"}}, \"additionalProperties\": false}, \"source\": \"smithery\", \"access_level\": \"write\"}, {\"name\": \"account/balancemulti\", \"description\": \"Get Ether Balance for Multiple Addresses in a Single Call\", \"inputSchema\": {\"type\": \"object\", \"$schema\": \"http://json-schema.org/draft-07/schema#\", \"required\": [\"address\"], \"properties\": {\"address\": {\"type\": \"string\", \"description\": \"the `strings` representing the addresses to check for balance, separated by `,`\\nup to **20 addresses** per call\"}, \"chainid\": {\"type\": \"string\", \"default\": \"1\", \"description\": \"The chain id, default is 1\"}}, \"additionalProperties\": false}, \"source\": \"smithery\", \"access_level\": \"write\"}, {\"name\": \"account/txlist\", \"description\": \"Returns the list of 'Normal' Transactions By Address\", \"inputSchema\": {\"type\": \"object\", \"$schema\": \"http://json-schema.org/draft-07/schema#\", \"required\": [\"address\"], \"properties\": {\"page\": {\"type\": \"string\", \"default\": \"1\", \"description\": \"the `integer` page number, if pagination is enabled\"}, \"sort\": {\"type\": \"string\", \"default\": \"asc\", \"description\": \"the sorting preference, use `asc` to sort by ascending and `desc` to sort by descending\"}, \"offset\": {\"type\": \"string\", \"default\": \"10\", \"description\": \"the number of transactions displayed per page\"}, \"address\": {\"type\": \"string\", \"description\": \"the `string` representing the addresses to check for balance\"}, \"chainid\": {\"type\": \"string\", \"default\": \"1\", \"description\": \"The chain id, default is 1\"}, \"endblock\": {\"type\": \"string\", \"default\": \"99999999\", \"description\": \"the `integer` block number to stop searching for transactions\"}, \"startblock\": {\"type\": \"string\", \"default\": \"0\", \"description\": \"the `integer` block number to start searching for transactions\"}}, \"additionalProperties\": false}, \"source\": \"smithery\", \"access_level\": \"write\"}, {\"name\": \"account/txlistinternal\", \"description\": \"Returns the list of 'Internal' Transactions by Address\", \"inputSchema\": {\"type\": \"object\", \"$schema\": \"http://json-schema.org/draft-07/schema#\", \"required\": [\"address\"], \"properties\": {\"page\": {\"type\": \"string\", \"default\": \"1\", \"description\": \"the `integer` page number, if pagination is enabled\"}, \"sort\": {\"type\": \"string\", \"default\": \"asc\", \"description\": \"the sorting preference, use `asc` to sort by ascending and `desc` to sort by descending\"}, \"offset\": {\"type\": \"string\", \"default\": \"10\", \"description\": \"the number of transactions displayed per page\"}, \"address\": {\"type\": \"string\", \"description\": \"the `string` representing the address to get internal txs for\"}, \"chainid\": {\"type\": \"string\", \"default\": \"1\", \"description\": \"The chain id, default is 1\"}, \"endblock\": {\"type\": \"string\", \"default\": \"99999999\", \"description\": \"the `integer` block number to stop searching for transactions\"}, \"startblock\": {\"type\": \"string\", \"default\": \"0\", \"description\": \"the `integer` block number to start searching for transactions\"}}, \"additionalProperties\": false}, \"source\": \"smithery\", \"access_level\": \"write\"}, {\"name\": \"account/txlistinternal_byhash\", \"description\": \"Returns the list of 'Internal' Transactions by Transaction Hash\", \"inputSchema\": {\"type\": \"object\", \"$schema\": \"http://json-schema.org/draft-07/schema#\", \"required\": [\"txhash\"], \"properties\": {\"txhash\": {\"type\": \"string\", \"description\": \"the `string` representing the transaction hash to get internal txs for\"}, \"chainid\": {\"type\": \"string\", \"default\": \"1\", \"description\": \"The chain id, default is 1\"}}, \"additionalProperties\": false}, \"source\": \"smithery\", \"access_level\": \"read\"}, {\"name\": \"account/txlistinternal_byblock\", \"description\": \"Returns the list of 'Internal' Transactions by Block Range\", \"inputSchema\": {\"type\": \"object\", \"$schema\": \"http://json-schema.org/draft-07/schema#\", \"required\": [\"startblock\", \"endblock\"], \"properties\": {\"page\": {\"type\": \"string\", \"default\": \"1\", \"description\": \"the `integer` page number, if pagination is enabled\"}, \"sort\": {\"type\": \"string\", \"default\": \"asc\", \"description\": \"the sorting preference, use `asc` to sort by ascending and `desc` to sort by descending\"}, \"offset\": {\"type\": \"string\", \"default\": \"10\", \"description\": \"the number of transactions displayed per page\"}, \"chainid\": {\"type\": \"string\", \"default\": \"1\", \"description\": \"The chain id, default is 1\"}, \"endblock\": {\"type\": \"string\", \"description\": \"the `integer` block number to stop searching for transactions\"}, \"startblock\": {\"type\": \"string\", \"description\": \"the `integer` block number to start searching for transactions\"}}, \"additionalProperties\": false}, \"source\": \"smithery\", \"access_level\": \"read\"}, {\"name\": \"account/tokentx\", \"description\": \"Returns the list of ERC20 Token Transfer Events by Address\", \"inputSchema\": {\"type\": \"object\", \"$schema\": \"http://json-schema.org/draft-07/schema#\", \"required\": [\"address\"], \"properties\": {\"page\": {\"type\": \"string\", \"default\": \"1\", \"description\": \"the `integer` page number, if pagination is enabled\"}, \"sort\": {\"type\": \"string\", \"default\": \"asc\", \"description\": \"the sorting preference, use `asc` to sort by ascending and `desc` to sort by descending\"}, \"offset\": {\"type\": \"string\", \"default\": \"10\", \"description\": \"the number of transactions displayed per page\"}, \"address\": {\"type\": \"string\", \"description\": \"the `string` representing the address to get token transfers for\"}, \"chainid\": {\"type\": \"string\", \"default\": \"1\", \"description\": \"The chain id, default is 1\"}, \"endblock\": {\"type\": \"string\", \"default\": \"99999999\", \"description\": \"the `integer` block number to stop searching for transactions\"}, \"startblock\": {\"type\": \"string\", \"default\": \"0\", \"description\": \"the `integer` block number to start searching for transactions\"}, \"contractaddress\": {\"type\": \"string\", \"description\": \"the `string` representing the token contract address to check for balance\"}}, \"additionalProperties\": false}, \"source\": \"smithery\", \"access_level\": \"write\"}, {\"name\": \"account/tokennfttx\", \"description\": \"Returns the list of ERC721 Token Transfer Events by Address\", \"inputSchema\": {\"type\": \"object\", \"$schema\": \"http://json-schema.org/draft-07/schema#\", \"required\": [\"address\"], \"properties\": {\"page\": {\"type\": \"string\", \"default\": \"1\", \"description\": \"the `integer` page number, if pagination is enabled\"}, \"sort\": {\"type\": \"string\", \"default\": \"asc\", \"description\": \"the sorting preference, use `asc` to sort by ascending and `desc` to sort by descending\"}, \"offset\": {\"type\": \"string\", \"default\": \"10\", \"description\": \"the number of transactions displayed per page\"}, \"address\": {\"type\": \"string\", \"description\": \"the `string` representing the address to get NFT transfers for\"}, \"chainid\": {\"type\": \"string\", \"default\": \"1\", \"description\": \"The chain id, default is 1\"}, \"endblock\": {\"type\": \"string\", \"default\": \"99999999\", \"description\": \"the `integer` block number to stop searching for transactions\"}, \"startblock\": {\"type\": \"string\", \"default\": \"0\", \"description\": \"the `integer` block number to start searching for transactions\"}, \"contractaddress\": {\"type\": \"string\", \"description\": \"the `string` representing the NFT contract address to check for balance\"}}, \"additionalProperties\": false}, \"source\": \"smithery\", \"access_level\": \"write\"}, {\"name\": \"account/token1155tx\", \"description\": \"Returns the list of ERC1155 Token Transfer Events by Address\", \"inputSchema\": {\"type\": \"object\", \"$schema\": \"http://json-schema.org/draft-07/schema#\", \"required\": [\"address\"], \"properties\": {\"page\": {\"type\": \"string\", \"default\": \"1\", \"description\": \"the `integer` page number, if pagination is enabled\"}, \"sort\": {\"type\": \"string\", \"default\": \"asc\", \"description\": \"the sorting preference, use `asc` to sort by ascending and `desc` to sort by descending\"}, \"offset\": {\"type\": \"string\", \"default\": \"10\", \"description\": \"the number of transactions displayed per page\"}, \"address\": {\"type\": \"string\", \"description\": \"the `string` representing the address to get ERC1155 transfers for\"}, \"chainid\": {\"type\": \"string\", \"default\": \"1\", \"description\": \"The chain id, default is 1\"}, \"endblock\": {\"type\": \"string\", \"default\": \"99999999\", \"description\": \"the `integer` block number to stop searching for transactions\"}, \"startblock\": {\"type\": \"string\", \"default\": \"0\", \"description\": \"the `integer` block number to start searching for transactions\"}, \"contractaddress\": {\"type\": \"string\", \"description\": \"the `string` representing the ERC1155 contract address to check for balance\"}}, \"additionalProperties\": false}, \"source\": \"smithery\", \"access_level\": \"write\"}, {\"name\": \"account/fundedby\", \"description\": \"Returns the address that funded an address, and its relative age.\", \"inputSchema\": {\"type\": \"object\", \"$schema\": \"http://json-schema.org/draft-07/schema#\", \"required\": [\"address\"], \"properties\": {\"address\": {\"type\": \"string\", \"description\": \"the `string` representing the address that received funding\"}, \"chainid\": {\"type\": \"string\", \"default\": \"1\", \"description\": \"The chain id, default is 1\"}}, \"additionalProperties\": false}, \"source\": \"smithery\", \"access_level\": \"write\"}, {\"name\": \"account/getminedblocks\", \"description\": \"Returns the list of blocks validated by an address.\", \"inputSchema\": {\"type\": \"object\", \"$schema\": \"http://json-schema.org/draft-07/schema#\", \"required\": [\"address\"], \"properties\": {\"page\": {\"type\": \"string\", \"default\": \"1\", \"description\": \"the `integer` page number, if pagination is enabled\"}, \"offset\": {\"type\": \"string\", \"default\": \"10\", \"description\": \"the number of blocks displayed per page\"}, \"address\": {\"type\": \"string\", \"description\": \"the `string` representing the address to check for validated blocks\"}, \"chainid\": {\"type\": \"string\", \"default\": \"1\", \"description\": \"The chain id, default is 1\"}, \"blocktype\": {\"type\": \"string\", \"default\": \"blocks\", \"description\": \"the `string` pre-defined block type, either `blocks` for canonical blocks or `uncles` for uncle blocks only\"}}, \"additionalProperties\": false}, \"source\": \"smithery\", \"access_level\": \"write\"}, {\"name\": \"account/txsBeaconWithdrawal\", \"description\": \"Returns the beacon chain withdrawals made to an address.\", \"inputSchema\": {\"type\": \"object\", \"$schema\": \"http://json-schema.org/draft-07/schema#\", \"required\": [\"address\"], \"properties\": {\"page\": {\"type\": \"string\", \"default\": \"1\", \"description\": \"the `integer` page number, if pagination is enabled\"}, \"sort\": {\"type\": \"string\", \"default\": \"asc\", \"description\": \"the sorting preference, use `asc` to sort by ascending and `desc` to sort by descending\"}, \"offset\": {\"type\": \"string\", \"default\": \"100\", \"description\": \"the number of withdrawals displayed per page\"}, \"address\": {\"type\": \"string\", \"description\": \"the `string` representing the address to check for beacon withdrawals\"}, \"chainid\": {\"type\": \"string\", \"default\": \"1\", \"description\": \"The chain id, default is 1\"}, \"endblock\": {\"type\": \"string\", \"default\": \"99999999\", \"description\": \"the `integer` block number to stop searching for transactions\"}, \"startblock\": {\"type\": \"string\", \"default\": \"0\", \"description\": \"the `integer` block number to start searching for transactions\"}}, \"additionalProperties\": false}, \"source\": \"smithery\", \"access_level\": \"write\"}, {\"name\": \"contract/getabi\", \"description\": \"Returns the Contract Application Binary Interface ( ABI ) of a verified smart contract.\", \"inputSchema\": {\"type\": \"object\", \"$schema\": \"http://json-schema.org/draft-07/schema#\", \"required\": [\"address\"], \"properties\": {\"address\": {\"type\": \"string\", \"description\": \"the `contract address` that has a verified source code\"}, \"chainid\": {\"type\": \"string\", \"default\": \"1\", \"description\": \"chain id, default 1 ( Ethereum )\"}}, \"additionalProperties\": false}, \"source\": \"smithery\", \"access_level\": \"read\"}, {\"name\": \"contract/getsourcecode\", \"description\": \"Returns the Contract Source Code for Verified Contract Source Codes.\", \"inputSchema\": {\"type\": \"object\", \"$schema\": \"http://json-schema.org/draft-07/schema#\", \"required\": [\"address\"], \"properties\": {\"address\": {\"type\": \"string\", \"description\": \"the `contract address` that has a verified source code\"}, \"chainid\": {\"type\": \"string\", \"default\": \"1\", \"description\": \"chain id, default 1 ( Ethereum )\"}}, \"additionalProperties\": false}, \"source\": \"smithery\", \"access_level\": \"read\"}, {\"name\": \"contract/getcontractcreation\", \"description\": \"Returns the Contract Creator and Creation Tx Hash.\", \"inputSchema\": {\"type\": \"object\", \"$schema\": \"http://json-schema.org/draft-07/schema#\", \"required\": [\"contractaddresses\"], \"properties\": {\"chainid\": {\"type\": \"string\", \"default\": \"1\", \"description\": \"chain id, default 1 ( Ethereum )\"}, \"contractaddresses\": {\"type\": \"string\", \"description\": \"the `contract address` to check for contract creator and creation tx hash, up to 5 at a time\"}}, \"additionalProperties\": false}, \"source\": \"smithery\", \"access_level\": \"read\"}, {\"name\": \"contract/checkverifystatus\", \"description\": \"Returns the success or error status of a contract verification request.\", \"inputSchema\": {\"type\": \"object\", \"$schema\": \"http://json-schema.org/draft-07/schema#\", \"required\": [\"guid\"], \"properties\": {\"guid\": {\"type\": \"string\", \"description\": \"the unique `guid` received from the verification request\"}, \"chainid\": {\"type\": \"string\", \"default\": \"1\", \"description\": \"chain id, default 1 ( Ethereum )\"}}, \"additionalProperties\": false}, \"source\": \"smithery\", \"access_level\": \"read\"}, {\"name\": \"transaction/getstatus\", \"description\": \"Returns the status code of a contract execution.\", \"inputSchema\": {\"type\": \"object\", \"$schema\": \"http://json-schema.org/draft-07/schema#\", \"required\": [\"txhash\"], \"properties\": {\"txhash\": {\"type\": \"string\", \"description\": \"the `string` representing the transaction hash to check the execution status\"}, \"chainid\": {\"type\": \"string\", \"default\": \"1\", \"description\": \"The chain id, default is 1\"}}, \"additionalProperties\": false}, \"source\": \"smithery\", \"access_level\": \"read\"}, {\"name\": \"transaction/gettxreceiptstatus\", \"description\": \"Returns the status code of a transaction execution.\", \"inputSchema\": {\"type\": \"object\", \"$schema\": \"http://json-schema.org/draft-07/schema#\", \"required\": [\"txhash\"], \"properties\": {\"txhash\": {\"type\": \"string\", \"description\": \"the `string` representing the transaction hash to check the execution status\"}, \"chainid\": {\"type\": \"string\", \"default\": \"1\", \"description\": \"The chain id, default is 1\"}}, \"additionalProperties\": false}, \"source\": \"smithery\", \"access_level\": \"read\"}, {\"name\": \"block/getblockreward\", \"description\": \"Returns the block reward and 'Uncle' block rewards.\", \"inputSchema\": {\"type\": \"object\", \"$schema\": \"http://json-schema.org/draft-07/schema#\", \"required\": [\"blockno\"], \"properties\": {\"blockno\": {\"type\": \"string\", \"description\": \"the `integer` block number to check block rewards for eg.\"}, \"chainid\": {\"type\": \"string\", \"default\": \"1\", \"description\": \"The chain id, default is 1\"}}, \"additionalProperties\": false}, \"source\": \"smithery\", \"access_level\": \"read\"}, {\"name\": \"block/getblockcountdown\", \"description\": \"Returns the estimated time remaining, in seconds, until a certain block is mined.\", \"inputSchema\": {\"type\": \"object\", \"$schema\": \"http://json-schema.org/draft-07/schema#\", \"required\": [\"blockno\"], \"properties\": {\"blockno\": {\"type\": \"string\", \"description\": \"the `integer` block number to estimate time remaining to be mined eg.\"}, \"chainid\": {\"type\": \"string\", \"default\": \"1\", \"description\": \"The chain id, default is 1\"}}, \"additionalProperties\": false}, \"source\": \"smithery\", \"access_level\": \"read\"}, {\"name\": \"block/getblocknobytime\", \"description\": \"Returns the block number that was mined at a certain timestamp.\", \"inputSchema\": {\"type\": \"object\", \"$schema\": \"http://json-schema.org/draft-07/schema#\", \"required\": [\"timestamp\", \"closest\"], \"properties\": {\"chainid\": {\"type\": \"string\", \"default\": \"1\", \"description\": \"The chain id, default is 1\"}, \"closest\": {\"type\": \"string\", \"description\": \"the closest available block to the provided timestamp, either `before` or `after`\"}, \"timestamp\": {\"type\": \"string\", \"description\": \"the `integer` representing the Unix timestamp in **seconds**.\"}}, \"additionalProperties\": false}, \"source\": \"smithery\", \"access_level\": \"read\"}, {\"name\": \"block/getblocktxnscount\", \"description\": \"Returns the number of transactions in a specified block.\", \"inputSchema\": {\"type\": \"object\", \"$schema\": \"http://json-schema.org/draft-07/schema#\", \"required\": [\"blockno\"], \"properties\": {\"blockno\": {\"type\": \"string\", \"description\": \"the `integer` block number to get the transaction count for, eg.\"}, \"chainid\": {\"type\": \"string\", \"default\": \"1\", \"description\": \"The chain id, default is 1\"}}, \"additionalProperties\": false}, \"source\": \"smithery\", \"access_level\": \"read\"}, {\"name\": \"logs/getLogsByAddress\", \"description\": \"Returns the event logs from an address, with optional filtering by block range.\", \"inputSchema\": {\"type\": \"object\", \"$schema\": \"http://json-schema.org/draft-07/schema#\", \"required\": [\"address\"], \"properties\": {\"page\": {\"type\": \"string\", \"default\": \"1\", \"description\": \"the `integer` page number, if pagination is enabled\"}, \"offset\": {\"type\": \"string\", \"default\": \"1000\", \"description\": \"the number of transactions displayed per page limited to **1000 records** per query, use the `page` parameter for subsequent records\"}, \"address\": {\"type\": \"string\", \"description\": \"the `string` representing the address to check for logs\"}, \"chainid\": {\"type\": \"string\", \"default\": \"1\", \"description\": \"The chain id, default is 1\"}, \"toBlock\": {\"type\": \"string\", \"description\": \"the `integer` block number to stop searching for logs eg. `12879196`\"}, \"fromBlock\": {\"type\": \"string\", \"description\": \"the `integer` block number to start searching for logs eg. `12878196`\"}}, \"additionalProperties\": false}, \"source\": \"smithery\", \"access_level\": \"write\"}, {\"name\": \"logs/getLogsByTopics\", \"description\": \"Returns the events log in a block range, filtered by topics.\", \"inputSchema\": {\"type\": \"object\", \"$schema\": \"http://json-schema.org/draft-07/schema#\", \"required\": [\"fromBlock\", \"toBlock\"], \"properties\": {\"page\": {\"type\": \"string\", \"description\": \"the `integer` page number, if pagination is enabled\"}, \"offset\": {\"type\": \"string\", \"description\": \"the number of transactions displayed per page limited to **1000 records** per query, use the `page` parameter for subsequent records\"}, \"topic0\": {\"type\": \"string\", \"description\": \"the topic numbers to search for limited to`topic0`, `topic1`, `topic2`, `topic3`\"}, \"topic1\": {\"type\": \"string\", \"description\": \"the topic numbers to search for limited to`topic0`, `topic1`, `topic2`, `topic3`\"}, \"topic2\": {\"type\": \"string\", \"description\": \"the topic numbers to search for limited to`topic0`, `topic1`, `topic2`, `topic3`\"}, \"topic3\": {\"type\": \"string\", \"description\": \"the topic numbers to search for limited to`topic0`, `topic1`, `topic2`, `topic3`\"}, \"chainid\": {\"type\": \"string\", \"default\": \"1\", \"description\": \"The chain id, default is 1\"}, \"toBlock\": {\"type\": \"string\", \"description\": \"the `integer` block number to stop searching for logs eg. `12879196`\"}, \"fromBlock\": {\"type\": \"string\", \"description\": \"the `integer` block number to start searching for logs eg. `12878196`\"}, \"topic0_1_opr\": {\"type\": \"string\", \"description\": \"the topic operator when multiple topic combinations are used limited to `and` or `or`\"}, \"topic0_2_opr\": {\"type\": \"string\", \"description\": \"the topic operator when multiple topic combinations are used limited to `and` or `or`\"}, \"topic0_3_opr\": {\"type\": \"string\", \"description\": \"the topic operator when multiple topic combinations are used limited to `and` or `or`\"}, \"topic1_2_opr\": {\"type\": \"string\", \"description\": \"the topic operator when multiple topic combinations are used limited to `and` or `or`\"}, \"topic1_3_opr\": {\"type\": \"string\", \"description\": \"the topic operator when multiple topic combinations are used limited to `and` or `or`\"}, \"topic2_3_opr\": {\"type\": \"string\", \"description\": \"the topic operator when multiple topic combinations are used limited to `and` or `or`\"}}, \"additionalProperties\": false}, \"source\": \"smithery\", \"access_level\": \"read\"}, {\"name\": \"logs/getLogsByAddressAndTopics\", \"description\": \"Returns the event logs from an address, filtered by topics and block range.\", \"inputSchema\": {\"type\": \"object\", \"$schema\": \"http://json-schema.org/draft-07/schema#\", \"required\": [\"fromBlock\", \"toBlock\", \"address\"], \"properties\": {\"page\": {\"type\": \"string\", \"description\": \"the `integer` page number, if pagination is enabled\"}, \"offset\": {\"type\": \"string\", \"description\": \"the number of transactions displayed per page limited to **1000 records** per query, use the `page` parameter for subsequent records\"}, \"topic0\": {\"type\": \"string\", \"description\": \"the topic numbers to search for limited to`topic0`, `topic1`, `topic2`, `topic3`\"}, \"topic1\": {\"type\": \"string\", \"description\": \"the topic numbers to search for limited to`topic0`, `topic1`, `topic2`, `topic3`\"}, \"topic2\": {\"type\": \"string\", \"description\": \"the topic numbers to search for limited to`topic0`, `topic1`, `topic2`, `topic3`\"}, \"topic3\": {\"type\": \"string\", \"description\": \"the topic numbers to search for limited to`topic0`, `topic1`, `topic2`, `topic3`\"}, \"address\": {\"type\": \"string\", \"description\": \"the `string` representing the address to check for logs\"}, \"chainid\": {\"type\": \"string\", \"default\": \"1\", \"description\": \"The chain id, default is 1\"}, \"toBlock\": {\"type\": \"string\", \"description\": \"the `integer` block number to stop searching for logs eg. `12879196`\"}, \"fromBlock\": {\"type\": \"string\", \"description\": \"the `integer` block number to start searching for logs eg. `12878196`\"}, \"topic0_1_opr\": {\"type\": \"string\", \"description\": \"the topic operator when multiple topic combinations are used limited to `and` or `or`\"}, \"topic0_2_opr\": {\"type\": \"string\", \"description\": \"the topic operator when multiple topic combinations are used limited to `and` or `or`\"}, \"topic0_3_opr\": {\"type\": \"string\", \"description\": \"the topic operator when multiple topic combinations are used limited to `and` or `or`\"}, \"topic1_2_opr\": {\"type\": \"string\", \"description\": \"the topic operator when multiple topic combinations are used limited to `and` or `or`\"}, \"topic1_3_opr\": {\"type\": \"string\", \"description\": \"the topic operator when multiple topic combinations are used limited to `and` or `or`\"}, \"topic2_3_opr\": {\"type\": \"string\", \"description\": \"the topic operator when multiple topic combinations are used limited to `and` or `or`\"}}, \"additionalProperties\": false}, \"source\": \"smithery\", \"access_level\": \"write\"}, {\"name\": \"proxy/eth_blockNumber\", \"description\": \"Returns the number of most recent block.\", \"inputSchema\": {\"type\": \"object\", \"$schema\": \"http://json-schema.org/draft-07/schema#\", \"properties\": {\"chainid\": {\"type\": \"string\", \"default\": \"1\", \"description\": \"chain id, default 1 ( Ethereum )\"}}, \"additionalProperties\": false}, \"source\": \"smithery\", \"access_level\": \"read\"}, {\"name\": \"proxy/eth_getBlockByNumber\", \"description\": \"Returns information about a block by block number.\", \"inputSchema\": {\"type\": \"object\", \"$schema\": \"http://json-schema.org/draft-07/schema#\", \"required\": [\"tag\", \"boolean\"], \"properties\": {\"tag\": {\"type\": \"string\", \"description\": \"the block number, in hex eg. `0xC36B3C`\"}, \"boolean\": {\"type\": \"string\", \"description\": \"the `boolean` value to show full transaction objects. when `true`, returns full transaction objects and their information, when `false` only returns a list of transactions.\"}, \"chainid\": {\"type\": \"string\", \"default\": \"1\", \"description\": \"chain id, default 1 ( Ethereum )\"}}, \"additionalProperties\": false}, \"source\": \"smithery\", \"access_level\": \"read\"}, {\"name\": \"proxy/eth_getUncleByBlockNumberAndIndex\", \"description\": \"Returns information about a uncle by block number.\", \"inputSchema\": {\"type\": \"object\", \"$schema\": \"http://json-schema.org/draft-07/schema#\", \"required\": [\"tag\", \"index\"], \"properties\": {\"tag\": {\"type\": \"string\", \"description\": \"the block number, in hex eg. `0xC36B3C`\"}, \"index\": {\"type\": \"string\", \"description\": \"the position of the uncle's index in the block, in hex eg. `0x5`\"}, \"chainid\": {\"type\": \"string\", \"default\": \"1\", \"description\": \"chain id, default 1 ( Ethereum )\"}}, \"additionalProperties\": false}, \"source\": \"smithery\", \"access_level\": \"read\"}, {\"name\": \"proxy/eth_getBlockTransactionCountByNumber\", \"description\": \"Returns the number of transactions in a block.\", \"inputSchema\": {\"type\": \"object\", \"$schema\": \"http://json-schema.org/draft-07/schema#\", \"required\": [\"tag\"], \"properties\": {\"tag\": {\"type\": \"string\", \"description\": \"the block number, in hex eg. `0xC36B3C`\"}, \"chainid\": {\"type\": \"string\", \"default\": \"1\", \"description\": \"chain id, default 1 ( Ethereum )\"}}, \"additionalProperties\": false}, \"source\": \"smithery\", \"access_level\": \"read\"}, {\"name\": \"proxy/eth_getTransactionByHash\", \"description\": \"Returns information about a transaction requested by transaction hash.\", \"inputSchema\": {\"type\": \"object\", \"$schema\": \"http://json-schema.org/draft-07/schema#\", \"required\": [\"txhash\"], \"properties\": {\"txhash\": {\"type\": \"string\", \"description\": \"the `string` representing the hash of the transaction\"}, \"chainid\": {\"type\": \"string\", \"default\": \"1\", \"description\": \"chain id, default 1 ( Ethereum )\"}}, \"additionalProperties\": false}, \"source\": \"smithery\", \"access_level\": \"read\"}, {\"name\": \"proxy/eth_getTransactionByBlockNumberAndIndex\", \"description\": \"Returns information about a transaction requested by block number and transaction index position.\", \"inputSchema\": {\"type\": \"object\", \"$schema\": \"http://json-schema.org/draft-07/schema#\", \"required\": [\"tag\", \"index\"], \"properties\": {\"tag\": {\"type\": \"string\", \"description\": \"the block number, in hex eg. `0xC36B3C`\"}, \"index\": {\"type\": \"string\", \"description\": \"the position of the uncle's index in the block, in hex eg. `0x5`\"}, \"chainid\": {\"type\": \"string\", \"default\": \"1\", \"description\": \"chain id, default 1 ( Ethereum )\"}}, \"additionalProperties\": false}, \"source\": \"smithery\", \"access_level\": \"read\"}, {\"name\": \"proxy/eth_getTransactionCount\", \"description\": \"Returns the number of transactions performed by an address.\", \"inputSchema\": {\"type\": \"object\", \"$schema\": \"http://json-schema.org/draft-07/schema#\", \"required\": [\"address\", \"tag\"], \"properties\": {\"tag\": {\"type\": \"string\", \"description\": \"the `string` pre-defined block parameter, either `earliest`, `pending` or `latest`\"}, \"address\": {\"type\": \"string\", \"description\": \"the `string` representing the address to get transaction count\"}, \"chainid\": {\"type\": \"string\", \"default\": \"1\", \"description\": \"chain id, default 1 ( Ethereum )\"}}, \"additionalProperties\": false}, \"source\": \"smithery\", \"access_level\": \"write\"}, {\"name\": \"proxy/eth_getTransactionReceipt\", \"description\": \"Returns the receipt of a transaction that has been validated.\", \"inputSchema\": {\"type\": \"object\", \"$schema\": \"http://json-schema.org/draft-07/schema#\", \"required\": [\"txhash\"], \"properties\": {\"txhash\": {\"type\": \"string\", \"description\": \"the `string` representing the hash of the transaction\"}, \"chainid\": {\"type\": \"string\", \"default\": \"1\", \"description\": \"chain id, default 1 ( Ethereum )\"}}, \"additionalProperties\": false}, \"source\": \"smithery\", \"access_level\": \"read\"}, {\"name\": \"proxy/eth_call\", \"description\": \"Executes a new message call immediately without creating a transaction on the block chain.\", \"inputSchema\": {\"type\": \"object\", \"$schema\": \"http://json-schema.org/draft-07/schema#\", \"required\": [\"to\", \"data\", \"tag\"], \"properties\": {\"to\": {\"type\": \"string\", \"description\": \"the `string` representing the address to interact with\"}, \"tag\": {\"type\": \"string\", \"description\": \"the `string` pre-defined block parameter, either `earliest`, `pending` or `latest`\"}, \"data\": {\"type\": \"string\", \"description\": \"the hash of the method signature and encoded parameters\"}, \"chainid\": {\"type\": \"string\", \"default\": \"1\", \"description\": \"chain id, default 1 ( Ethereum )\"}}, \"additionalProperties\": false}, \"source\": \"smithery\", \"access_level\": \"execute\"}, {\"name\": \"proxy/eth_getCode\", \"description\": \"Returns code at a given address.\", \"inputSchema\": {\"type\": \"object\", \"$schema\": \"http://json-schema.org/draft-07/schema#\", \"required\": [\"address\", \"tag\"], \"properties\": {\"tag\": {\"type\": \"string\", \"description\": \"the `string` pre-defined block parameter, either `earliest`, `pending` or `latest`\"}, \"address\": {\"type\": \"string\", \"description\": \"the `string` representing the address to get code\"}, \"chainid\": {\"type\": \"string\", \"default\": \"1\", \"description\": \"chain id, default 1 ( Ethereum )\"}}, \"additionalProperties\": false}, \"source\": \"smithery\", \"access_level\": \"write\"}, {\"name\": \"proxy/eth_getStorageAt\", \"description\": \"Returns the value from a storage position at a given address.\", \"inputSchema\": {\"type\": \"object\", \"$schema\": \"http://json-schema.org/draft-07/schema#\", \"required\": [\"address\", \"position\", \"tag\"], \"properties\": {\"tag\": {\"type\": \"string\", \"description\": \"the `string` pre-defined block parameter, either `earliest`, `pending` or `latest`\"}, \"address\": {\"type\": \"string\", \"description\": \"the `string` representing the address to get code\"}, \"chainid\": {\"type\": \"string\", \"default\": \"1\", \"description\": \"chain id, default 1 ( Ethereum )\"}, \"position\": {\"type\": \"string\", \"description\": \"the hex code of the position in storage, eg `0x0`\"}}, \"additionalProperties\": false}, \"source\": \"smithery\", \"access_level\": \"write\"}, {\"name\": \"proxy/eth_gasPrice\", \"description\": \"Returns the current price per gas in wei.\", \"inputSchema\": {\"type\": \"object\", \"$schema\": \"http://json-schema.org/draft-07/schema#\", \"properties\": {\"chainid\": {\"type\": \"string\", \"default\": \"1\", \"description\": \"chain id, default 1 ( Ethereum )\"}}, \"additionalProperties\": false}, \"source\": \"smithery\", \"access_level\": \"read\"}, {\"name\": \"proxy/eth_estimateGas\", \"description\": \"Makes a call or transaction, which won't be added to the blockchain and returns the used gas.\", \"inputSchema\": {\"type\": \"object\", \"$schema\": \"http://json-schema.org/draft-07/schema#\", \"required\": [\"data\", \"to\"], \"properties\": {\"to\": {\"type\": \"string\", \"description\": \"the `string` representing the address to interact with\"}, \"gas\": {\"type\": \"string\", \"description\": \"the amount of gas provided for the transaction, in hex eg. `0x5f5e0ff`\"}, \"data\": {\"type\": \"string\", \"description\": \"the hash of the method signature and encoded parameters\"}, \"value\": {\"type\": \"string\", \"description\": \"the value sent in this transaction, in hex eg. `0xff22`\"}, \"chainid\": {\"type\": \"string\", \"default\": \"1\", \"description\": \"chain id, default 1 ( Ethereum )\"}, \"gasPrice\": {\"type\": \"string\", \"description\": \"the gas price paid for each unit of gas, in wei\"}}, \"additionalProperties\": false}, \"source\": \"smithery\", \"access_level\": \"write\"}, {\"name\": \"stats/tokensupply\", \"description\": \"Returns the current amount of an ERC-20 token in circulation.\", \"inputSchema\": {\"type\": \"object\", \"$schema\": \"http://json-schema.org/draft-07/schema#\", \"required\": [\"contractaddress\"], \"properties\": {\"chainid\": {\"type\": \"string\", \"default\": \"1\", \"description\": \"chain id, default 1 ( Ethereum )\"}, \"contractaddress\": {\"type\": \"string\", \"description\": \"the `contract address` of the ERC-20 token\"}}, \"additionalProperties\": false}, \"source\": \"smithery\", \"access_level\": \"read\"}, {\"name\": \"account/tokenbalance\", \"description\": \"Returns the current balance of an ERC-20 token of an address.\", \"inputSchema\": {\"type\": \"object\", \"$schema\": \"http://json-schema.org/draft-07/schema#\", \"required\": [\"contractaddress\", \"address\"], \"properties\": {\"address\": {\"type\": \"string\", \"description\": \"the `string` representing the address to check for token balance\"}, \"chainid\": {\"type\": \"string\", \"default\": \"1\", \"description\": \"chain id, default 1 ( Ethereum )\"}, \"contractaddress\": {\"type\": \"string\", \"description\": \"the `contract address` of the ERC-20 token\"}}, \"additionalProperties\": false}, \"source\": \"smithery\", \"access_level\": \"write\"}, {\"name\": \"gas/gasestimate\", \"description\": \"Returns the estimated time, in seconds, for a transaction to be confirmed on the blockchain.\", \"inputSchema\": {\"type\": \"object\", \"$schema\": \"http://json-schema.org/draft-07/schema#\", \"required\": [\"gasprice\"], \"properties\": {\"chainid\": {\"type\": \"string\", \"default\": \"1\", \"description\": \"chain id, default 1 ( Ethereum )\"}, \"gasprice\": {\"type\": \"string\", \"description\": \"the price paid per unit of gas, in `wei`\"}}, \"additionalProperties\": false}, \"source\": \"smithery\", \"access_level\": \"read\"}, {\"name\": \"gas/gasoracle\", \"description\": \"Returns the current Safe, Proposed and Fast gas prices.\", \"inputSchema\": {\"type\": \"object\", \"$schema\": \"http://json-schema.org/draft-07/schema#\", \"properties\": {\"chainid\": {\"type\": \"string\", \"default\": \"1\", \"description\": \"chain id, default 1 ( Ethereum )\"}}, \"additionalProperties\": false}, \"source\": \"smithery\", \"access_level\": \"read\"}, {\"name\": \"stats/dailyavggaslimit\", \"description\": \"Returns the historical daily average gas limit of the Ethereum network.\", \"inputSchema\": {\"type\": \"object\", \"$schema\": \"http://json-schema.org/draft-07/schema#\", \"required\": [\"startdate\", \"enddate\", \"sort\"], \"properties\": {\"sort\": {\"type\": \"string\", \"description\": \"the sorting preference, use `asc` to sort by ascending and `desc` to sort by descending\"}, \"chainid\": {\"type\": \"string\", \"default\": \"1\", \"description\": \"chain id, default 1 ( Ethereum )\"}, \"enddate\": {\"type\": \"string\", \"description\": \"the ending date in `yyyy-MM-dd` format, eg. `2019-02-28`\"}, \"startdate\": {\"type\": \"string\", \"description\": \"the starting date in `yyyy-MM-dd` format, eg. `2019-01-31`\"}}, \"additionalProperties\": false}, \"source\": \"smithery\", \"access_level\": \"read\"}, {\"name\": \"stats/ethsupply\", \"description\": \"Returns the current amount of Ether in circulation excluding ETH2 Staking rewards and EIP1559 burnt fees.\", \"inputSchema\": {\"type\": \"object\", \"$schema\": \"http://json-schema.org/draft-07/schema#\", \"properties\": {\"chainid\": {\"type\": \"string\", \"default\": \"1\", \"description\": \"chain id, default 1 ( Ethereum )\"}}, \"additionalProperties\": false}, \"source\": \"smithery\", \"access_level\": \"read\"}, {\"name\": \"stats/ethsupply2\", \"description\": \"Returns the current amount of Ether in circulation, ETH2 Staking rewards, EIP1559 burnt fees, and total withdrawn ETH from the beacon chain.\", \"inputSchema\": {\"type\": \"object\", \"$schema\": \"http://json-schema.org/draft-07/schema#\", \"properties\": {\"chainid\": {\"type\": \"string\", \"default\": \"1\", \"description\": \"chain id, default 1 ( Ethereum )\"}}, \"additionalProperties\": false}, \"source\": \"smithery\", \"access_level\": \"read\"}, {\"name\": \"stats/ethprice\", \"description\": \"Returns the latest price of 1 ETH.\", \"inputSchema\": {\"type\": \"object\", \"$schema\": \"http://json-schema.org/draft-07/schema#\", \"properties\": {\"chainid\": {\"type\": \"string\", \"default\": \"1\", \"description\": \"chain id, default 1 ( Ethereum )\"}}, \"additionalProperties\": false}, \"source\": \"smithery\", \"access_level\": \"read\"}, {\"name\": \"stats/chainsize\", \"description\": \"Returns the size of the Ethereum blockchain, in bytes, over a date range.\", \"inputSchema\": {\"type\": \"object\", \"$schema\": \"http://json-schema.org/draft-07/schema#\", \"required\": [\"startdate\", \"enddate\", \"clienttype\", \"syncmode\", \"sort\"], \"properties\": {\"sort\": {\"type\": \"string\", \"description\": \"the sorting preference, use `asc` to sort by ascending and `desc` to sort by descending\"}, \"chainid\": {\"type\": \"string\", \"default\": \"1\", \"description\": \"chain id, default 1 ( Ethereum )\"}, \"enddate\": {\"type\": \"string\", \"description\": \"the ending date in `yyyy-MM-dd` format, eg. `2019-02-28`\"}, \"syncmode\": {\"type\": \"string\", \"description\": \"the type of node to run, either `default` or `archive`\"}, \"startdate\": {\"type\": \"string\", \"description\": \"the starting date in `yyyy-MM-dd` format, eg. `2019-02-01`\"}, \"clienttype\": {\"type\": \"string\", \"description\": \"the Ethereum node client to use, either `geth` or `parity`\"}}, \"additionalProperties\": false}, \"source\": \"smithery\", \"access_level\": \"read\"}, {\"name\": \"stats/nodecount\", \"description\": \"Returns the total number of discoverable Ethereum nodes.\", \"inputSchema\": {\"type\": \"object\", \"$schema\": \"http://json-schema.org/draft-07/schema#\", \"properties\": {\"chainid\": {\"type\": \"string\", \"default\": \"1\", \"description\": \"chain id, default 1 ( Ethereum )\"}}, \"additionalProperties\": false}, \"source\": \"smithery\", \"access_level\": \"read\"}, {\"name\": \"stats/dailytxnfee\", \"description\": \"Returns the amount of transaction fees paid to miners per day.\", \"inputSchema\": {\"type\": \"object\", \"$schema\": \"http://json-schema.org/draft-07/schema#\", \"required\": [\"startdate\", \"enddate\", \"sort\"], \"properties\": {\"sort\": {\"type\": \"string\", \"description\": \"the sorting preference, use `asc` to sort by ascending and `desc` to sort by descending\"}, \"chainid\": {\"type\": \"string\", \"default\": \"1\", \"description\": \"chain id, default 1 ( Ethereum )\"}, \"enddate\": {\"type\": \"string\", \"description\": \"the ending date in `yyyy-MM-dd` format, eg. `2019-02-28`\"}, \"startdate\": {\"type\": \"string\", \"description\": \"the starting date in `yyyy-MM-dd` format, eg. `2019-02-01`\"}}, \"additionalProperties\": false}, \"source\": \"smithery\", \"access_level\": \"read\"}, {\"name\": \"stats/dailynewaddress\", \"description\": \"Returns the number of new Ethereum addresses created per day.\", \"inputSchema\": {\"type\": \"object\", \"$schema\": \"http://json-schema.org/draft-07/schema#\", \"required\": [\"startdate\", \"enddate\", \"sort\"], \"properties\": {\"sort\": {\"type\": \"string\", \"description\": \"the sorting preference, use `asc` to sort by ascending and `desc` to sort by descending\"}, \"chainid\": {\"type\": \"string\", \"default\": \"1\", \"description\": \"chain id, default 1 ( Ethereum )\"}, \"enddate\": {\"type\": \"string\", \"description\": \"the ending date in `yyyy-MM-dd` format, eg. `2019-02-28`\"}, \"startdate\": {\"type\": \"string\", \"description\": \"the starting date in `yyyy-MM-dd` format, eg. `2019-02-01`\"}}, \"additionalProperties\": false}, \"source\": \"smithery\", \"access_level\": \"write\"}, {\"name\": \"stats/dailynetutilization\", \"description\": \"Returns the daily average gas used over gas limit, in percentage.\", \"inputSchema\": {\"type\": \"object\", \"$schema\": \"http://json-schema.org/draft-07/schema#\", \"required\": [\"startdate\", \"enddate\", \"sort\"], \"properties\": {\"sort\": {\"type\": \"string\", \"description\": \"the sorting preference, use `asc` to sort by ascending and `desc` to sort by descending\"}, \"chainid\": {\"type\": \"string\", \"default\": \"1\", \"description\": \"chain id, default 1 ( Ethereum )\"}, \"enddate\": {\"type\": \"string\", \"description\": \"the ending date in `yyyy-MM-dd` format, eg. `2019-02-28`\"}, \"startdate\": {\"type\": \"string\", \"description\": \"the starting date in `yyyy-MM-dd` format, eg. `2019-02-01`\"}}, \"additionalProperties\": false}, \"source\": \"smithery\", \"access_level\": \"read\"}, {\"name\": \"stats/dailyavghashrate\", \"description\": \"Returns the historical measure of processing power of the Ethereum network.\", \"inputSchema\": {\"type\": \"object\", \"$schema\": \"http://json-schema.org/draft-07/schema#\", \"required\": [\"startdate\", \"enddate\", \"sort\"], \"properties\": {\"sort\": {\"type\": \"string\", \"description\": \"the sorting preference, use `asc` to sort by ascending and `desc` to sort by descending\"}, \"chainid\": {\"type\": \"string\", \"default\": \"1\", \"description\": \"chain id, default 1 ( Ethereum )\"}, \"enddate\": {\"type\": \"string\", \"description\": \"the ending date in `yyyy-MM-dd` format, eg. `2019-02-28`\"}, \"startdate\": {\"type\": \"string\", \"description\": \"the starting date in `yyyy-MM-dd` format, eg. `2019-02-01`\"}}, \"additionalProperties\": false}, \"source\": \"smithery\", \"access_level\": \"read\"}, {\"name\": \"stats/dailytx\", \"description\": \"Returns the number of transactions performed on the Ethereum blockchain per day.\", \"inputSchema\": {\"type\": \"object\", \"$schema\": \"http://json-schema.org/draft-07/schema#\", \"required\": [\"startdate\", \"enddate\", \"sort\"], \"properties\": {\"sort\": {\"type\": \"string\", \"description\": \"the sorting preference, use `asc` to sort by ascending and `desc` to sort by descending\"}, \"chainid\": {\"type\": \"string\", \"default\": \"1\", \"description\": \"chain id, default 1 ( Ethereum )\"}, \"enddate\": {\"type\": \"string\", \"description\": \"the ending date in `yyyy-MM-dd` format, eg. `2019-02-28`\"}, \"startdate\": {\"type\": \"string\", \"description\": \"the starting date in `yyyy-MM-dd` format, eg. `2019-02-01`\"}}, \"additionalProperties\": false}, \"source\": \"smithery\", \"access_level\": \"read\"}, {\"name\": \"stats/dailyavgnetdifficulty\", \"description\": \"Returns the historical mining difficulty of the Ethereum network.\", \"inputSchema\": {\"type\": \"object\", \"$schema\": \"http://json-schema.org/draft-07/schema#\", \"required\": [\"startdate\", \"enddate\", \"sort\"], \"properties\": {\"sort\": {\"type\": \"string\", \"description\": \"the sorting preference, use `asc` to sort by ascending and `desc` to sort by descending\"}, \"chainid\": {\"type\": \"string\", \"default\": \"1\", \"description\": \"chain id, default 1 ( Ethereum )\"}, \"enddate\": {\"type\": \"string\", \"description\": \"the ending date in `yyyy-MM-dd` format, eg. `2019-02-28`\"}, \"startdate\": {\"type\": \"string\", \"description\": \"the starting date in `yyyy-MM-dd` format, eg. `2019-02-01`\"}}, \"additionalProperties\": false}, \"source\": \"smithery\", \"access_level\": \"read\"}, {\"name\": \"stats/ethdailyprice\", \"description\": \"Returns the historical price of 1 ETH.\", \"inputSchema\": {\"type\": \"object\", \"$schema\": \"http://json-schema.org/draft-07/schema#\", \"required\": [\"startdate\", \"enddate\", \"sort\"], \"properties\": {\"sort\": {\"type\": \"string\", \"description\": \"the sorting preference, use `asc` to sort by ascending and `desc` to sort by descending\"}, \"chainid\": {\"type\": \"string\", \"default\": \"1\", \"description\": \"chain id, default 1 ( Ethereum )\"}, \"enddate\": {\"type\": \"string\", \"description\": \"the ending date in `yyyy-MM-dd` format, eg. `2019-02-28`\"}, \"startdate\": {\"type\": \"string\", \"description\": \"the starting date in `yyyy-MM-dd` format, eg. `2019-02-01`\"}}, \"additionalProperties\": false}, \"source\": \"smithery\", \"access_level\": \"read\"}], \"tools_count\": 55, \"homepage\": \"https://smithery.ai/server/@xiaok/etherscan-mcp-server\", \"url\": \"\", \"topics\": [], \"data_sources\": [\"smithery\"]}", "target": "", "id": "@xiaok/etherscan-mcp-server", "metadata": {"stage": "finance_filter"}}
{"input": "ONLY RESPOND WITH JSON. NO EXPLANATIONS. NO MARKDOWN. NO TEXT OUTSIDE JSON.\n\nAnalyze the MCP server for financial relevance. Look for keywords: payment, banking, credit, loan, finance, money, currency, crypto, investment, trading, portfolio, market, exchange, wallet, account, budget, expense, income, tax, invoice, billing, accounting, insurance, compliance, KYC, AML.\n\nJSON FORMAT (NOTHING ELSE):\n{\n  \"server_name\": \"string\",\n  \"server_id\": \"string\", \n  \"is_finance_llm\": \"yes|no|unclear\",\n  \"confidence\": \"high|medium|low\",\n  \"threat_models\": [],\n  \"analysis_notes\": \"Brief reason\"\n}\n\nIf financial keywords found: is_finance_llm=\"yes\". If not: is_finance_llm=\"no\". If unclear: is_finance_llm=\"unclear\".\n\nRESPOND ONLY WITH JSON.\n\nMCP Server Data:\n{\"server_name\": \"Blockscout MCP Server\", \"server_id\": \"@blockscout/mcp-server\", \"description\": \"Provide AI agents and automation tools with contextual access to blockchain data including balances, tokens, NFTs, and contract metadata. Enable multi-chain support and deliver enhanced user experience with progress notifications for long-running queries. Facilitate seamless integration with AI hosts like Claude Desktop for blockchain data analysis.\", \"readme\": \"\", \"tools\": [{\"name\": \"__get_instructions__\", \"description\": \"\\n    This tool MUST be called BEFORE any other tool.\\n    Without calling it, the MCP server will not work as expected.\\n    It MUST be called once in a session.\\n    \", \"inputSchema\": {\"type\": \"object\", \"title\": \"__get_instructions__Arguments\", \"properties\": {}}, \"source\": \"smithery\", \"access_level\": \"read\"}, {\"name\": \"get_block_info\", \"description\": \"\\n    Get block information like timestamp, gas used, burnt fees, transaction count etc.\\n    Can optionally include the list of transaction hashes contained in the block. Transaction hashes are omitted by default; request them only when you truly need them, because on high-traffic chains the list may exhaust the context.\\n    \", \"inputSchema\": {\"type\": \"object\", \"title\": \"get_block_infoArguments\", \"required\": [\"chain_id\", \"number_or_hash\"], \"properties\": {\"chain_id\": {\"type\": \"string\", \"title\": \"Chain Id\", \"description\": \"The ID of the blockchain\"}, \"number_or_hash\": {\"type\": \"string\", \"title\": \"Number Or Hash\", \"description\": \"Block number or hash\"}, \"include_transactions\": {\"anyOf\": [{\"type\": \"boolean\"}, {\"type\": \"null\"}], \"title\": \"Include Transactions\", \"default\": false, \"description\": \"If true, includes a list of transaction hashes from the block.\"}}}, \"source\": \"smithery\", \"access_level\": \"read\"}, {\"name\": \"get_latest_block\", \"description\": \"\\n    Get the latest indexed block number and timestamp, which represents the most recent state of the blockchain. \\n    No transactions or token transfers can exist beyond this point, making it useful as a reference timestamp for other API calls.\\n    \", \"inputSchema\": {\"type\": \"object\", \"title\": \"get_latest_blockArguments\", \"required\": [\"chain_id\"], \"properties\": {\"chain_id\": {\"type\": \"string\", \"title\": \"Chain Id\", \"description\": \"The ID of the blockchain\"}}}, \"source\": \"smithery\", \"access_level\": \"read\"}, {\"name\": \"get_address_by_ens_name\", \"description\": \"\\n    Useful for when you need to convert an ENS domain name (e.g. \\\"blockscout.eth\\\")\\n    to its corresponding Ethereum address.\\n    \", \"inputSchema\": {\"type\": \"object\", \"title\": \"get_address_by_ens_nameArguments\", \"required\": [\"name\"], \"properties\": {\"name\": {\"type\": \"string\", \"title\": \"Name\", \"description\": \"ENS domain name to resolve\"}}}, \"source\": \"smithery\", \"access_level\": \"write\"}, {\"name\": \"get_transactions_by_address\", \"description\": \"\\n    Get transactions for an address within a specific time range.\\n    Use cases:\\n      - `get_transactions_by_address(address, age_from)` - get all transactions to/from the address since the given date up to the current time\\n      - `get_transactions_by_address(address, age_from, age_to)` - get all transactions to/from the address between the given dates\\n      - `get_transactions_by_address(address, age_from, age_to, methods)` - get all transactions to/from the address between the given dates and invoking the given method signature\\n    Manipulating `age_from` and `age_to` allows you to paginate through results by time ranges.\\n    \", \"inputSchema\": {\"type\": \"object\", \"title\": \"get_transactions_by_addressArguments\", \"required\": [\"chain_id\", \"address\"], \"properties\": {\"age_to\": {\"anyOf\": [{\"type\": \"string\"}, {\"type\": \"null\"}], \"title\": \"Age To\", \"default\": null, \"description\": \"End date and time (e.g 2025-05-22T22:30:00.00Z).\"}, \"address\": {\"type\": \"string\", \"title\": \"Address\", \"description\": \"Address which either sender or receiver of the transaction\"}, \"methods\": {\"anyOf\": [{\"type\": \"string\"}, {\"type\": \"null\"}], \"title\": \"Methods\", \"default\": null, \"description\": \"A method signature to filter transactions by (e.g 0x304e6ade)\"}, \"age_from\": {\"anyOf\": [{\"type\": \"string\"}, {\"type\": \"null\"}], \"title\": \"Age From\", \"default\": null, \"description\": \"Start date and time (e.g 2025-05-22T23:00:00.00Z).\"}, \"chain_id\": {\"type\": \"string\", \"title\": \"Chain Id\", \"description\": \"The ID of the blockchain\"}}}, \"source\": \"smithery\", \"access_level\": \"write\"}, {\"name\": \"get_token_transfers_by_address\", \"description\": \"\\n    Get ERC-20 token transfers for an address within a specific time range.\\n    Use cases:\\n      - `get_token_transfers_by_address(address, age_from)` - get all transfers of any ERC-20 token to/from the address since the given date up to the current time\\n      - `get_token_transfers_by_address(address, age_from, age_to)` - get all transfers of any ERC-20 token to/from the address between the given dates\\n      - `get_token_transfers_by_address(address, age_from, age_to, token)` - get all transfers of the given ERC-20 token to/from the address between the given dates\\n    Manipulating `age_from` and `age_to` allows you to paginate through results by time ranges. For example, after getting transfers up to a certain timestamp, you can use that timestamp as `age_to` in the next query to get the next page of older transfers.\\n    \", \"inputSchema\": {\"type\": \"object\", \"title\": \"get_token_transfers_by_addressArguments\", \"required\": [\"chain_id\", \"address\"], \"properties\": {\"token\": {\"anyOf\": [{\"type\": \"string\"}, {\"type\": \"null\"}], \"title\": \"Token\", \"default\": null, \"description\": \"An ERC-20 token contract address to filter transfers by a specific token. If omitted, returns transfers of all tokens.\"}, \"age_to\": {\"anyOf\": [{\"type\": \"string\"}, {\"type\": \"null\"}], \"title\": \"Age To\", \"default\": null, \"description\": \"End date and time (e.g 2025-05-22T22:30:00.00Z). Can be omitted to get all transfers up to the current time.\"}, \"address\": {\"type\": \"string\", \"title\": \"Address\", \"description\": \"Address which either transfer initiator or transfer receiver\"}, \"age_from\": {\"anyOf\": [{\"type\": \"string\"}, {\"type\": \"null\"}], \"title\": \"Age From\", \"default\": null, \"description\": \"Start date and time (e.g 2025-05-22T23:00:00.00Z). This parameter should be provided in most cases to limit transfers and avoid heavy database queries. Omit only if you absolutely need the full history.\"}, \"chain_id\": {\"type\": \"string\", \"title\": \"Chain Id\", \"description\": \"The ID of the blockchain\"}}}, \"source\": \"smithery\", \"access_level\": \"write\"}, {\"name\": \"lookup_token_by_symbol\", \"description\": \"\\n    Search for token addresses by symbol or name. Returns multiple potential\\n    matches based on symbol or token name similarity. Only the first\\n    ``TOKEN_RESULTS_LIMIT`` matches from the Blockscout API are returned.\\n    \", \"inputSchema\": {\"type\": \"object\", \"title\": \"lookup_token_by_symbolArguments\", \"required\": [\"chain_id\", \"symbol\"], \"properties\": {\"symbol\": {\"type\": \"string\", \"title\": \"Symbol\", \"description\": \"Token symbol or name to search for\"}, \"chain_id\": {\"type\": \"string\", \"title\": \"Chain Id\", \"description\": \"The ID of the blockchain\"}}}, \"source\": \"smithery\", \"access_level\": \"write\"}, {\"name\": \"get_contract_abi\", \"description\": \"\\n    Get smart contract ABI (Application Binary Interface).\\n    An ABI defines all functions, events, their parameters, and return types. The ABI is required to format function calls or interpret contract data.\\n    \", \"inputSchema\": {\"type\": \"object\", \"title\": \"get_contract_abiArguments\", \"required\": [\"chain_id\", \"address\"], \"properties\": {\"address\": {\"type\": \"string\", \"title\": \"Address\", \"description\": \"Smart contract address\"}, \"chain_id\": {\"type\": \"string\", \"title\": \"Chain Id\", \"description\": \"The ID of the blockchain\"}}}, \"source\": \"smithery\", \"access_level\": \"read\"}, {\"name\": \"get_address_info\", \"description\": \"\\n    Get comprehensive information about an address, including:\\n    - Address existence check\\n    - Native token (ETH) balance (provided as is, without adjusting by decimals)\\n    - ENS name association (if any)\\n    - Contract status (whether the address is a contract, whether it is verified)\\n    - Proxy contract information (if applicable): determines if a smart contract is a proxy contract (which forwards calls to implementation contracts), including proxy type and implementation addresses\\n    - Token details (if the contract is a token): name, symbol, decimals, total supply, etc.\\n    Essential for address analysis, contract investigation, token research, and DeFi protocol analysis.\\n    \", \"inputSchema\": {\"type\": \"object\", \"title\": \"get_address_infoArguments\", \"required\": [\"chain_id\", \"address\"], \"properties\": {\"address\": {\"type\": \"string\", \"title\": \"Address\", \"description\": \"Address to get information about\"}, \"chain_id\": {\"type\": \"string\", \"title\": \"Chain Id\", \"description\": \"The ID of the blockchain\"}}}, \"source\": \"smithery\", \"access_level\": \"write\"}, {\"name\": \"get_tokens_by_address\", \"description\": \"\\n    Get comprehensive ERC20 token holdings for an address with enriched metadata and market data.\\n    Returns detailed token information including contract details (name, symbol, decimals), market metrics (exchange rate, market cap, volume), holders count, and actual balance (provided as is, without adjusting by decimals).\\n    Supports pagination.\\n    Essential for portfolio analysis, wallet auditing, and DeFi position tracking.\\n    \", \"inputSchema\": {\"type\": \"object\", \"title\": \"get_tokens_by_addressArguments\", \"required\": [\"chain_id\", \"address\"], \"properties\": {\"cursor\": {\"anyOf\": [{\"type\": \"string\"}, {\"type\": \"null\"}], \"title\": \"Cursor\", \"default\": null, \"description\": \"The pagination cursor from a previous response to get the next page of results.\"}, \"address\": {\"type\": \"string\", \"title\": \"Address\", \"description\": \"Wallet address\"}, \"chain_id\": {\"type\": \"string\", \"title\": \"Chain Id\", \"description\": \"The ID of the blockchain\"}}}, \"source\": \"smithery\", \"access_level\": \"write\"}, {\"name\": \"transaction_summary\", \"description\": \"\\n    Get human-readable transaction summaries from Blockscout Transaction Interpreter.\\n    Automatically classifies transactions into natural language descriptions (transfers, swaps, NFT sales, DeFi operations)\\n    Essential for rapid transaction comprehension, dashboard displays, and initial analysis.\\n    Note: Not all transactions can be summarized and accuracy is not guaranteed for complex patterns.\\n    \", \"inputSchema\": {\"type\": \"object\", \"title\": \"transaction_summaryArguments\", \"required\": [\"chain_id\", \"transaction_hash\"], \"properties\": {\"chain_id\": {\"type\": \"string\", \"title\": \"Chain Id\", \"description\": \"The ID of the blockchain\"}, \"transaction_hash\": {\"type\": \"string\", \"title\": \"Transaction Hash\", \"description\": \"Transaction hash\"}}}, \"source\": \"smithery\", \"access_level\": \"read\"}, {\"name\": \"nft_tokens_by_address\", \"description\": \"\\n    Retrieve NFT tokens (ERC-721, ERC-404, ERC-1155) owned by an address, grouped by collection.\\n    Provides collection details (type, address, name, symbol, total supply, holder count) and individual token instance data (ID, name, description, external URL, metadata attributes).\\n    Essential for a detailed overview of an address's digital collectibles and their associated collection data.\\n    \", \"inputSchema\": {\"type\": \"object\", \"title\": \"nft_tokens_by_addressArguments\", \"required\": [\"chain_id\", \"address\"], \"properties\": {\"cursor\": {\"anyOf\": [{\"type\": \"string\"}, {\"type\": \"null\"}], \"title\": \"Cursor\", \"default\": null, \"description\": \"The pagination cursor from a previous response to get the next page of results.\"}, \"address\": {\"type\": \"string\", \"title\": \"Address\", \"description\": \"NFT owner address\"}, \"chain_id\": {\"type\": \"string\", \"title\": \"Chain Id\", \"description\": \"The ID of the blockchain\"}}}, \"source\": \"smithery\", \"access_level\": \"write\"}, {\"name\": \"get_transaction_info\", \"description\": \"\\n    Get comprehensive transaction information. \\n    Unlike standard eth_getTransactionByHash, this tool returns enriched data including decoded input parameters, detailed token transfers with token metadata, transaction fee breakdown (priority fees, burnt fees) and categorized transaction types.\\n    By default, the raw transaction input is omitted if a decoded version is available to save context; request it with `include_raw_input=True` only when you truly need the raw hex data.\\n    Essential for transaction analysis, debugging smart contract interactions, tracking DeFi operations.\\n    \", \"inputSchema\": {\"type\": \"object\", \"title\": \"get_transaction_infoArguments\", \"required\": [\"chain_id\", \"transaction_hash\"], \"properties\": {\"chain_id\": {\"type\": \"string\", \"title\": \"Chain Id\", \"description\": \"The ID of the blockchain\"}, \"transaction_hash\": {\"type\": \"string\", \"title\": \"Transaction Hash\", \"description\": \"Transaction hash\"}, \"include_raw_input\": {\"anyOf\": [{\"type\": \"boolean\"}, {\"type\": \"null\"}], \"title\": \"Include Raw Input\", \"default\": false, \"description\": \"If true, includes the raw transaction input data.\"}}}, \"source\": \"smithery\", \"access_level\": \"write\"}, {\"name\": \"get_transaction_logs\", \"description\": \"\\n    Get comprehensive transaction logs.\\n    Unlike standard eth_getLogs, this tool returns enriched logs, primarily focusing on decoded event parameters with their types and values (if event decoding is applicable).\\n    Essential for analyzing smart contract events, tracking token transfers, monitoring DeFi protocol interactions, debugging event emissions, and understanding complex multi-contract transaction flows.\\n    \", \"inputSchema\": {\"type\": \"object\", \"title\": \"get_transaction_logsArguments\", \"required\": [\"chain_id\", \"transaction_hash\"], \"properties\": {\"cursor\": {\"anyOf\": [{\"type\": \"string\"}, {\"type\": \"null\"}], \"title\": \"Cursor\", \"default\": null, \"description\": \"The pagination cursor from a previous response to get the next page of results.\"}, \"chain_id\": {\"type\": \"string\", \"title\": \"Chain Id\", \"description\": \"The ID of the blockchain\"}, \"transaction_hash\": {\"type\": \"string\", \"title\": \"Transaction Hash\", \"description\": \"Transaction hash\"}}}, \"source\": \"smithery\", \"access_level\": \"read\"}, {\"name\": \"get_address_logs\", \"description\": \"\\n    Get comprehensive logs emitted by a specific address.\\n    Returns enriched logs, primarily focusing on decoded event parameters with their types and values (if event decoding is applicable).\\n    Essential for analyzing smart contract events emitted by specific addresses, monitoring token contract activities, tracking DeFi protocol state changes, debugging contract event emissions, and understanding address-specific event history flows.\\n    \", \"inputSchema\": {\"type\": \"object\", \"title\": \"get_address_logsArguments\", \"required\": [\"chain_id\", \"address\"], \"properties\": {\"cursor\": {\"anyOf\": [{\"type\": \"string\"}, {\"type\": \"null\"}], \"title\": \"Cursor\", \"default\": null, \"description\": \"The pagination cursor from a previous response to get the next page of results.\"}, \"address\": {\"type\": \"string\", \"title\": \"Address\", \"description\": \"Account address\"}, \"chain_id\": {\"type\": \"string\", \"title\": \"Chain Id\", \"description\": \"The ID of the blockchain\"}}}, \"source\": \"smithery\", \"access_level\": \"write\"}, {\"name\": \"get_chains_list\", \"description\": \"\\n    Get the list of known blockchain chains with their IDs.\\n    Useful for getting a chain ID when the chain name is known. This information can be used in other tools that require a chain ID to request information.\\n    \", \"inputSchema\": {\"type\": \"object\", \"title\": \"get_chains_listArguments\", \"properties\": {}}, \"source\": \"smithery\", \"access_level\": \"read\"}], \"tools_count\": 16, \"homepage\": \"https://smithery.ai/server/@blockscout/mcp-server\", \"url\": \"\", \"topics\": [], \"data_sources\": [\"smithery\"]}", "target": "", "id": "@blockscout/mcp-server", "metadata": {"stage": "finance_filter"}}
{"input": "ONLY RESPOND WITH JSON. NO EXPLANATIONS. NO MARKDOWN. NO TEXT OUTSIDE JSON.\n\nAnalyze the MCP server for financial relevance. Look for keywords: payment, banking, credit, loan, finance, money, currency, crypto, investment, trading, portfolio, market, exchange, wallet, account, budget, expense, income, tax, invoice, billing, accounting, insurance, compliance, KYC, AML.\n\nJSON FORMAT (NOTHING ELSE):\n{\n  \"server_name\": \"string\",\n  \"server_id\": \"string\", \n  \"is_finance_llm\": \"yes|no|unclear\",\n  \"confidence\": \"high|medium|low\",\n  \"threat_models\": [],\n  \"analysis_notes\": \"Brief reason\"\n}\n\nIf financial keywords found: is_finance_llm=\"yes\". If not: is_finance_llm=\"no\". If unclear: is_finance_llm=\"unclear\".\n\nRESPOND ONLY WITH JSON.\n\nMCP Server Data:\n{\"server_name\": \"Binance Cryptocurrency Market Data Service\", \"server_id\": \"@snjyor/binance-mcp-data\", \"description\": \"Provide real-time cryptocurrency market data from Binance directly to AI agents. Access current prices, order books, candlestick charts, trading history, and price statistics seamlessly. Enable AI-driven queries about the latest market trends without visiting external sites.\", \"readme\": \"\", \"tools\": [{\"name\": \"get_order_book\", \"description\": \"\", \"inputSchema\": {\"type\": \"object\", \"$schema\": \"http://json-schema.org/draft-07/schema#\", \"required\": [\"symbol\"], \"properties\": {\"limit\": {\"type\": \"number\", \"description\": \"Order book depth, default 100, max 5000\"}, \"symbol\": {\"type\": \"string\", \"description\": \"Trading pair symbol, e.g. BTCUSDT\"}}, \"additionalProperties\": false}, \"source\": \"smithery\", \"access_level\": \"read\"}, {\"name\": \"get_recent_trades\", \"description\": \"\", \"inputSchema\": {\"type\": \"object\", \"$schema\": \"http://json-schema.org/draft-07/schema#\", \"required\": [\"symbol\"], \"properties\": {\"limit\": {\"type\": \"number\", \"description\": \"Number of trades to return, default 500, max 1000\"}, \"symbol\": {\"type\": \"string\", \"description\": \"Trading pair symbol, e.g. BTCUSDT\"}}, \"additionalProperties\": false}, \"source\": \"smithery\", \"access_level\": \"execute\"}, {\"name\": \"get_historical_trades\", \"description\": \"\", \"inputSchema\": {\"type\": \"object\", \"$schema\": \"http://json-schema.org/draft-07/schema#\", \"required\": [\"symbol\"], \"properties\": {\"limit\": {\"type\": \"number\", \"description\": \"Number of trades to return, default 500, max 1000\"}, \"fromId\": {\"type\": \"number\", \"description\": \"Trade ID to start from, default returns the most recent trades\"}, \"symbol\": {\"type\": \"string\", \"description\": \"Trading pair symbol, e.g. BTCUSDT\"}}, \"additionalProperties\": false}, \"source\": \"smithery\", \"access_level\": \"execute\"}, {\"name\": \"get_aggregate_trades\", \"description\": \"\", \"inputSchema\": {\"type\": \"object\", \"$schema\": \"http://json-schema.org/draft-07/schema#\", \"required\": [\"symbol\"], \"properties\": {\"limit\": {\"type\": \"number\", \"description\": \"Number of trades to return, default 500, max 1000\"}, \"fromId\": {\"type\": \"number\", \"description\": \"Aggregate trade ID to start from\"}, \"symbol\": {\"type\": \"string\", \"description\": \"Trading pair symbol, e.g. BTCUSDT\"}, \"endTime\": {\"type\": \"number\", \"description\": \"End timestamp (milliseconds)\"}, \"startTime\": {\"type\": \"number\", \"description\": \"Start timestamp (milliseconds)\"}}, \"additionalProperties\": false}, \"source\": \"smithery\", \"access_level\": \"execute\"}, {\"name\": \"get_klines\", \"description\": \"\", \"inputSchema\": {\"type\": \"object\", \"$schema\": \"http://json-schema.org/draft-07/schema#\", \"required\": [\"symbol\", \"interval\"], \"properties\": {\"limit\": {\"type\": \"number\", \"description\": \"Number of K-lines to return, default 500, max 1000\"}, \"symbol\": {\"type\": \"string\", \"description\": \"Trading pair symbol, e.g. BTCUSDT\"}, \"endTime\": {\"type\": \"number\", \"description\": \"End timestamp (milliseconds)\"}, \"interval\": {\"type\": \"string\", \"description\": \"K-line interval, e.g. 1m, 3m, 5m, 15m, 30m, 1h, 2h, 4h, 6h, 8h, 12h, 1d, 3d, 1w, 1M\"}, \"timeZone\": {\"type\": \"string\", \"description\": \"Time zone, default UTC\"}, \"startTime\": {\"type\": \"number\", \"description\": \"Start timestamp (milliseconds)\"}}, \"additionalProperties\": false}, \"source\": \"smithery\", \"access_level\": \"read\"}, {\"name\": \"get_ui_klines\", \"description\": \"\", \"inputSchema\": {\"type\": \"object\", \"$schema\": \"http://json-schema.org/draft-07/schema#\", \"required\": [\"symbol\", \"interval\"], \"properties\": {\"limit\": {\"type\": \"number\", \"description\": \"Number of K-lines to return, default 500, max 1000\"}, \"symbol\": {\"type\": \"string\", \"description\": \"Trading pair symbol, e.g. BTCUSDT\"}, \"endTime\": {\"type\": \"number\", \"description\": \"End timestamp (milliseconds)\"}, \"interval\": {\"type\": \"string\", \"description\": \"K-line interval, e.g. 1m, 3m, 5m, 15m, 30m, 1h, 2h, 4h, 6h, 8h, 12h, 1d, 3d, 1w, 1M\"}, \"timeZone\": {\"type\": \"string\", \"description\": \"Time zone, default UTC\"}, \"startTime\": {\"type\": \"number\", \"description\": \"Start timestamp (milliseconds)\"}}, \"additionalProperties\": false}, \"source\": \"smithery\", \"access_level\": \"read\"}, {\"name\": \"get_avg_price\", \"description\": \"\", \"inputSchema\": {\"type\": \"object\", \"$schema\": \"http://json-schema.org/draft-07/schema#\", \"required\": [\"symbol\"], \"properties\": {\"symbol\": {\"type\": \"string\", \"description\": \"Trading pair symbol, e.g. BTCUSDT\"}}, \"additionalProperties\": false}, \"source\": \"smithery\", \"access_level\": \"read\"}, {\"name\": \"get_24hr_ticker\", \"description\": \"\", \"inputSchema\": {\"type\": \"object\", \"$schema\": \"http://json-schema.org/draft-07/schema#\", \"properties\": {\"symbol\": {\"type\": \"string\", \"description\": \"Trading pair symbol, e.g. BTCUSDT\"}, \"symbols\": {\"type\": \"array\", \"items\": {\"type\": \"string\"}, \"description\": \"Array of multiple trading pair symbols\"}}, \"additionalProperties\": false}, \"source\": \"smithery\", \"access_level\": \"read\"}, {\"name\": \"get_trading_day_ticker\", \"description\": \"\", \"inputSchema\": {\"type\": \"object\", \"$schema\": \"http://json-schema.org/draft-07/schema#\", \"properties\": {\"type\": {\"enum\": [\"FULL\", \"MINI\"], \"type\": \"string\", \"description\": \"Return data type, FULL or MINI\"}, \"symbol\": {\"type\": \"string\", \"description\": \"Trading pair symbol, e.g. BTCUSDT\"}, \"symbols\": {\"type\": \"array\", \"items\": {\"type\": \"string\"}, \"description\": \"Array of multiple trading pair symbols\"}, \"timeZone\": {\"type\": \"number\", \"description\": \"Time zone, default 0\"}}, \"additionalProperties\": false}, \"source\": \"smithery\", \"access_level\": \"read\"}, {\"name\": \"get_price\", \"description\": \"\", \"inputSchema\": {\"type\": \"object\", \"$schema\": \"http://json-schema.org/draft-07/schema#\", \"properties\": {\"symbol\": {\"type\": \"string\", \"description\": \"Trading pair symbol, e.g. BTCUSDT\"}, \"symbols\": {\"type\": \"array\", \"items\": {\"type\": \"string\"}, \"description\": \"Array of multiple trading pair symbols\"}}, \"additionalProperties\": false}, \"source\": \"smithery\", \"access_level\": \"read\"}, {\"name\": \"get_book_ticker\", \"description\": \"\", \"inputSchema\": {\"type\": \"object\", \"$schema\": \"http://json-schema.org/draft-07/schema#\", \"properties\": {\"symbol\": {\"type\": \"string\", \"description\": \"Trading pair symbol, e.g. BTCUSDT\"}, \"symbols\": {\"type\": \"array\", \"items\": {\"type\": \"string\"}, \"description\": \"Array of multiple trading pair symbols\"}}, \"additionalProperties\": false}, \"source\": \"smithery\", \"access_level\": \"read\"}, {\"name\": \"get_rolling_window_ticker\", \"description\": \"\", \"inputSchema\": {\"type\": \"object\", \"$schema\": \"http://json-schema.org/draft-07/schema#\", \"properties\": {\"type\": {\"enum\": [\"FULL\", \"MINI\"], \"type\": \"string\", \"description\": \"Return data type, FULL or MINI\"}, \"symbol\": {\"type\": \"string\", \"description\": \"Trading pair symbol, e.g. BTCUSDT\"}, \"symbols\": {\"type\": \"array\", \"items\": {\"type\": \"string\"}, \"description\": \"Array of multiple trading pair symbols\"}, \"windowSize\": {\"type\": \"string\", \"description\": \"Window size, e.g. 1m, 4h, 1d\"}}, \"additionalProperties\": false}, \"source\": \"smithery\", \"access_level\": \"read\"}], \"tools_count\": 12, \"homepage\": \"https://smithery.ai/server/@snjyor/binance-mcp-data\", \"url\": \"\", \"topics\": [], \"data_sources\": [\"smithery\"]}", "target": "", "id": "@snjyor/binance-mcp-data", "metadata": {"stage": "finance_filter"}}
{"input": "ONLY RESPOND WITH JSON. NO EXPLANATIONS. NO MARKDOWN. NO TEXT OUTSIDE JSON.\n\nAnalyze the MCP server for financial relevance. Look for keywords: payment, banking, credit, loan, finance, money, currency, crypto, investment, trading, portfolio, market, exchange, wallet, account, budget, expense, income, tax, invoice, billing, accounting, insurance, compliance, KYC, AML.\n\nJSON FORMAT (NOTHING ELSE):\n{\n  \"server_name\": \"string\",\n  \"server_id\": \"string\", \n  \"is_finance_llm\": \"yes|no|unclear\",\n  \"confidence\": \"high|medium|low\",\n  \"threat_models\": [],\n  \"analysis_notes\": \"Brief reason\"\n}\n\nIf financial keywords found: is_finance_llm=\"yes\". If not: is_finance_llm=\"no\". If unclear: is_finance_llm=\"unclear\".\n\nRESPOND ONLY WITH JSON.\n\nMCP Server Data:\n{\"server_name\": \"Heurist Mesh network\", \"server_id\": \"heurist-network/heurist-agent-framework\", \"description\": \"[Heurist Mesh Agent](https://github.com/heurist-network/heurist-mesh-mcp-server) - Access specialized web3 AI agents for blockchain analysis, smart contract security, token metrics, and blockchain interactions through the [Heurist Mesh network](https://github.com/heurist-network/heurist-agent-framework/tree/main/mesh).\", \"readme\": \"<div align=\\\"center\\\">\\n    <img src=\\\"./docs/img/agent-framework-poster.jpg\\\" alt=\\\"Heurist Agent Framework Banner\\\" width=\\\"100%\\\" />\\n</div>\\n\\n# Heurist Agent Framework\\n\\nA flexible multi-interface AI agent framework that can interact through various platforms including Telegram, Discord, Twitter, Farcaster, REST API, and MCP.\\n\\nGrab a Heurist API Key instantly for free by using the code 'agent' while submitting the form on https://heurist.ai/dev-access\\n\\n---\\n\\n## Overview\\n\\nThe Heurist Agent Framework is built on a modular architecture that allows an AI agent to:\\n\\n- Process text and voice messages\\n- Generate images and videos\\n- Interact across multiple platforms with consistent behavior\\n- Fetch and store information in a knowledge base (Postgres and SQLite supported)\\n- Access external APIs, tools, and a wide range of [Mesh Agents](./mesh/README.md) to compose complex workflows\\n\\n## Table of Contents\\n\\n- [Features](#features)\\n- [Heurist Mesh](#heurist-mesh)\\n  - [MCP Support](#mcp-support)\\n  - [Recommended Mesh Agents](#recommended-mesh-agents)\\n  - [Full List of Mesh Agents](#full-list-of-mesh-agents)\\n  - [Usage and Development Guide](#usage-and-development-guide)\\n- [Heurist Agent Framework Architecture](#heurist-agent-framework-architecture)\\n  - [Agent Structure](#agent-structure)\\n  - [Agent Interfaces](#agent-interfaces)\\n  - [Heurist Core](#heurist-core)\\n    - [Components](#components)\\n    - [Workflows](#workflows)\\n    - [Tool Management](#tool-management)\\n    - [External Clients](#external-clients)\\n  - [Agent Usage and Development Guide](#agent-usage-and-development-guide)\\n- [Development Setup](#development-setup)\\n- [How to Use GitHub Issues](#how-to-use-github-issues)\\n- [License](#license)\\n- [Contributing](#contributing)\\n- [Support](#support)\\n- [Star History](#star-history)\\n\\n## Features\\n\\n- \\ud83e\\udd16 **Core Agent** - Modular framework with advanced LLM integration\\n- \\ud83e\\udde9 **Component Architecture** - Plug-and-play components for flexible agent or agentic application design\\n- \\ud83d\\udd04 **Workflow System** - RAG, Chain of Thought, and Research workflows\\n- \\ud83d\\uddbc\\ufe0f **Media Generation** - Image creation and processing capabilities\\n- \\ud83c\\udfa4 **Voice Processing** - Audio transcription and text-to-speech\\n- \\ud83d\\udcbe **Vector Storage** - Knowledge retrieval with PostgreSQL/SQLite support\\n- \\ud83d\\udee0\\ufe0f **Tool Integration** - Extensible tool framework with MCP support\\n- \\ud83c\\udf10 **Mesh Agent Access** - Connect to community-contributed specialized agents via API or MCP\\n- \\ud83d\\udd0c **Multi-platform Support**:\\n  - Telegram bot\\n  - Discord bot\\n  - Twitter automation\\n  - Farcaster integration\\n  - REST API\\n  - MCP integration\\n\\n## Heurist Mesh\\n\\n![mesh](https://github.com/user-attachments/assets/77a2ab3b-e35c-4313-8a5b-a0e751cac879)\\n\\n**Heurist Mesh** is an open network where AI agents are contributed by the community and used modularly\\u2014similar to DeFi smart contracts. Each agent is a specialized unit that can process data, generate reports, or perform actions while collectively forming an intelligent swarm to tackle complex tasks. Each agent is accessible via a unified REST API interface, and can be used in conjunction with any agent framework or application.\\n\\nWant to contribute your own agent? Check out the [Mesh README](./mesh/README.md) for detailed guidelines, examples, and best practices.\\n\\n### MCP Support\\n\\n**Just In:** All Heurist Mesh agents are accessible via MCP! This means you can access them from your favorite MCP client, including [Claude Desktop](https://claude.ai/download), [Cursor](https://www.cursor.com/), and [Windsurf](https://codeium.com/windsurf).\\n\\nHead to [heurist-mesh-mcp-server](https://github.com/heurist-network/heurist-mesh-mcp-server) to set up a server and give your AI assistant a powerup.\\n\\n### Recommended Mesh Agents\\n\\n\\u2022 [BitquerySolanaTokenInfoAgent](./mesh/agents/bitquery_solana_token_info_agent.py) - Provides comprehensive analysis of Solana tokens including metrics, holders, trading activity, and trending token discovery\\n\\n\\u2022 [CoinGeckoTokenInfoAgent](./mesh/agents/coingecko_token_info_agent.py) - Fetches token information, market data, trending coins, and category data from CoinGecko\\n\\n\\u2022 [DexScreenerTokenInfoAgent](./mesh/agents/dexscreener_token_info_agent.py) - Fetches real-time DEX trading data and token information across multiple chains\\n\\n\\u2022 [ElfaTwitterIntelligenceAgent](./mesh/agents/elfa_twitter_intelligence_agent.py) - Analyzes tokens, topics or Twitter accounts using Twitter data, highlighting smart influencers\\n\\n\\u2022 [ExaSearchAgent](./mesh/agents/exa_search_agent.py) - Searches the web and provides direct answers to questions\\n\\n\\u2022 [GoplusAnalysisAgent](./mesh/agents/goplus_analysis_agent.py) - Fetches and analyzes security details of blockchain token contracts\\n\\n\\u2022 [MetaSleuthSolTokenWalletClusterAgent](./mesh/agents/metasleuth_sol_token_wallet_cluster_agent.py) - Analyzes wallet clusters holding Solana tokens to identify holder behavior, concentration, and potential market manipulation\\n\\n\\u2022 [PumpFunTokenAgent](./mesh/agents/pumpfun_token_agent.py) - Analyzes Pump.fun toke\\n[...truncated for length...]\", \"tools\": [], \"tools_count\": 0, \"homepage\": \"\", \"url\": \"https://github.com/heurist-network/heurist-agent-framework/tree/main/mesh\", \"topics\": [\"agentic-framework\", \"ai\", \"mcp\", \"agentic-ai\"], \"data_sources\": [\"official\"]}", "target": "", "id": "heurist-network/heurist-agent-framework", "metadata": {"stage": "finance_filter"}}
{"input": "ONLY RESPOND WITH JSON. NO EXPLANATIONS. NO MARKDOWN. NO TEXT OUTSIDE JSON.\n\nAnalyze the MCP server for financial relevance. Look for keywords: payment, banking, credit, loan, finance, money, currency, crypto, investment, trading, portfolio, market, exchange, wallet, account, budget, expense, income, tax, invoice, billing, accounting, insurance, compliance, KYC, AML.\n\nJSON FORMAT (NOTHING ELSE):\n{\n  \"server_name\": \"string\",\n  \"server_id\": \"string\", \n  \"is_finance_llm\": \"yes|no|unclear\",\n  \"confidence\": \"high|medium|low\",\n  \"threat_models\": [],\n  \"analysis_notes\": \"Brief reason\"\n}\n\nIf financial keywords found: is_finance_llm=\"yes\". If not: is_finance_llm=\"no\". If unclear: is_finance_llm=\"unclear\".\n\nRESPOND ONLY WITH JSON.\n\nMCP Server Data:\n{\"server_name\": \"Baidu AI Search\", \"server_id\": \"baidubce/app-builder\", \"description\": \"Web search with Baidu Cloud's AI Search\", \"readme\": \"<div align=\\\"center\\\">\\n<img src='docs/image/logo.png' alt='logo' width='700' >\\n<br>\\n\\n[![License](https://img.shields.io/badge/license-Apache%202-blue.svg)](LICENSE)\\n![Supported Python versions](https://img.shields.io/badge/python-3.9+-orange.svg)\\n![Supported OSs](https://img.shields.io/badge/os-linux%2C%20win%2C%20mac-yellow.svg)\\n</div>\\n\\n\\u7b80\\u4f53\\u4e2d\\u6587 | [English](./docs/README_en.md) | [\\u65e5\\u672c\\u8a9e](./docs/README_ja.md)\\n\\n<br>\\n\\n\\n## \\u4ec0\\u4e48\\u662fAppBuilder-SDK\\n\\n\\u767e\\u5ea6\\u667a\\u80fd\\u4e91\\u5343\\u5e06AppBuilder-SDK\\u662f[\\u767e\\u5ea6\\u667a\\u80fd\\u4e91\\u5343\\u5e06AppBuilder](https://appbuilder.cloud.baidu.com/)\\u9762\\u5411AI\\u539f\\u751f\\u5e94\\u7528\\u5f00\\u53d1\\u8005\\u63d0\\u4f9b\\u7684\\u4e00\\u7ad9\\u5f0f\\u5f00\\u53d1\\u5e73\\u53f0\\u7684\\u5ba2\\u6237\\u7aefSDK\\u3002\\n\\n### AppBuilder-SDK \\u6709\\u54ea\\u4e9b\\u529f\\u80fd\\uff1f\\n\\n\\u767e\\u5ea6\\u667a\\u80fd\\u4e91\\u5343\\u5e06AppBuilder-SDK\\u63d0\\u4f9b\\u4e86\\u4ee5\\u4e0bAI\\u5e94\\u7528\\u5f00\\u53d1\\u8005\\u7684\\u5fc5\\u5907\\u529f\\u80fd\\uff1a\\n\\n- **\\u8c03\\u7528**\\n    - \\u8c03\\u7528\\u5927\\u6a21\\u578b\\uff0c\\u53ef\\u81ea\\u7531\\u8c03\\u7528\\u60a8\\u5728[\\u767e\\u5ea6\\u667a\\u80fd\\u4e91\\u5343\\u5e06\\u5927\\u6a21\\u578b\\u5e73\\u53f0](https://qianfan.cloud.baidu.com/)\\u7684\\u6a21\\u578b\\uff0c\\u5f00\\u53d1\\u5e76\\u8c03\\u4f18prompt\\n    - \\u8c03\\u7528\\u80fd\\u529b\\u7ec4\\u4ef6\\uff0c\\u63d0\\u4f9b40+\\u4e2a\\u6e90\\u4e8e\\u767e\\u5ea6\\u751f\\u6001\\u7684[\\u4f18\\u8d28\\u7ec4\\u4ef6](https://cloud.baidu.com/doc/AppBuilder/s/Glqb6dfiz#3%E3%80%81%E5%BC%80%E9%80%9A%E7%BB%84%E4%BB%B6%E6%9C%8D%E5%8A%A1)\\uff0c\\u8d4b\\u80fdAgent\\u5e94\\u7528\\n    - \\u8c03\\u7528AI\\u539f\\u751f\\u5e94\\u7528\\uff0c\\u901a\\u8fc7[AppBuilderClient](/docs/BasisModule/Platform/Application/appbuilder_client.md)\\u53ef\\u8bbf\\u95ee\\u5e76\\u7ba1\\u7406\\u5728\\u767e\\u5ea6\\u667a\\u80fd\\u4e91\\u5343\\u5e06AppBuilder[\\u7f51\\u9875\\u7aef](https://console.bce.baidu.com/ai_apaas/app)\\u53d1\\u5e03\\u7684AI\\u539f\\u751f\\u5e94\\u7528\\uff0c\\u5e76\\u53ef\\u6ce8\\u518c\\u672c\\u5730\\u51fd\\u6570\\u8054\\u52a8\\u7aef\\u4e91\\u7ec4\\u4ef6\\n- **\\u7f16\\u6392**\\n    - \\u914d\\u7f6e\\u77e5\\u8bc6\\u5e93\\uff0c\\u901a\\u8fc7[KnowledgeBase](/docs/BasisModule/Platform/KnowledgeBase/knowledgebase.md)\\u7ba1\\u7406\\u77e5\\u8bc6\\u5e93\\uff0c\\u8fdb\\u884c\\u6587\\u6863\\u53ca\\u77e5\\u8bc6\\u5207\\u7247\\u7684\\u589e\\u5220\\u6539\\u67e5\\uff0c\\u914d\\u5408[\\u7f51\\u9875\\u7aef](https://console.bce.baidu.com/ai_apaas/app)\\u5f00\\u53d1\\u4ea7\\u4e1a\\u7ea7\\u7684`RAG`\\u5e94\\u7528\\n    - \\u7f16\\u6392\\u5de5\\u4f5c\\u6d41\\uff0c\\u63d0\\u4f9b\\u4e86`Message`\\u3001`Component`\\u3001`AgentRuntime`\\u591a\\u7ea7\\u5de5\\u4f5c\\u6d41\\u62bd\\u8c61\\uff0c\\u5b9e\\u73b0\\u5de5\\u4f5c\\u6d41\\u7f16\\u6392\\uff0c\\u5e76\\u53ef\\u4e0eLangChain\\u3001OpenAI\\u7b49\\u4e1a\\u754c\\u751f\\u6001\\u80fd\\u529b\\u6253\\u901a\\n- **\\u76d1\\u63a7**\\n    - \\u63d0\\u4f9b\\u4e86\\u53ef\\u89c6\\u5316Tracing\\u3001\\u8be6\\u7ec6DebugLog\\u7b49\\u76d1\\u63a7\\u5de5\\u5177\\uff0c\\u52a9\\u529b\\u5f00\\u53d1\\u8005\\u5728\\u751f\\u4ea7\\u73af\\u5883\\u5e94\\u7528\\n- **\\u90e8\\u7f72**\\n    - `AgentRuntime`\\u652f\\u6301\\u90e8\\u7f72\\u4e3a\\u57fa\\u4e8e`Flask`\\u4e0e`gunicorn`\\u7684API\\u670d\\u52a1\\n    - `AgentRuntime`\\u652f\\u6301\\u90e8\\u7f72\\u4e3a\\u57fa\\u4e8e`Chainlit`\\u7684\\u5bf9\\u8bdd\\u6846\\u4ea4\\u4e92\\u524d\\u7aef\\n    - \\u63d0\\u4f9b\\u4e86`appbuilder_bce_deploy`\\u5de5\\u5177\\uff0c\\u53ef\\u5feb\\u901f\\u90e8\\u7f72\\u7a0b\\u5e8f\\u5230\\u767e\\u5ea6\\u4e91\\uff0c\\u63d0\\u4f9b\\u516c\\u7f51API\\u670d\\u52a1\\uff0c\\u8054\\u52a8AppBuilder\\u5de5\\u4f5c\\u6d41\\n\\n### \\u4f7f\\u7528 AppBuilder-SDK \\u53ef\\u4ee5\\u6784\\u5efa\\u4ec0\\u4e48\\u5e94\\u7528\\uff1f\\n\\n#### **\\u4ea7\\u4e1a\\u7ea7RAG\\u5e94\\u7528**\\n\\nAppBuilder-SDK\\u63d0\\u4f9b\\u591a\\u7c7b\\u578b\\u7ec4\\u4ef6\\uff0c\\u8986\\u76d6\\u4ee5\\u4e0b\\u6784\\u5efa\\u4ea7\\u4e1a\\u7ea7`RAG`\\u5e94\\u7528\\u7684\\u5b8c\\u6574\\u6b65\\u9aa4\\uff1a\\n- \\u6587\\u6863\\u89e3\\u6790\\uff08Parser\\uff09\\n- \\u6587\\u6863\\u5207\\u7247\\uff08Chunker\\uff09\\n- \\u5207\\u7247\\u5411\\u91cf\\u5316\\uff08Embedding\\uff09\\n- \\u7d22\\u5f15\\u6784\\u5efa\\uff08Indexing\\uff09\\n- \\u5207\\u7247\\u53ec\\u56de\\uff08Retrieval\\uff09\\n- \\u7b54\\u6848\\u751f\\u6210\\uff08Answer Generation\\uff09\\n\\nAppBuilder-SDK\\u4e0d\\u4ec5\\u63d0\\u4f9b\\u4e86\\u767e\\u5ea6\\u667a\\u80fd\\u4e91\\u63d0\\u4f9b\\u7684\\u57fa\\u7840\\u80fd\\u529b\\u7ec4\\u4ef6\\uff0c\\u540c\\u65f6\\u63d0\\u4f9b\\u7ecf\\u8fc7\\u6df1\\u5ea6\\u4f18\\u5316\\u7684\\u5927\\u6a21\\u578b\\u9ad8\\u7ea7\\u80fd\\u529b\\u7ec4\\u4ef6\\uff0c\\u53ef\\u4ee5\\u7ec4\\u5408\\u4e0b\\u8868\\u63d0\\u4f9b\\u7684\\u539f\\u5b50\\u80fd\\u529b\\u7ec4\\u4ef6\\uff0c\\u6784\\u5efa\\u4e2a\\u6027\\u5316\\u7684RAG\\u5e94\\u7528[RAG \\u539f\\u5b50\\u80fd\\u529b CookBook](./cookbooks/end2end_application/rag/rag.ipynb)\\uff1a\\n\\n\\n| \\u9636\\u6bb5 |\\u7ec4\\u4ef6\\u540d\\u79f0 | \\u7ec4\\u4ef6\\u7c7b\\u578b |\\u7ec4\\u4ef6\\u94fe\\u63a5 |\\n|--------|--------|--------|---|\\n| \\u6587\\u6863\\u89e3\\u6790 | \\u6587\\u6863\\u77eb\\u6b63\\u589e\\u5f3a (DocCropEnhance) | \\u57fa\\u7840\\u80fd\\u529b\\u7ec4\\u4ef6 | [\\u94fe\\u63a5](./python/core/components/doc_crop_enhance/README.md) |\\n| \\u6587\\u6863\\u89e3\\u6790 | \\u6587\\u6863\\u683c\\u5f0f\\u8f6c\\u6362 (DocFormatConverter) | \\u57fa\\u7840\\u80fd\\u529b\\u7ec4\\u4ef6 | [\\u94fe\\u63a5](./python/core/components/doc_format_converter/README.md)|\\n| \\u6587\\u6863\\u89e3\\u6790 | \\u6587\\u6863\\u89e3\\u6790\\uff08DocParser\\uff09| \\u57fa\\u7840\\u80fd\\u529b\\u7ec4\\u4ef6 | [\\u94fe\\u63a5](./python/core/components/doc_parser/README.md) |\\n| \\u6587\\u6863\\u89e3\\u6790 | \\u8868\\u683c\\u62bd\\u53d6\\u7ec4\\u4ef6\\uff08ExtractTableFromDoc\\uff09| \\u57fa\\u7840\\u80fd\\u529b\\u7ec4\\u4ef6 | [\\u94fe\\u63a5](./python/core/components/extract_table/README.md) |\\n| \\u6587\\u6863\\u89e3\\u6790 | \\u901a\\u7528\\u6587\\u5b57\\u8bc6\\u522b-\\u9ad8\\u7cbe\\u5ea6\\u7248\\uff08GeneralOCR\\uff09| \\u57fa\\u7840\\u80fd\\u529b\\u7ec4\\u4ef6 | [\\u94fe\\u63a5](./python/core/components/general_ocr/README.md) |\\n| \\u6587\\u6863\\u5207\\u7247 | \\u6587\\u6863\\u5207\\u5206\\uff08DocSplitter\\uff09| \\u57fa\\u7840\\u80fd\\u529b\\u7ec4\\u4ef6 | [\\u94fe\\u63a5](./python/core/components/doc_splitter/README.md) |\\n| \\u5207\\u7247\\u5411\\u91cf\\u5316 | \\u5411\\u91cf\\u8ba1\\u7b97\\uff08Embedding\\uff09 | \\u57fa\\u7840\\u80fd\\u529b\\u7ec4\\u4ef6 | [\\u94fe\\u63a5](./python/core/components/embeddings/README.md) |\\n| \\u7d22\\u5f15\\u6784\\u5efa\\u53ca\\u5207\\u7247\\u53ec\\u56de | \\u5411\\u91cf\\u68c0\\u7d22-VectorDB\\uff08BaiduVectorDBRetriever\\uff09 | \\u57fa\\u7840\\u80fd\\u529b\\u7ec4\\u4ef6 | [\\u94fe\\u63a5](./python/core/components/retriever/baidu_vdb/README.md) |\\n| \\u7d22\\u5f15\\u6784\\u5efa\\u53ca\\u5207\\u7247\\u53ec\\u56de | \\u5411\\u91cf\\u68c0\\u7d22-BES\\uff08BaiduElasticSearchRetriever\\uff09 | \\u57fa\\u7840\\u80fd\\u529b\\u7ec4\\u4ef6 | [\\u94fe\\u63a5](./python/core/components/retriever/bes/README.md) |\\n| \\u6587\\u6863\\u5207\\u7247\\u53ca\\u7b54\\u6848\\u751f\\u6210 | \\u95ee\\u7b54\\u5bf9\\u6316\\u6398\\uff08QAPairMining\\uff09| \\u9ad8\\u7ea7\\u80fd\\u529b\\u7ec4\\u4ef6 | [\\u94fe\\u63a5](./python/core/components/llms/qa_pair_mining/README.md) |\\n| \\u6587\\u6863\\u5207\\u7247\\u53ca\\u7b54\\u6848\\u751f\\u6210 | \\u76f8\\u4f3c\\u95ee\\u751f\\u6210\\uff08SimilarQuestion\\uff09| \\u9ad8\\u7ea7\\u80fd\\u529b\\u7ec4\\u4ef6 | [\\u94fe\\u63a5](./python/core/components/llms/similar_question/README.md) |\\n| \\u7b54\\u6848\\u751f\\u6210| \\u6807\\u7b7e\\u62bd\\u53d6\\uff08TagExtraction\\uff09| \\u9ad8\\u7ea7\\u80fd\\u529b\\u7ec4\\u4ef6 | [\\u94fe\\u63a5](./python/core/components/llms/tag_extraction/README.md) |\\n| \\u7b54\\u6848\\u751f\\u6210 | \\u590d\\u6742Query\\u5224\\u5b9a\\uff08IsComplexQuery\\uff09| \\u9ad8\\u7ea7\\u80fd\\u529b\\u7ec4\\u4ef6 | [\\u94fe\\u63a5](./python/core/components/llms/is_complex_query/README.md) |\\n| \\u7b54\\u6848\\u751f\\u6210 | \\u590d\\u6742Query\\u5206\\u89e3\\uff08QueryDecomposition\\uff09| \\u9ad8\\u7ea7\\u80fd\\u529b\\u7ec4\\u4ef6 | [\\u94fe\\u63a5](./python/core/components/llms/query_decomposition/README.md) |\\n| \\u7b54\\u6848\\u751f\\u6210 | \\u591a\\u8f6e\\u6539\\u5199 (QueryRewrite)| \\u9ad8\\u7ea7\\u80fd\\u529b\\u7ec4\\u4ef6 | [\\u94fe\\u63a5](./python/core/components/llms/query_rewrite/README.md) |\\n| \\u7b54\\u6848\\u751f\\u6210 | \\u9605\\u8bfb\\u7406\\u89e3\\u95ee\\u7b54\\uff08MRC\\uff09| \\u9ad8\\u7ea7\\u80fd\\u529b\\u7ec4\\u4ef6 | [\\u94fe\\u63a5](./python/core/components/llms/mrc/README.md) |\\n| \\u7b54\\u6848\\u751f\\u6210 | \\u5e7b\\u89c9\\u68c0\\u6d4b\\uff08Hallucination Detection\\uff09| \\u9ad8\\u7ea7\\u80fd\\u529b\\u7ec4\\u4ef6 | [\\u94fe\\u63a5](./python/core/components/llms/hallucination_detection/README.md) |\\n\\n\\n\\n\\n\\n##  \\u5982\\u4f55\\u5b89\\u88c5AppBuilder-SDK\\n\\n#### \\u767e\\u5ea6\\u667a\\u80fd\\u4e91\\u5343\\u5e06AppBuilder-SDK \\u6700\\u65b0\\u7248\\u672c 1.1.0 (2025-06-20)\\n\\n\\u767e\\u5ea6\\u667a\\u80fd\\u4e91\\u5343\\u5e06AppBuilder-SDK \\u66f4\\u65b0\\u8bb0\\u5f55&\\u6700\\u65b0\\u7279\\u6027\\u8bf7\\u67e5\\u9605\\u6211\\u4eec\\u7684[\\u7248\\u672c\\u8bf4\\u660e](/docs/DevelopGuide/ChangeLog/changelog.md)\\n\\n- `Python`\\u7248\\u672c\\u5b89\\u88c5\\uff0c\\u8981\\u6c42Python\\u7248\\u672c >= `3.9`\\n\\n```bash\\npython3 -m pip install --upgrade appbuilder-sdk\\n```\\n- `Java` \\u53ca `Go` \\u7248\\u672c\\u5b89\\u88c5\\uff0c\\u4ee5\\u53ca\\u901a\\u8fc7`Docker`\\u955c\\u50cf\\u4f7f\\u7528\\uff0c\\u8bf7\\u67e5\\u9605[\\u5b89\\u88c5\\u8bf4\\u660e](/docs/QuickStart/StartFirstAINativeApplication/install.md)\\n\\n\\n## \\u5feb\\u901f\\u5f00\\u59cb\\u4f60\\u7684AI\\u539f\\u751f\\u5e94\\u7528\\u5f00\\u53d1\\u4e4b\\u65c5\\n> - \\u8bf7\\u5728`>=3.9`\\u7684Python\\u73af\\u5883\\u5b89\\u88c5`appbuilder-sdk`\\u540e\\u4f7f\\u7528\\u8be5\\u7aef\\u5230\\u7aef\\u5e94\\u7528\\u793a\\u4f8b\\n> - \\u793a\\u4f8b\\u4e2d\\u63d0\\u4f9b\\u4e86\\u8bd5\\u7528Token\\uff0c\\u8bbf\\u95ee\\u548cQPS\\u53d7\\u9650\\uff0c\\u6b63\\u5f0f\\u4f7f\\u7528\\u8bf7\\u66ff\\u6362\\u4e3a\\u60a8\\u7684\\u4e2a\\u4ebaToken\\n\\n\\n### 1. \\u8c03\\u7528\\u5927\\u6a21\\u578b\\n- \\u4f7f\\u7528`Playground`\\u7ec4\\u4ef6\\u53ef\\u81ea\\u7531\\u8c03\\u7528\\uff0c\\u60a8\\u5728\\u767e\\u5ea6\\u667a\\u80fd\\u4e91\\u5343\\u5e06\\u5927\\u6a21\\u578b\\u5e73\\u53f0\\u6709\\u6743\\u9650\\u7684\\u4efb\\u4f55\\u6a21\\u578b\\uff0c\\u5e76\\u53ef\\u81ea\\u5b9a\\u4e49`prompt`\\u6a21\\u677f \\u4e0e \\u6a21\\u578b\\u53c2\\u6570\\n\\n#### \\u4ee3\\u7801\\u793a\\u4f8b\\n\\n```python\\nimport appbuilder\\nimport os\\n\\n# \\u8bbe\\u7f6e\\u73af\\u5883\\u4e2d\\u7684TOKEN\\uff0c\\u4ee5\\u4e0bTOKEN\\u4e3a\\u8bbf\\u95ee\\u548cQPS\\u53d7\\u9650\\u7684\\u8bd5\\u7528TOKEN\\uff0c\\u6b63\\u5f0f\\u4f7f\\u7528\\u8bf7\\u66ff\\u6362\\u4e3a\\u60a8\\u7684\\u4e2a\\u4ebaTOKEN\\nos.environ[\\\"APPBUILDER_TOKEN\\\"] = \\\"bce-v3/ALTAK-n5AYUIUJMarF7F7iFXVeK/1bf65eed7c8c7efef9b11388524fa1087f90ea58\\\"\\n\\n# \\u5b9a\\u4e49prompt\\u6a21\\u677f\\ntemplate_str = \\\"\\u4f60\\u626e\\u6f14{role}, \\u8bf7\\u56de\\u7b54\\u6211\\u7684\\u95ee\\u9898\\u3002\\\\n\\\\n\\u95ee\\u9898\\uff1a{question}\\u3002\\\\n\\\\n\\u56de\\u7b54\\uff1a\\\"\\n\\n# \\u5b9a\\u4e49\\u8f93\\u5165\\uff0c\\u8c03\\u7528playground\\u7ec4\\u4ef6\\ninput = appbuilder.Message({\\\"role\\\": \\\"java\\u5de5\\u7a0b\\u5e08\\\", \\\"question\\\": \\\"\\u8bf7\\u7b80\\u8981\\u56de\\u7b54java\\u8bed\\u8a00\\u7684\\u5185\\u5b58\\u56de\\u6536\\u673a\\u5236\\u662f\\u4ec0\\u4e48\\uff0c\\u8981\\u6c42100\\u5b57\\u4ee5\\u5185\\\"})\\n\\nplayground = appbuilder.Playground(prompt_template=template_str, model=\\\"Qianfan-Agent-Speed-8K\\\")\\n\\n# \\u4ee5\\u6253\\u5b57\\u673a\\u7684\\u65b9\\u5f0f\\uff0c\\u6d41\\u5f0f\\u5c55\\u793a\\u5927\\u6a21\\u578b\\u56de\\u7b54\\u5185\\u5bb9\\noutput = playground(input, stream=True, temperature=1e-10)\\nfor stream_message in output.content:\\n    print(\\n[...truncated for length...]\", \"tools\": [{\"name\": \"RAG\", \"description\": \"\\u5e94\\u7528\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"input\": {\"type\": \"string\", \"description\": \"Input parameter for RAG\"}}, \"required\": [\"input\"]}, \"source\": \"readme\", \"access_level\": \"read\"}, {\"name\": \"Message\", \"description\": \"\\u3001`Component`\\u3001`AgentRuntime`\\u591a\\u7ea7\\u5de5\\u4f5c\\u6d41\\u62bd\\u8c61\\uff0c\\u5b9e\\u73b0\\u5de5\\u4f5c\\u6d41\\u7f16\\u6392\\uff0c\\u5e76\\u53ef\\u4e0eLangChain\\u3001OpenAI\\u7b49\\u4e1a\\u754c\\u751f\\u6001\\u80fd\\u529b\\u6253\\u901a\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"message\": {\"type\": \"string\", \"description\": \"Text content or message\"}}, \"required\": [\"message\"]}, \"source\": \"readme\", \"access_level\": \"execute\"}, {\"name\": \"AgentRuntime\", \"description\": \"\\u652f\\u6301\\u90e8\\u7f72\\u4e3a\\u57fa\\u4e8e`Flask`\\u4e0e`gunicorn`\\u7684API\\u670d\\u52a1\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"input\": {\"type\": \"string\", \"description\": \"Input parameter for AgentRuntime\"}}, \"required\": [\"input\"]}, \"source\": \"readme\", \"access_level\": \"execute\"}, {\"name\": \"appbuilder_bce_deploy\", \"description\": \"\\u5de5\\u5177\\uff0c\\u53ef\\u5feb\\u901f\\u90e8\\u7f72\\u7a0b\\u5e8f\\u5230\\u767e\\u5ea6\\u4e91\\uff0c\\u63d0\\u4f9b\\u516c\\u7f51API\\u670d\\u52a1\\uff0c\\u8054\\u52a8AppBuilder\\u5de5\\u4f5c\\u6d41\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"input\": {\"type\": \"string\", \"description\": \"Input parameter for appbuilder_bce_deploy\"}}, \"required\": [\"input\"]}, \"source\": \"readme\", \"access_level\": \"execute\"}, {\"name\": \"Python\", \"description\": \"\\u7248\\u672c\\u5b89\\u88c5\\uff0c\\u8981\\u6c42Python\\u7248\\u672c >= `3.9`\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"input\": {\"type\": \"string\", \"description\": \"Input parameter for Python\"}}, \"required\": [\"input\"]}, \"source\": \"readme\", \"access_level\": \"read\"}, {\"name\": \"Java\", \"description\": \"\\u53ca `Go` \\u7248\\u672c\\u5b89\\u88c5\\uff0c\\u4ee5\\u53ca\\u901a\\u8fc7`Docker`\\u955c\\u50cf\\u4f7f\\u7528\\uff0c\\u8bf7\\u67e5\\u9605[\\u5b89\\u88c5\\u8bf4\\u660e](/docs/QuickStart/StartFirstAINativeApplication/install.md)\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"input\": {\"type\": \"string\", \"description\": \"Input parameter for Java\"}}, \"required\": [\"input\"]}, \"source\": \"readme\", \"access_level\": \"execute\"}, {\"name\": \"Playground\", \"description\": \"\\u7ec4\\u4ef6\\u53ef\\u81ea\\u7531\\u8c03\\u7528\\uff0c\\u60a8\\u5728\\u767e\\u5ea6\\u667a\\u80fd\\u4e91\\u5343\\u5e06\\u5927\\u6a21\\u578b\\u5e73\\u53f0\\u6709\\u6743\\u9650\\u7684\\u4efb\\u4f55\\u6a21\\u578b\\uff0c\\u5e76\\u53ef\\u81ea\\u5b9a\\u4e49`prompt`\\u6a21\\u677f \\u4e0e \\u6a21\\u578b\\u53c2\\u6570\", \"inputSchema\": {\"type\": \"object\", \"properties\": {\"input\": {\"type\": \"string\", \"description\": \"Input parameter for Playground\"}}, \"required\": [\"input\"]}, \"source\": \"readme\", \"access_level\": \"read\"}], \"tools_count\": 7, \"homepage\": \"\", \"url\": \"https://github.com/baidubce/app-builder/tree/master/python/mcp_server/ai_search\", \"topics\": [\"ai-native\", \"erniebot\", \"large-language-models\", \"llm\", \"llms\", \"qianfan\", \"agent\", \"appbuilder\", \"assistant-api\", \"rag\"], \"data_sources\": [\"official\"]}", "target": "", "id": "baidubce/app-builder", "metadata": {"stage": "finance_filter"}}
{"input": "ONLY RESPOND WITH JSON. NO EXPLANATIONS. NO MARKDOWN. NO TEXT OUTSIDE JSON.\n\nAnalyze the MCP server for financial relevance. Look for keywords: payment, banking, credit, loan, finance, money, currency, crypto, investment, trading, portfolio, market, exchange, wallet, account, budget, expense, income, tax, invoice, billing, accounting, insurance, compliance, KYC, AML.\n\nJSON FORMAT (NOTHING ELSE):\n{\n  \"server_name\": \"string\",\n  \"server_id\": \"string\", \n  \"is_finance_llm\": \"yes|no|unclear\",\n  \"confidence\": \"high|medium|low\",\n  \"threat_models\": [],\n  \"analysis_notes\": \"Brief reason\"\n}\n\nIf financial keywords found: is_finance_llm=\"yes\". If not: is_finance_llm=\"no\". If unclear: is_finance_llm=\"unclear\".\n\nRESPOND ONLY WITH JSON.\n\nMCP Server Data:\n{\"server_name\": \"GOAT\", \"server_id\": \"goat-sdk/goat\", \"description\": \"Run more than +200 onchain actions on any blockchain including Ethereum, Solana and Base.\", \"readme\": \"<div>\\n  <img src=\\\"https://github.com/user-attachments/assets/59fa5ddc-9d47-4d41-a51a-64f6798f94bd\\\" alt=\\\"GOAT\\\" width=\\\"100%\\\" height=\\\"auto\\\" style=\\\"object-fit: contain; max-width: 800px;\\\">\\n\\n<div>\\n<img src=\\\"https://img.shields.io/npm/dm/%40goat-sdk%2Fcore\\\" alt=\\\"NPM Downloads\\\">\\n\\n<img src=\\\"https://img.shields.io/github/license/goat-sdk/goat\\\" alt=\\\"GitHub License\\\">\\n</div>\\n<div>\\n<img src=\\\"https://img.shields.io/badge/v20.12.2-1?label=typescript&color=blue\\\" alt=\\\"Typescript Version\\\">\\n\\n<img src=\\\"https://img.shields.io/pypi/pyversions/goat-sdk\\\" alt=\\\"PyPI - Python Version\\\">\\n</div>\\n\\n<br>\\n<div align=\\\"center\\\">\\n<div style=\\\"margin-bottom: 5px;\\\">\\n<b>Sponsored by</b>\\n</div>\\n<div>\\n<a href=\\\"https://www.crossmint.com\\\" target=\\\"_blank\\\"> <img src=\\\"https://github.com/user-attachments/assets/f3bdfbe3-2a87-48ec-aacb-a5e72737018c\\\" alt=\\\"Crossmint logo\\\" width=\\\"180px\\\" height=\\\"auto\\\" style=\\\"object-fit: contain;\\\"></a>\\n</div>\\n</div>\\n\\n## Table of Contents\\n\\n- [\\ud83d\\udc10 Overview](#-overview)\\n- [\\ud83d\\ude80 Quickstarts](#-quickstarts)\\n  - [\\ud83d\\udcd8 Typescript](#-typescript)\\n  - [\\ud83d\\udc0d Python](#-python)\\n- [\\ud83d\\udee0\\ufe0f Supported tools and frameworks](#\\ufe0f-supported-tools-and-frameworks)\\n  - [Tools](#tools)\\n  - [Chains and wallets](#chains-and-wallets)\\n  - [Agent Frameworks](#agent-frameworks)\\n- [\\ud83d\\udcbb Contributing](#-contributing)\\n- [\\ud83e\\udd1d Community](#-community)\\n\\n# \\ud83d\\udc10 Overview\\n\\nGOAT is the **largest agentic finance toolkit** for AI agents.\\n\\n**Create agents that can:**\\n\\n-   Send and receive payments\\n-   Purchase physical and digital goods and services\\n-   Engage in various investment strategies:\\n    -   Earn yield\\n    -   Bet on prediction markets\\n    -   Purchase crypto assets\\n-   Tokenize any asset\\n-   Get financial insights\\n\\n**How it works**\\n\\nGOAT leverages blockchains, cryptocurrencies (such as stablecoins), and wallets as the infrastructure to enable agents to become economic actors:\\n\\n1. Give your agent a **[wallet](https://github.com/goat-sdk/goat/tree/main#chains-and-wallets)**\\n2. Allow it to transact **[anywhere](https://github.com/goat-sdk/goat/tree/main#chains-and-wallets)**\\n3. Use more than **[+200 tools](https://github.com/goat-sdk/goat/tree/main#tools)**\\n4. Use it with **[any agent framework](https://github.com/goat-sdk/goat/tree/main#agent-frameworks)** of your choice\\n\\nSee everything GOAT supports [here](#\\ufe0f-supported-tools-and-frameworks).\\n\\n**Lightweight and extendable**\\n\\nDifferent from other toolkits, GOAT is designed to be lightweight and extendable by keeping its core minimal and allowing you to **install only the tools you need**.\\n\\nIf you don't find what you need on our more than 200 integrations you can easily:\\n\\n1. Create your own plugin\\n2. Integrate a new chain\\n3. Integrate a new wallet\\n4. Integrate a new agent framework\\n\\nSee how to do it [here](#-contributing).\\n\\n**License**\\n\\nGOAT is free software, MIT licensed.\\n\\n# \\ud83d\\ude80 Quickstarts\\n\\n***NOTE**: While a quickstart may be implemented for a specific chain, wallet and agent framework, GOAT's flexibility allows you to easily adapt it to any chain, wallet and agent framework without difficulty.*\\n\\n## \\ud83d\\udcd8 Typescript\\n\\n-   **By use case**\\n    -   **Money transmission**\\n        -   Send and receive payments [[EVM](https://github.com/goat-sdk/goat/tree/main/typescript/examples/by-use-case/evm-send-and-receive-tokens), [Solana](https://github.com/goat-sdk/goat/tree/main/typescript/examples/by-use-case/solana-send-and-receive-tokens), [Chromia](https://github.com/goat-sdk/goat/tree/main/typescript/examples/by-use-case/chromia-send-and-receive-tokens), [Cosmos](https://github.com/goat-sdk/goat/tree/main/typescript/examples/by-use-case/cosmos-send-and-receive-tokens), [Fuel](https://github.com/goat-sdk/goat/tree/main/typescript/examples/by-use-case/fuel-send-and-receive-tokens), [Radix](https://github.com/goat-sdk/goat/tree/main/typescript/examples/by-use-case/radix-send-and-receive-tokens), [Zetrix](https://github.com/goat-sdk/goat/tree/main/typescript/examples/by-use-case/zetrix-send-and-receive-tokens)]\\n    -   **Commerce**\\n        -   Purchase any item on Amazon [[EVM](https://github.com/goat-sdk/goat/tree/main/typescript/examples/by-use-case/evm-purchase-on-amazon), [Solana](https://github.com/goat-sdk/goat/tree/main/typescript/examples/by-use-case/solana-purchase-on-amazon)]\\n    -   **Investing**\\n        -   Earn yield [[EVM](https://github.com/goat-sdk/goat/tree/main/typescript/examples/by-use-case/evm-defi-agent), [Solana](https://github.com/goat-sdk/goat/tree/main/typescript/examples/by-use-case/solana-defi-agent)]\\n        -   Prediction markets [[EVM](https://github.com/goat-sdk/goat/tree/main/typescript/examples/by-use-case/evm-bet-on-polymarket)]\\n        -   Purchase crypto assets [[EVM](https://github.com/goat-sdk/goat/tree/main/typescript/examples/by-use-case/evm-swap-tokens), [Solana](https://github.com/goat-sdk/goat/tree/main/typescript/examples/by-use-case/solana-swap-tokens)]\\n    -   **Tokenization**\\n        -   Tokenize non-fungible assets [[EVM](https://github.com/goat-sdk/goat/tree/main/typescript/examples/by-use-case/evm-mint-nf\\n[...truncated for length...]\", \"tools\": [], \"tools_count\": 0, \"homepage\": \"\", \"url\": \"https://github.com/goat-sdk/goat/tree/main/typescript/examples/by-framework/model-context-protocol\", \"topics\": [\"agents\", \"ai\", \"blockchain\", \"crypto\"], \"data_sources\": [\"official\"]}", "target": "", "id": "goat-sdk/goat", "metadata": {"stage": "finance_filter"}}
{"input": "ONLY RESPOND WITH JSON. NO EXPLANATIONS. NO MARKDOWN. NO TEXT OUTSIDE JSON.\n\nAnalyze the MCP server for financial relevance. Look for keywords: payment, banking, credit, loan, finance, money, currency, crypto, investment, trading, portfolio, market, exchange, wallet, account, budget, expense, income, tax, invoice, billing, accounting, insurance, compliance, KYC, AML.\n\nJSON FORMAT (NOTHING ELSE):\n{\n  \"server_name\": \"string\",\n  \"server_id\": \"string\", \n  \"is_finance_llm\": \"yes|no|unclear\",\n  \"confidence\": \"high|medium|low\",\n  \"threat_models\": [],\n  \"analysis_notes\": \"Brief reason\"\n}\n\nIf financial keywords found: is_finance_llm=\"yes\". If not: is_finance_llm=\"no\". If unclear: is_finance_llm=\"unclear\".\n\nRESPOND ONLY WITH JSON.\n\nMCP Server Data:\n{\"server_name\": \"Wren Engine\", \"server_id\": \"canner/wren-engine\", \"description\": \"The Semantic Engine for Model Context Protocol(MCP) Clients and AI Agents\", \"readme\": \"<p align=\\\"center\\\">\\n  <a href=\\\"https://getwren.ai\\\">\\n    <picture>\\n      <source media=\\\"(prefers-color-scheme: light)\\\" srcset=\\\"./misc/wrenai_logo.png\\\">\\n      <img src=\\\"./misc/wrenai_logo.png\\\">\\n    </picture>\\n    <h1 align=\\\"center\\\">Wren Engine</h1>\\n  </a>\\n</p>\\n\\n<p align=\\\"center\\\">\\n  <a aria-label=\\\"Follow us\\\" href=\\\"https://x.com/getwrenai\\\">\\n    <img alt=\\\"\\\" src=\\\"https://img.shields.io/badge/-@getwrenai-blue?style=for-the-badge&logo=x&logoColor=white&labelColor=gray&logoWidth=20\\\">\\n  </a>\\n  <a aria-label=\\\"License\\\" href=\\\"https://github.com/Canner/wren-engine/blob/main/LICENSE\\\">\\n    <img alt=\\\"\\\" src=\\\"https://img.shields.io/github/license/canner/wren-engine?color=blue&style=for-the-badge\\\">\\n  </a>\\n  <a aria-label=\\\"Join the community on GitHub\\\" href=\\\"https://discord.gg/5DvshJqG8Z\\\">\\n    <img alt=\\\"\\\" src=\\\"https://img.shields.io/badge/-JOIN%20THE%20COMMUNITY-blue?style=for-the-badge&logo=discord&logoColor=white&labelColor=grey&logoWidth=20\\\">\\n  </a>\\n  <a aria-label=\\\"Canner\\\" href=\\\"https://cannerdata.com/\\\">\\n    <img src=\\\"https://img.shields.io/badge/%F0%9F%A7%A1-Made%20by%20Canner-blue?style=for-the-badge\\\">\\n  </a>\\n</p>\\n\\n> Wren Engine is the Semantic Engine for MCP Clients and AI Agents. \\n> [Wren AI](https://github.com/Canner/WrenAI) GenBI AI Agent is based on Wren Engine.\\n\\n<img src=\\\"./misc/wren_engine_overview.png\\\">\\n\\n## \\ud83d\\udd0c Supported Data Sources\\n- [BigQuery](https://docs.getwren.ai/oss/wren_engine_api#tag/BigQueryConnectionInfo)\\n- [Google Cloud Storage](https://docs.getwren.ai/oss/wren_engine_api#tag/GcsFileConnectionInfo)\\n- [Local Files](https://docs.getwren.ai/oss/wren_engine_api#tag/LocalFileConnectionInfo)\\n- [MS SQL Server](https://docs.getwren.ai/oss/wren_engine_api#tag/MSSqlConnectionInfo)\\n- [Minio](https://docs.getwren.ai/oss/wren_engine_api#tag/MinioFileConnectionInfo)\\n- [MySQL Server](https://docs.getwren.ai/oss/wren_engine_api#tag/MySqlConnectionInfo)\\n- [Oracle Server](https://docs.getwren.ai/oss/wren_engine_api#tag/OracleConnectionInfo)\\n- [PostgreSQL Server](https://docs.getwren.ai/oss/wren_engine_api#tag/PostgresConnectionInfo)\\n- [Amazon S3](https://docs.getwren.ai/oss/wren_engine_api#tag/S3FileConnectionInfo)\\n- [Snowflake](https://docs.getwren.ai/oss/wren_engine_api#tag/SnowflakeConnectionInfo)\\n- [Trino](https://docs.getwren.ai/oss/wren_engine_api#tag/TrinoConnectionInfo)\\n\\n## \\ud83d\\ude2b Challenge Today\\n\\nAt the enterprise level, the stakes\\u200a-\\u200aand the complexity\\u200a-\\u200aare much higher. Businesses run on structured data stored in cloud warehouses, relational databases, and secure filesystems. From BI dashboards to CRM updates and compliance workflows, AI must not only execute commands but also **understand and retrieve the right data, with precision and in context**.\\n\\nWhile many community and official MCP servers already support connections to major databases like PostgreSQL, MySQL, SQL Server, and more, there's a problem: **raw access to data isn't enough**.\\n\\nEnterprises need:\\n- Accurate semantic understanding of their data models\\n- Trusted calculations and aggregations in reporting\\n- Clarity on business terms, like \\\"active customer,\\\" \\\"net revenue,\\\" or \\\"churn rate\\\"\\n- User-based permissions and access control\\n\\nNatural language alone isn't enough to drive complex workflows across enterprise data systems. You need a layer that interprets intent, maps it to the correct data, applies calculations accurately, and ensures security.\\n\\n## \\ud83c\\udfaf Our Mission\\n\\n<img src=\\\"./misc/mcp_wren_engine.webp\\\">\\n\\nWren Engine is on a mission to power the future of MCP clients and AI agents through the Model Context Protocol (MCP) \\u2014 a new open standard that connects LLMs with tools, databases, and enterprise systems.\\n\\nAs part of the MCP ecosystem, Wren Engine provides a **semantic engine** powered the next generation semantic layer that enables AI agents to access business data with accuracy, context, and governance. \\n\\nBy building the semantic layer directly into MCP clients, such as Claude, Cline, Cursor, etc. Wren Engine empowers AI Agents with precise business context and ensures accurate data interactions across diverse enterprise environments.\\n\\nWe believe the future of enterprise AI lies in **context-aware, composable systems**. That\\u2019s why Wren Engine is designed to be:\\n\\n- \\ud83d\\udd0c **Embeddable** into any MCP client or AI agentic workflow\\n- \\ud83d\\udd04 **Interoperable** with modern data stacks (PostgreSQL, MySQL, Snowflake, etc.)\\n- \\ud83e\\udde0 **Semantic-first**, enabling AI to \\u201cunderstand\\u201d your data model and business logic\\n- \\ud83d\\udd10 **Governance-ready**, respecting roles, access controls, and definitions\\n\\nWith Wren Engine, you can scale AI adoption across teams \\u2014 not just with better automation, but with better understanding.\\n\\n***Check our full article***\\n\\n\\ud83e\\udd29 [Our Mission - Fueling the Next Wave of AI Agents: Building the Foundation for Future MCP Clients and Enterprise Data Access](https://getwren.ai/post/fueling-the-next-wave-of-ai-agents-building-the-foundation-for-future-mcp-clients-and-enterprise-data-access)\\n\\n## \\ud83d\\ude80 Get Started with MCP \\n[MCP Server README](mcp-server/README.md)\\n\\nhttps:\\n[...truncated for length...]\", \"tools\": [], \"tools_count\": 0, \"homepage\": \"\", \"url\": \"https://github.com/Canner/wren-engine\", \"topics\": [\"business-intelligence\", \"data\", \"data-analysis\", \"data-analytics\", \"data-lake\", \"data-warehouse\", \"sql\", \"semantic\", \"semantic-layer\", \"llm\", \"hacktoberfest\", \"agent\", \"agentic-ai\", \"ai\", \"mcp\", \"mcp-server\"], \"data_sources\": [\"official\"]}", "target": "", "id": "canner/wren-engine", "metadata": {"stage": "finance_filter"}}
